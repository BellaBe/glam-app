================================================================================
Directory Structure: /home/bellabe/glam-app/shared
================================================================================

shared/
shared/
├── api/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/api/__init__.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Unified API response models and utilities for glam-app microservices.
│   │   
│   │   This module provides a single, consistent approach to API responses
│   │   across all services.
│   │   """
│   │   
│   │   from .models import (
│   │       # Core models
│   │       ApiResponse,
│   │       Meta,
│   │       Pagination,
│   │       Links,
│   │       ErrorDetail,
│   │   )
│   │   
│   │   from .responses import (
│   │       # Response helpers
│   │       create_response,
│   │       success_response,
│   │       error_response,
│   │       paginated_response,
│   │   )
│   │   
│   │   from .dependencies import (
│   │       # FastAPI dependencies
│   │       PaginationDep,
│   │       RequestContextDep, 
│   │   )
│   │   
│   │   from .middleware import (
│   │       # Middleware
│   │       APIMiddleware,
│   │       setup_middleware,
│   │   )
│   │   
│   │   from .correlation import (
│   │       # Correlation utilities
│   │       get_correlation_id,
│   │       set_correlation_context,
│   │       get_correlation_context,
│   │       add_correlation_header,
│   │       add_correlation_to_event,
│   │       extract_correlation_from_event, 
│   │   )
│   │   
│   │   __all__ = [
│   │       # Models
│   │       "ApiResponse",
│   │       "Meta",
│   │       "Pagination",
│   │       "Links",
│   │       "ErrorDetail",
│   │       
│   │       # Response helpers
│   │       "create_response",
│   │       "success_response",
│   │       "error_response",
│   │       "paginated_response",
│   │       
│   │       # Dependencies
│   │       "PaginationDep",
│   │       "RequestContextDep",
│   │       
│   │       # Correlation
│   │       "get_correlation_id",
│   │       "set_correlation_context",
│   │       "get_correlation_context",
│   │       "add_correlation_header",
│   │       "add_correlation_to_event",
│   │       "extract_correlation_from_event",
│   │       
│   │       # Middleware
│   │       "APIMiddleware",
│   │       "setup_middleware",
│   │   ]
│   │   ```
│   │   
│   ├── correlation.py
│   │   
│   │   ```py
│   │   # File: shared/api/correlation.py
│   │   
│   │   """
│   │   Simplified correlation ID support for distributed tracing.
│   │   
│   │   Focuses on the essential functionality needed for request tracing
│   │   across services without over-engineering.
│   │   """
│   │   
│   │   from typing import Optional, Annotated
│   │   from contextvars import ContextVar
│   │   from fastapi import Request, Depends
│   │   import uuid
│   │   
│   │   # Context variable for async operations
│   │   _correlation_context: ContextVar[Optional[str]] = ContextVar(
│   │       "correlation_id", default=None
│   │   )
│   │   
│   │   
│   │   def get_correlation_id(request: Request) -> str:
│   │       """
│   │       Get or generate correlation ID for the current request.
│   │   
│   │       Priority:
│   │       1. Request state (set by middleware)
│   │       2. X-Correlation-ID header (from upstream service)
│   │       3. Generate new one (originating request)
│   │       """
│   │       # Check request state first
│   │       if hasattr(request.state, "correlation_id"):
│   │           return request.state.correlation_id
│   │   
│   │       # Check headers from upstream service
│   │       correlation_id = request.headers.get("X-Correlation-ID")
│   │       if correlation_id:
│   │           return correlation_id
│   │   
│   │       # Generate new one
│   │       return f"corr_{uuid.uuid4().hex[:12]}"
│   │   
│   │   
│   │   # FastAPI dependency
│   │   CorrelationIdDep = Annotated[str, Depends(get_correlation_id)]
│   │   
│   │   
│   │   def set_correlation_context(correlation_id: str) -> None:
│   │       """Set correlation ID in async context."""
│   │       _correlation_context.set(correlation_id)
│   │   
│   │   
│   │   def get_correlation_context() -> Optional[str]:
│   │       """Get correlation ID from async context."""
│   │       return _correlation_context.get()
│   │   
│   │   
│   │   # Essential integrations only
│   │   
│   │   
│   │   def add_correlation_header(headers: dict) -> dict:
│   │       """
│   │       Add correlation ID to outgoing HTTP headers.
│   │   
│   │       Usage:
│   │           headers = add_correlation_header({"Content-Type": "application/json"})
│   │           response = await client.get(url, headers=headers)
│   │       """
│   │       correlation_id = get_correlation_context()
│   │       if correlation_id:
│   │           headers["X-Correlation-ID"] = correlation_id
│   │       return headers
│   │   
│   │   
│   │   def add_correlation_to_event(event_data: dict) -> dict:
│   │       """
│   │       Add correlation ID to message bus events.
│   │   
│   │       Usage:
│   │           event_data = {"subject": "ORDER_CREATED", "data": {...}}
│   │           event_with_correlation = add_correlation_to_event(event_data)
│   │       """
│   │       correlation_id = get_correlation_context()
│   │       if correlation_id:
│   │           if "metadata" not in event_data:
│   │               event_data["metadata"] = {}
│   │           event_data["metadata"]["correlation_id"] = correlation_id
│   │       return event_data
│   │   
│   │   
│   │   def extract_correlation_from_event(event_data: dict) -> Optional[str]:
│   │       """Extract correlation ID from event data."""
│   │       return event_data.get("metadata", {}).get("correlation_id")
│   │   ```
│   │   
│   ├── dependencies.py
│   │   
│   │   ```py
│   │   # File: shared/api/dependencies.py
│   │   
│   │   """
│   │   FastAPI dependencies for standardized API behavior.
│   │   
│   │   Simplified to focus on commonly used dependencies.
│   │   """
│   │   
│   │   from typing import Annotated, Optional
│   │   from fastapi import Query, Request, Depends
│   │   from pydantic import BaseModel, Field
│   │   from .correlation import get_correlation_id
│   │   
│   │   
│   │   class PaginationParams(BaseModel):
│   │       """Standard pagination parameters."""
│   │       
│   │       page: int = Field(default=1, ge=1)
│   │       limit: int = Field(default=50, ge=1, le=1000)
│   │       
│   │       @property
│   │       def offset(self) -> int:
│   │           """Calculate offset for database queries."""
│   │           return (self.page - 1) * self.limit
│   │   
│   │   
│   │   def get_pagination_params(
│   │       page: int = Query(1, ge=1, description="Page number"),
│   │       limit: int = Query(50, ge=1, le=1000, description="Items per page")
│   │   ) -> PaginationParams:
│   │       """
│   │       FastAPI dependency for pagination parameters.
│   │       
│   │       Usage:
│   │           @app.get("/items")
│   │           async def list_items(pagination: PaginationDep):
│   │               items = await db.query(offset=pagination.offset, limit=pagination.limit)
│   │       """
│   │       return PaginationParams(page=page, limit=limit)
│   │   
│   │   
│   │   def get_request_id(request: Request) -> str:
│   │       """
│   │       Get request ID from middleware-set state.
│   │       
│   │       Raises error if middleware hasn't run, ensuring proper initialization.
│   │       """
│   │       if not hasattr(request.state, "request_id"):
│   │           raise RuntimeError(
│   │               "Request ID not found. Ensure APIMiddleware is properly configured."
│   │           )
│   │       return request.state.request_id
│   │   
│   │   def get_client_ip(request: Request) -> str:
│   │       """
│   │       Extract client IP address.
│   │       Only add if needed for rate limiting or security.
│   │       """
│   │       forwarded_for = request.headers.get("X-Forwarded-For")
│   │       if forwarded_for:
│   │           return forwarded_for.split(",")[0].strip()
│   │       return request.client.host if request.client else "unknown"
│   │   
│   │   
│   │   # Type aliases for clean dependency injection
│   │   ClientIpDep = Annotated[str, Depends(get_client_ip)]
│   │   RequestIdDep = Annotated[str, Depends(get_request_id)]
│   │   PaginationDep = Annotated[PaginationParams, Depends(get_pagination_params)]
│   │   CorrelationIdDep = Annotated[str, Depends(get_correlation_id)]  # Re-export for convenience
│   │   
│   │   
│   │   # Optional: Simplified request context for logging
│   │   class RequestContext(BaseModel):
│   │       """Essential request context for logging/auditing."""
│   │       
│   │       request_id: str
│   │       correlation_id: str
│   │       method: str
│   │       path: str
│   │       ip_client: Optional[str] = None  # Optional client IP for rate limiting/security
│   │       
│   │       @classmethod
│   │       def from_request(cls, request: Request) -> "RequestContext":
│   │           """Create context from FastAPI request."""
│   │           return cls(
│   │               request_id=get_request_id(request),
│   │               correlation_id=get_correlation_id(request),
│   │               method=request.method,
│   │               path=str(request.url.path),
│   │               ip_client=get_client_ip(request)  # Optional: Add client IP if needed
│   │           )
│   │   
│   │   
│   │   def get_request_context(request: Request) -> RequestContext:
│   │       """Get essential request context."""
│   │       return RequestContext.from_request(request)
│   │   
│   │   
│   │   RequestContextDep = Annotated[RequestContext, Depends(get_request_context)]
│   │   
│   │   ```
│   │   
│   ├── health.py
│   │   
│   │   ```py
│   │   # glam-app/shared/api/health.py
│   │   
│   │   from fastapi import APIRouter, Request
│   │   from datetime import datetime, timezone
│   │   from shared.api.responses import success_response
│   │   
│   │   
│   │   def create_health_router(service_name: str) -> APIRouter:
│   │       router = APIRouter()
│   │   
│   │       @router.get("/health", tags=["Health"])
│   │       async def health_check(request: Request):
│   │           """Basic health check endpoint with service name and timestamp"""
│   │           return success_response(
│   │               data={
│   │                   "status": "healthy",
│   │                   "service": service_name,
│   │                   "timestamp": datetime.now(timezone.utc).isoformat(),
│   │               },
│   │               request_id=getattr(request.state, "request_id", None),
│   │               correlation_id=getattr(request.state, "correlation_id", None),
│   │           )
│   │   
│   │       return router
│   │   ```
│   │   
│   ├── middleware.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/api/middleware.py
│   │   # -------------------------------
│   │   
│   │   """Simplified API middleware."""
│   │   
│   │   import time
│   │   import uuid
│   │   import logging
│   │   from typing import Callable
│   │   
│   │   from fastapi import Request, Response
│   │   from fastapi import FastAPI
│   │   from fastapi.responses import JSONResponse
│   │   from starlette.middleware.base import BaseHTTPMiddleware
│   │   from fastapi.exceptions import RequestValidationError, HTTPException
│   │   
│   │   from shared.utils.exceptions import GlamBaseError
│   │   from ..metrics import PrometheusMiddleware, metrics_endpoint
│   │   
│   │   from .responses import error_response
│   │   from .correlation import get_correlation_id, set_correlation_context
│   │   
│   │   logger = logging.getLogger(__name__)
│   │   
│   │   
│   │   class APIMiddleware(BaseHTTPMiddleware):
│   │       """Unified middleware for request/response handling."""
│   │       
│   │       def __init__(self, app, *, service_name: str = "glam-service"):
│   │           super().__init__(app)
│   │           self.service_name = service_name
│   │       
│   │       async def dispatch(self, request: Request, call_next: Callable) -> Response:
│   │           # Generate IDs
│   │           request_id = request.headers.get("X-Request-ID", f"req_{uuid.uuid4().hex[:12]}")
│   │           
│   │           # Get correlation ID (this will check headers and generate if needed)
│   │           correlation_id = get_correlation_id(request)
│   │           
│   │           # Store in request state for easy access in the request
│   │           request.state.request_id = request_id
│   │           request.state.correlation_id = correlation_id
│   │           
│   │           # IMPORTANT: Set correlation context for async operations
│   │           # This makes correlation_id available throughout the request lifecycle
│   │           set_correlation_context(correlation_id)
│   │           
│   │           # Track timing
│   │           start_time = time.perf_counter()
│   │           
│   │           try:
│   │               response = await call_next(request)
│   │               
│   │               # Add standard headers
│   │               response.headers["X-Request-ID"] = request_id
│   │               response.headers["X-Correlation-ID"] = correlation_id
│   │               response.headers["X-Service-Name"] = self.service_name
│   │               
│   │               return response
│   │               
│   │           except Exception as exc:
│   │               # Convert to standard error response
│   │               error_resp = self._handle_exception(exc, request_id, correlation_id)
│   │               
│   │               # Determine status code
│   │               status_code = 500
│   │               if isinstance(exc, GlamBaseError):
│   │                   status_code = exc.status
│   │               elif isinstance(exc, HTTPException):
│   │                   status_code = exc.status_code
│   │               elif isinstance(exc, RequestValidationError):
│   │                   status_code = 422
│   │               
│   │               # Log error
│   │               duration_ms = (time.perf_counter() - start_time) * 1000
│   │               logger.error(
│   │                   "Request failed",
│   │                   extra={
│   │                       "request_id": request_id,
│   │                       "correlation_id": correlation_id,
│   │                       "method": request.method,
│   │                       "path": request.url.path,
│   │                       "status": status_code,
│   │                       "duration_ms": round(duration_ms, 2),
│   │                       "error_code": error_resp.error.code if error_resp.error else "UNKNOWN",
│   │                       "service": self.service_name
│   │                   }
│   │               )
│   │               
│   │               response = JSONResponse(
│   │                   content=error_resp.model_dump(mode="json", exclude_none=True),
│   │                   status_code=status_code
│   │               )
│   │               
│   │               # Add standard headers
│   │               response.headers["X-Request-ID"] = request_id
│   │               response.headers["X-Correlation-ID"] = correlation_id
│   │               response.headers["X-Service-Name"] = self.service_name
│   │               
│   │               return response
│   │       
│   │       def _handle_exception(self, exc: Exception, request_id: str, correlation_id: str):
│   │           """Convert exception to error response."""
│   │           
│   │           if isinstance(exc, GlamBaseError):
│   │               return error_response(
│   │                   code=exc.code,
│   │                   message=exc.message,
│   │                   details=exc.details,
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │           
│   │           elif isinstance(exc, RequestValidationError):
│   │               validation_errors = []
│   │               for error in exc.errors():
│   │                   field_path = ".".join(str(loc) for loc in error["loc"])
│   │                   validation_errors.append({
│   │                       "field": field_path,
│   │                       "message": error["msg"],
│   │                       "type": error["type"]
│   │                   })
│   │               
│   │               return error_response(
│   │                   code="VALIDATION_ERROR",
│   │                   message="Request validation failed",
│   │                   details={"validation_errors": validation_errors},
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │           
│   │           elif isinstance(exc, HTTPException):
│   │               return error_response(
│   │                   code=f"HTTP_{exc.status_code}",
│   │                   message=exc.detail,
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │           
│   │           else:
│   │               logger.exception(
│   │                   "Unhandled exception",
│   │                   extra={
│   │                       "request_id": request_id,
│   │                       "correlation_id": correlation_id,
│   │                       "error_type": type(exc).__name__
│   │                   }
│   │               )
│   │               
│   │               return error_response(
│   │                   code="INTERNAL_ERROR",
│   │                   message="An unexpected error occurred",
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │   
│   │   
│   │   def setup_middleware(
│   │       app: FastAPI,
│   │       *,
│   │       service_name: str,
│   │       enable_metrics: bool = True,
│   │       metrics_path: str = "/metrics",
│   │   ):
│   │       """
│   │       Set up all standard middleware for a service.
│   │       
│   │       This sets up middleware in the correct order:
│   │       1. Prometheus metrics (if enabled) - captures all requests
│   │       2. API middleware - handles responses and errors
│   │       
│   │       Args:
│   │           app: FastAPI application
│   │           service_name: Name of the service
│   │           enable_metrics: Whether to enable Prometheus metrics
│   │           metrics_path: Path for metrics endpoint
│   │           debug: Whether to include error details in responses
│   │       """
│   │       # Add Prometheus middleware FIRST (captures all requests)
│   │       if enable_metrics:
│   │           app.add_middleware(PrometheusMiddleware, service_name=service_name)
│   │           
│   │           # Add metrics endpoint
│   │           app.add_api_route(
│   │               metrics_path,
│   │               metrics_endpoint,
│   │               methods=["GET"],
│   │               include_in_schema=False,
│   │               tags=["monitoring"]
│   │           )
│   │   
│   │       # Add API middleware for standardized responses
│   │       app.add_middleware(APIMiddleware, service_name=service_name)
│   │   ```
│   │   
│   ├── models.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/api/models.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Unified API response models for glam-app services.
│   │   Consolidates all response structures into a single, consistent pattern.
│   │   """
│   │   
│   │   from typing import TypeVar, Generic, Optional, Any, Dict, List
│   │   from datetime import datetime, timezone
│   │   from pydantic import BaseModel, Field, ConfigDict
│   │   import uuid
│   │   
│   │   # Generic type for response data
│   │   T = TypeVar("T")
│   │   
│   │   
│   │   class Meta(BaseModel):
│   │       """Metadata included in all responses."""
│   │       request_id: str = Field(description="Unique request identifier")
│   │       correlation_id: Optional[str] = Field(None, description="Distributed tracing ID")
│   │       timestamp: datetime = Field(
│   │           default_factory=lambda: datetime.now(timezone.utc),
│   │           description="Response timestamp in UTC"
│   │       )
│   │       
│   │       model_config = ConfigDict(
│   │           json_encoders={datetime: lambda v: v.isoformat()}
│   │       )
│   │   
│   │   
│   │   class Pagination(BaseModel):
│   │       """Pagination metadata for list responses."""
│   │       page: int = Field(ge=1)
│   │       limit: int = Field(ge=1, le=1000)
│   │       total: int = Field(ge=0)
│   │       pages: int = Field(ge=0)
│   │       has_next: bool
│   │       has_previous: bool
│   │       
│   │       @classmethod
│   │       def create(cls, page: int, limit: int, total: int) -> "Pagination":
│   │           """Create pagination from parameters."""
│   │           pages = (total + limit - 1) // limit if total > 0 else 0
│   │           return cls(
│   │               page=page,
│   │               limit=limit,
│   │               total=total,
│   │               pages=pages,
│   │               has_next=page < pages,
│   │               has_previous=page > 1
│   │           )
│   │   
│   │   
│   │   class Links(BaseModel):
│   │       """HATEOAS links for resource navigation."""
│   │       self: str
│   │       next: Optional[str] = None
│   │       previous: Optional[str] = None
│   │       first: Optional[str] = None
│   │       last: Optional[str] = None
│   │       
│   │       @classmethod
│   │       def create_paginated(
│   │           cls, 
│   │           base_url: str, 
│   │           page: int, 
│   │           limit: int, 
│   │           pages: int,
│   │           **query_params
│   │       ) -> "Links":
│   │           """Create pagination links."""
│   │           def build_url(page_num: int) -> str:
│   │               params = {**query_params, "page": page_num, "limit": limit}
│   │               query = "&".join(f"{k}={v}" for k, v in params.items())
│   │               return f"{base_url}?{query}"
│   │           
│   │           return cls(
│   │               self=build_url(page),
│   │               next=build_url(page + 1) if page < pages else None,
│   │               previous=build_url(page - 1) if page > 1 else None,
│   │               first=build_url(1) if pages > 0 else None,
│   │               last=build_url(pages) if pages > 0 else None
│   │           )
│   │   
│   │   
│   │   class ErrorDetail(BaseModel):
│   │       """Error information."""
│   │       code: str
│   │       message: str
│   │       details: Optional[Dict[str, Any]] = None
│   │   
│   │   
│   │   class ApiResponse(BaseModel, Generic[T]):
│   │       """
│   │       Unified API response structure.
│   │       Used for both success and error responses.
│   │       """
│   │       # For success responses
│   │       data: Optional[T] = None
│   │       
│   │       # For error responses
│   │       error: Optional[ErrorDetail] = None
│   │       
│   │       # Always present
│   │       meta: Meta
│   │       
│   │       # Optional for paginated responses
│   │       pagination: Optional[Pagination] = None
│   │       links: Optional[Links] = None
│   │       
│   │       model_config = ConfigDict(
│   │           json_encoders={datetime: lambda v: v.isoformat()}
│   │       )
│   │   ```
│   │   
│   └── responses.py
│       
│       ```py
│       # -------------------------------
│       # shared/api/responses.py
│       # -------------------------------
│       
│       """Response helper functions."""
│       
│       from typing import Optional, Dict, Any, List, Tuple
│       import uuid
│       from .models import ApiResponse, Meta, ErrorDetail, Pagination, Links, T
│       
│       
│       def create_response(
│           data: Optional[T] = None,
│           error: Optional[ErrorDetail] = None,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None,
│           pagination: Optional[Pagination] = None,
│           links: Optional[Links] = None
│       ) -> ApiResponse[T]:
│           """Create a unified API response."""
│           if request_id is None:
│               request_id = f"req_{uuid.uuid4().hex[:12]}"
│           
│           meta = Meta(request_id=request_id, correlation_id=correlation_id)
│           
│           return ApiResponse(
│               data=data,
│               error=error,
│               meta=meta,
│               pagination=pagination,
│               links=links
│           )
│       
│       
│       def success_response(
│           data: T,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None,
│           links: Optional[Links] = None
│       ) -> ApiResponse[T]:
│           """Create a success response."""
│           return create_response(
│               data=data,
│               request_id=request_id,
│               correlation_id=correlation_id,
│               links=links
│           )
│       
│       
│       def error_response(
│           code: str,
│           message: str,
│           details: Optional[Dict[str, Any]] = None,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None
│       ) -> ApiResponse[None]:
│           """Create an error response."""
│           error = ErrorDetail(code=code, message=message, details=details)
│           return create_response(
│               error=error,
│               request_id=request_id,
│               correlation_id=correlation_id
│           )
│       
│       
│       def paginated_response(
│           data: List[T],
│           page: int,
│           limit: int,
│           total: int,
│           base_url: str,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None,
│           **query_params
│       ) -> ApiResponse[List[T]]:
│           """Create a paginated response."""
│           pagination = Pagination.create(page, limit, total)
│           links = Links.create_paginated(base_url, page, limit, pagination.pages, **query_params)
│           
│           return create_response(
│               data=data,
│               request_id=request_id,
│               correlation_id=correlation_id,
│               pagination=pagination,
│               links=links
│           )
│       ```
│       
├── messaging/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   # shared/messaging/__init__.py
│   │   """Shared messaging module for publisher, subscriber, event context, stream client, subject, and payloads."""
│   │   
│   │   from .publisher import Publisher
│   │   from .listener import Listener 
│   │   
│   │   from .jetstream_client import JetStreamClient
│   │   from .stream_config import StreamConfig
│   │   from .subjects import Subjects
│   │   from .common_payloads import (
│   │       MerchantCreatedPayload,
│   │       WebhookReceivedPayload,
│   │   )
│   │   
│   │   __all__ = [
│   │       "Publisher",
│   │       "Listener",
│   │       "JetStreamClient",
│   │       "StreamConfig",
│   │       "Subjects",
│   │       "MerchantCreatedPayload",
│   │       "WebhookReceivedPayload",
│   │   ]
│   │   ```
│   │   
│   ├── common_payloads.py
│   │   
│   │   ```py
│   │   # shared/messaging/payloads/common.py
│   │   
│   │   from pydantic import BaseModel, Field, EmailStr
│   │   from typing import Dict, Any
│   │   from uuid import UUID
│   │   from datetime import datetime, timezone
│   │   from enum import Enum
│   │   
│   │   class ExternalSource(str, Enum):
│   │       SHOPIFY="shopify"
│   │       STRIPE="stripe"
│   │   
│   │   class MerchantCreatedPayload(BaseModel):
│   │       """Merchant created event payload"""
│   │       merchant_id: UUID
│   │       merchant_domain: str
│   │       business_name: str
│   │       contact_email: EmailStr
│   │       created_by: str
│   │       created_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
│   │       
│   │       
│   │   class WebhookReceivedPayload(BaseModel):
│   │       """Webhook received - published by webhook service, consumed by others"""
│   │       webhook_id: UUID
│   │       merchant_id: UUID
│   │       source: ExternalSource
│   │       event_type: str
│   │       payload: Dict[str, Any]
│   │       received_at: datetime = Field(default_factory=lambda: datetime.now(timezone.utc))
│   │       verified: bool = True
│   │   ```
│   │   
│   ├── jetstream_client.py
│   │   
│   │   ```py
│   │   # shared/shared/messaging/jetstream_client.py
│   │   """Pure JetStream client - only connection + stream management.
│   │   """
│   │   
│   │   import os
│   │   from typing import List, Optional
│   │   
│   │   import nats
│   │   from nats.aio.client import Client
│   │   from nats.js import JetStreamContext
│   │   from nats.js.api import StreamConfig, RetentionPolicy, StorageType
│   │   from nats.js.errors import NotFoundError
│   │   
│   │   from shared.utils.logger import ServiceLogger
│   │   
│   │   
│   │   class JetStreamClient:
│   │       """Pure JetStream client - only connection + stream management."""
│   │   
│   │       def __init__(self, logger: Optional[ServiceLogger] = None) -> None:  # ✔ typed
│   │           self._client: Optional[Client] = None
│   │           self._js: Optional[JetStreamContext] = None
│   │           self.logger = logger
│   │   
│   │       # context-manager helpers --------------------------------------------------
│   │       async def __aenter__(self): return self
│   │       async def __aexit__(self, exc_t, exc, tb): await self.close()
│   │   
│   │       # public accessors ---------------------------------------------------------
│   │       @property
│   │       def client(self) -> Client:
│   │           if not self._client:
│   │               raise RuntimeError("NATS client not connected")
│   │           return self._client
│   │   
│   │       @property
│   │       def js(self) -> JetStreamContext:
│   │           if not self._js:
│   │               raise RuntimeError("JetStream not initialized")
│   │           return self._js
│   │   
│   │       # connection ---------------------------------------------------------------
│   │       async def connect(self, servers: List[str]) -> None:
│   │           opts = {
│   │               "servers": servers,
│   │               "max_reconnect_attempts": -1,
│   │               "reconnect_time_wait": 2,
│   │           }
│   │           if user := os.getenv("NATS_USER"):
│   │               opts.update(user=user, password=os.getenv("NATS_PASSWORD", ""))
│   │   
│   │           self._client = await nats.connect(**opts)
│   │           self._js = self._client.jetstream()
│   │           if self.logger:
│   │               self.logger.info("Connected to NATS %s", servers)
│   │   
│   │       async def close(self) -> None:
│   │           if self._client and not self._client.is_closed:
│   │               await self._client.close()
│   │               if self.logger:
│   │                   self.logger.info("NATS connection closed")
│   │   
│   │       def is_connected(self) -> bool:
│   │           return bool(self._client and self._client.is_connected)
│   │   
│   │       # stream helpers -----------------------------------------------------------
│   │       async def ensure_stream(
│   │           self,
│   │           name: str,
│   │           subjects: List[str],
│   │           **kw,
│   │       ) -> None:
│   │           if not self._js:
│   │               raise RuntimeError("JetStream not initialized")
│   │   
│   │           cfg = StreamConfig(
│   │               name=name,
│   │               subjects=subjects,
│   │               retention=kw.get("retention", RetentionPolicy.LIMITS),
│   │               max_age=kw.get("max_age", 24 * 60 * 60),
│   │               max_msgs=kw.get("max_msgs", 1_000_000),
│   │               storage=kw.get("storage", StorageType.FILE),
│   │           )
│   │   
│   │           try:
│   │               await self._js.stream_info(name)
│   │               if self.logger:
│   │                   self.logger.debug("Using existing stream: %s", name)
│   │           except NotFoundError:                       # ← only when it’s absent
│   │               await self._js.add_stream(cfg)
│   │               if self.logger:
│   │                   self.logger.info("Created new stream: %s", name)
│   │   
│   │       async def delete_stream(self, name: str) -> None:
│   │           if not self._js:
│   │               raise RuntimeError("JetStream not initialized")
│   │           await self._js.delete_stream(name)
│   │           if self.logger:
│   │               self.logger.info("Deleted stream: %s", name)
│   │   
│   │       async def get_stream_info(self, name: str) -> dict:
│   │           if not self._js:
│   │               raise RuntimeError("JetStream not initialized")
│   │           info = await self._js.stream_info(name)
│   │           return {
│   │               "name": info.config.name,
│   │               "subjects": info.config.subjects,
│   │               "messages": info.state.messages,
│   │               "bytes": info.state.bytes,
│   │           }
│   │   ```
│   │   
│   ├── listener.py
│   │   
│   │   ```py
│   │   # shared/messaging/js_listener.py
│   │   """A thin, “safe” JetStream listener with JSON decode guard and error handling."""
│   │   
│   │   import asyncio, json
│   │   from abc import ABC, abstractmethod
│   │   from typing import Any, Dict, Optional
│   │   
│   │   from nats.js.api import AckPolicy, ConsumerConfig, DeliverPolicy
│   │   from nats.js.errors import NotFoundError
│   │   
│   │   from shared.utils.logger import ServiceLogger
│   │   from .jetstream_client import JetStreamClient
│   │   from .event_context import set_correlation_id, set_source_service
│   │   
│   │   
│   │   class Listener(ABC):
│   │       """
│   │       A thin, “safe” JetStream listener:
│   │       • one subject
│   │       • JSON decode guard
│   │       • soft-fail vs. hard-fail error handling
│   │       """
│   │       
│   │       stream_name: str = "GLAM_EVENTS"
│   │       batch_size: int = 10
│   │       ack_wait_sec: int = 30
│   │       max_deliver: int = 3
│   │   
│   │       # ---- subclasses MUST fill these --------------------------------------
│   │       @property
│   │       @abstractmethod
│   │       def service_name(self) -> str:
│   │           """Name of the owning micro-service (used for durable name)."""
│   │           pass
│   │   
│   │       @property
│   │       @abstractmethod
│   │       def subject(self) -> str:
│   │           """Full NATS subject to consume, e.g. ``evt.email.sent.v1``."""
│   │           pass
│   │   
│   │       @property
│   │       @abstractmethod
│   │       def queue_group(self) -> str:
│   │           """Queue group so replicas share the workload."""
│   │           pass
│   │   
│   │       # ----------------------------------------------------------------------
│   │       def __init__(self, js_client: JetStreamClient, logger: ServiceLogger) -> None:
│   │           self._js = js_client.js
│   │           self.logger = logger
│   │           self._sub = None
│   │   
│   │       # ======================================================================
│   │       # public API
│   │       # ======================================================================
│   │       async def start(self) -> None:
│   │           await self._ensure_stream()
│   │           await self._ensure_consumer()
│   │           await self._create_subscription()
│   │           self.logger.info("Listening on %s", self.subject)
│   │           asyncio.create_task(self._poll_loop())
│   │   
│   │       async def stop(self) -> None:
│   │           if self._sub:
│   │               await self._sub.unsubscribe()
│   │   
│   │       # ======================================================================
│   │       # override in subclasses
│   │       # ======================================================================
│   │       @abstractmethod
│   │       async def on_message(self, data: Dict[str, Any]) -> None: ...
│   │   
│   │       # ======================================================================
│   │       # internals
│   │       # ======================================================================
│   │       # stream
│   │       async def _ensure_stream(self) -> None:
│   │           """Stream must exist and cover ``evt.*`` **and** ``cmd.*``."""
│   │           from nats.js.api import RetentionPolicy, StorageType, StreamConfig  # local to avoid circulars
│   │   
│   │           try:
│   │               await self._js.stream_info(self.stream_name)
│   │           except NotFoundError:
│   │               cfg = StreamConfig(
│   │                   name=self.stream_name,
│   │                   subjects=["evt.*", "cmd.*"],
│   │                   retention=RetentionPolicy.LIMITS,
│   │                   max_age=24 * 60 * 60,
│   │                   max_msgs=1_000_000,
│   │                   storage=StorageType.FILE,
│   │               )
│   │               await self._js.add_stream(cfg)
│   │               self.logger.info("Created stream %s", self.stream_name)
│   │           
│   │   
│   │       # consumer
│   │       async def _ensure_consumer(self) -> None:
│   │           durable = f"{self.service_name}-{self.queue_group}"
│   │           try:
│   │               await self._js.consumer_info(self.stream_name, durable)
│   │           except NotFoundError:
│   │               cfg = ConsumerConfig(
│   │                   durable_name=durable,
│   │                   deliver_policy=DeliverPolicy.ALL,
│   │                   ack_policy=AckPolicy.EXPLICIT,
│   │                   max_deliver=self.max_deliver,
│   │                   ack_wait=self.ack_wait_sec,
│   │                   filter_subject=self.subject,
│   │               )
│   │               await self._js.add_consumer(self.stream_name, cfg)
│   │   
│   │       # subscription
│   │       async def _create_subscription(self) -> None:
│   │           self._sub = await self._js.pull_subscribe(
│   │               self.subject,
│   │               durable=f"{self.service_name}-{self.queue_group}",
│   │               stream=self.stream_name,
│   │           )
│   │   
│   │       # polling loop
│   │       async def _poll_loop(self) -> None:
│   │           while True:
│   │               if not self._sub:
│   │                   self.logger.error("Subscription not initialized, skipping poll")
│   │                   await asyncio.sleep(1)
│   │                   continue
│   │               msgs = await self._sub.fetch(batch=10, timeout=1)
│   │               for m in msgs:
│   │                   await self._safe_handle(m)
│   │   
│   │       # safe handler
│   │       async def _safe_handle(self, msg) -> None:
│   │           try:
│   │               envelope = json.loads(msg.data.decode())
│   │           except json.JSONDecodeError:
│   │               self.logger.error("Bad JSON on %s", self.subject)
│   │               await msg.ack()
│   │               return
│   │   
│   │           # Envelope sanity
│   │           for f in ("event_id", "event_type", "data"):
│   │               if f not in envelope:
│   │                   self.logger.error("Missing %s; acking", f)
│   │                   await msg.ack()
│   │                   return
│   │           if envelope["event_type"] != self.subject.split(".", 1)[-1]:
│   │               await msg.ack()
│   │               return
│   │   
│   │           # Context vars
│   │           set_correlation_id(envelope.get("correlation_id"))
│   │           set_source_service(envelope.get("source_service"))
│   │   
│   │           # Business logic
│   │           try:
│   │               await self.on_message(envelope["data"])
│   │               await msg.ack()
│   │           except Exception as exc:
│   │               should_ack = await self.on_error(exc, envelope["data"])
│   │               await (msg.ack() if should_ack else msg.nack())
│   │   
│   │       # default hook
│   │       async def on_error(self, error: Exception, data: dict) -> bool:
│   │           self.logger.error("Error on %s: %s", self.subject, error, exc_info=True)
│   │           return False
│   │   ```
│   │   
│   ├── publisher.py
│   │   
│   │   ```py
│   │   # shared/shared/messaging/publisher.py
│   │   """Publisher base class for domain events and commands."""
│   │   import json
│   │   from abc import ABC, abstractmethod
│   │   from datetime import datetime, timezone
│   │   from typing import Dict, Optional, TypeVar
│   │   from uuid import uuid4
│   │   
│   │   from shared.utils.logger import ServiceLogger
│   │   from .event_context import get_correlation_id
│   │   from .jetstream_client import JetStreamClient
│   │   
│   │   DataT = TypeVar("DataT")
│   │   
│   │   
│   │   class Publisher(ABC):
│   │       """Publishes domain facts (evt.*) - commands to be added when needed."""
│   │   
│   │       @property
│   │       @abstractmethod
│   │       def service_name(self) -> str: ...
│   │       
│   │       def __init__(self, jetstream_client: JetStreamClient, logger: ServiceLogger) -> None:
│   │           self.js_client = jetstream_client
│   │           self.logger = logger
│   │           self._stream_ready = False
│   │   
│   │       # ────────────────────────────────────────────────────────────────────────
│   │       async def _ensure_stream(self) -> None:
│   │           if self._stream_ready:
│   │               return
│   │           await self.js_client.ensure_stream(
│   │               name="GLAM_EVENTS",
│   │               subjects=["evt.*", "cmd.*"],
│   │               max_age=24 * 60 * 60,
│   │               max_msgs=1_000_000,
│   │           )
│   │           self._stream_ready = True
│   │   
│   │       # ────────────────────────────────────────────────────────────────────────
│   │       async def publish_event(
│   │           self,
│   │           subject: str,
│   │           data: dict,
│   │           correlation_id: Optional[str] = None,
│   │           metadata: Optional[Dict[str, dict]] = None,
│   │       ) -> str:
│   │           
│   │           if not (subject.startswith("evt.") or subject.startswith("cmd.")):
│   │               raise ValueError("subject must start with 'evt.' or 'cmd.'")
│   │           
│   │           
│   │           await self._ensure_stream()
│   │   
│   │           event_id = str(uuid4())
│   │           correlation_id = correlation_id or get_correlation_id()
│   │           
│   │   
│   │           envelope = {
│   │               "event_id": event_id,
│   │               "event_type": subject,
│   │               "correlation_id": correlation_id,
│   │               "timestamp": datetime.now(timezone.utc).isoformat(),
│   │               "source_service": self.service_name,
│   │               "data": data,
│   │               "metadata": metadata or {},
│   │           }
│   │   
│   │   
│   │           await self.js_client.js.publish(subject, json.dumps(envelope).encode())
│   │           self.logger.info("Published %s [%s]", subject, event_id)
│   │           return event_id
│   │   ```
│   │   
│   ├── stream_config.py
│   │   
│   │   ```py
│   │   # shared/messaging/streams/stream_config.py
│   │   
│   │   from enum import Enum
│   │   from dataclasses import dataclass
│   │   from typing import List
│   │   
│   │   class Streams(str, Enum):
│   │       """NATS JetStream streams for GLAM"""
│   │       EVENTS = "GLAM_EVENTS"  # Single stream for MVP
│   │       DLQ = "GLAM_DLQ"       # Dead letter queue
│   │   
│   │   
│   │   @dataclass
│   │   class StreamConfig:
│   │       """Stream configuration"""
│   │       name: str
│   │       subjects: List[str]
│   │       max_age_hours: int = 24
│   │       max_msgs: int = 1000000
│   │   
│   │   
│   │   # MVP Stream configuration
│   │   STREAM_CONFIGS = [
│   │       StreamConfig(
│   │           name=Streams.EVENTS,
│   │           subjects=["evt.*", "cmd.*"],
│   │           max_age_hours=24,
│   │           max_msgs=1000000,
│   │       ),
│   │       StreamConfig(
│   │           name=Streams.DLQ,
│   │           subjects=["dlq.*"],
│   │           max_age_hours=168,  # 7 days
│   │           max_msgs=100000,
│   │       )
│   │   ]
│   │   ```
│   │   
│   └── subjects.py
│       
│       ```py
│       # shared/shared/messaging/subjects.py
│       """NATS subjects for microservices."""
│       
│       from enum import Enum
│       
│       class Subjects(str, Enum):
│           """NATS subjects for the notification service"""
│           EMAIL_SEND_REQUESTED = "cmd.email.send.requested.v1"
│           EMAIL_SEND_COMPLETE = "evt.email.send.complete.v1"
│           EMAIL_SEND_FAILED = "evt.email.send.failed.v1"
│           EMAIL_SEND_BOUNCED = "evt.email.send.bounced.v1"
│           EMAIL_SEND_BULK_REQUESTED = "cmd.email.send.bulk.requested.v1"
│           EMAIL_SEND_BULK_STARTED = "evt.email.send.bulk.started.v1"
│           EMAIL_SEND_BULK_COMPLETE = "evt.email.send.bulk.complete.v1"
│           EMAIL_SEND_BULK_FAILED = "evt.email.send.bulk.failed.v1"
│           
│       ```
│       
├── metrics/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   
│   │   # -------------------------------
│   │   # shared/metrics/__init__.py
│   │   # -------------------------------
│   │   
│   │   """Prometheus metrics utilities for microservices."""
│   │   
│   │   from .middleware import (
│   │       PrometheusMiddleware,
│   │       metrics_endpoint,
│   │       http_requests_total,
│   │       http_request_duration_seconds,
│   │       http_requests_in_progress,
│   │   )
│   │   
│   │   __all__ = [
│   │       "PrometheusMiddleware",
│   │       "metrics_endpoint",
│   │       "http_requests_total",
│   │       "http_request_duration_seconds",
│   │       "http_requests_in_progress",
│   │   ]
│   │   ```
│   │   
│   └── middleware.py
│       
│       ```py
│       # -------------------------------
│       # shared/metrics/middleware.py
│       # -------------------------------
│       
│       """
│       Prometheus metrics middleware for all services.
│       
│       Provides standard HTTP metrics and allows services to register
│       their own domain-specific metrics.
│       """
│       
│       import time
│       import re
│       from fastapi import Request
│       from starlette.middleware.base import BaseHTTPMiddleware
│       from starlette.responses import Response
│       from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
│       
│       # Standard HTTP metrics for all services
│       http_requests_total = Counter(
│           'http_requests_total',
│           'Total HTTP requests',
│           ['service', 'method', 'endpoint', 'status']
│       )
│       
│       http_request_duration_seconds = Histogram(
│           'http_request_duration_seconds',
│           'HTTP request duration in seconds',
│           ['service', 'method', 'endpoint']
│       )
│       
│       http_requests_in_progress = Gauge(
│           'http_requests_in_progress',
│           'HTTP requests in progress',
│           ['service']
│       )
│       
│       
│       class PrometheusMiddleware(BaseHTTPMiddleware):
│           """Prometheus metrics collection middleware."""
│           
│           def __init__(self, app, service_name: str):
│               super().__init__(app)
│               self.service_name = service_name
│           
│           async def dispatch(self, request: Request, call_next):
│               # Skip metrics endpoint to avoid recursion
│               if request.url.path == "/metrics":
│                   return await call_next(request)
│               
│               # Get method and normalize path
│               method = request.method
│               path = self._normalize_path(request.url.path)
│               
│               # Track in-progress requests
│               http_requests_in_progress.labels(service=self.service_name).inc()
│               
│               # Time the request
│               start_time = time.time()
│               
│               try:
│                   response = await call_next(request)
│                   status_code = response.status_code
│                   
│                   # Record success metrics
│                   self._record_metrics(method, path, status_code, start_time)
│                   
│                   return response
│                   
│               except Exception as e:
│                   # Record failure metrics
│                   self._record_metrics(method, path, 500, start_time)
│                   raise
│               finally:
│                   http_requests_in_progress.labels(service=self.service_name).dec()
│           
│           def _record_metrics(self, method: str, path: str, status: int, start_time: float):
│               """Record HTTP metrics."""
│               http_requests_total.labels(
│                   service=self.service_name,
│                   method=method,
│                   endpoint=path,
│                   status=status
│               ).inc()
│               
│               http_request_duration_seconds.labels(
│                   service=self.service_name,
│                   method=method,
│                   endpoint=path
│               ).observe(time.time() - start_time)
│           
│           def _normalize_path(self, path: str) -> str:
│               """Normalize paths to prevent high cardinality."""
│               # Replace UUIDs
│               path = re.sub(
│                   r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}',
│                   '{id}',
│                   path
│               )
│               # Replace numeric IDs
│               path = re.sub(r'/\d+', '/{id}', path)
│               return path
│       
│       
│       async def metrics_endpoint(request: Request) -> Response:
│           """Endpoint to expose Prometheus metrics."""
│           return Response(
│               content=generate_latest(),
│               media_type=CONTENT_TYPE_LATEST
│           )
│       
│       ```
│       
├── utils/
│   ├── __init__.py
│   ├── config_loader.py
│   │   
│   │   ```py
│   │   # shared/config/loader.py
│   │   from __future__ import annotations
│   │   from pathlib import Path
│   │   from typing import Any, Dict, Iterable
│   │   import os
│   │   import yaml
│   │   from dotenv import dotenv_values
│   │   
│   │   # repo root
│   │   _REPO_ROOT = Path(__file__).resolve()
│   │   while _REPO_ROOT.name != "glam-app":
│   │       if _REPO_ROOT.parent == _REPO_ROOT:
│   │           raise RuntimeError("Unable to locate glam-app root directory")
│   │       _REPO_ROOT = _REPO_ROOT.parent
│   │   
│   │   _CONFIG_DIR = _REPO_ROOT / "config"
│   │   _SHARED_CONFIG = _CONFIG_DIR / "shared.yml"
│   │   _SVC_CFG_DIR = _CONFIG_DIR / "services"
│   │   _SERVICES_DIR = _REPO_ROOT / "services"
│   │   
│   │   def _load_yaml(path: Path) -> Dict[str, Any]:
│   │       if not path.is_file():
│   │           return {}
│   │       with path.open() as f:
│   │           return yaml.safe_load(f) or {}
│   │   
│   │   def _deep_merge(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
│   │       out = a.copy()
│   │       for k, v in b.items():
│   │           if k in out and isinstance(out[k], dict) and isinstance(v, dict):
│   │               out[k] = _deep_merge(out[k], v)
│   │           else:
│   │               out[k] = v
│   │       return out
│   │   
│   │   def _load_service_dotenv(service: str) -> None:
│   │       """Load services/{service}/.env for local runs only. Never override existing env."""
│   │       if os.path.exists("/.dockerenv") or os.getenv("DISABLE_DOTENV") == "1":
│   │           return
│   │       p = _SERVICES_DIR / service / ".env"
│   │       if not p.is_file():
│   │           return
│   │       for k, v in (dotenv_values(p) or {}).items():
│   │           if v is not None and k not in os.environ:
│   │               os.environ[k] = v
│   │   
│   │   def merged_config(
│   │       service: str,
│   │       *,
│   │       passthrough_env: Iterable[str] = ("DATABASE_URL",),
│   │   ) -> Dict[str, Any]:
│   │       """shared.yml < service.yml, plus selected raw env keys (no prefixes)."""
│   │       _load_service_dotenv(service)
│   │   
│   │       cfg = _deep_merge(
│   │           _load_yaml(_SHARED_CONFIG),
│   │           _load_yaml(_SVC_CFG_DIR / f"{service}.yml"),
│   │       )
│   │   
│   │       for k in passthrough_env:
│   │           if k in os.environ and k not in cfg:
│   │               cfg[k] = os.environ[k]
│   │       return cfg
│   │   
│   │   def flatten_config(data: dict, parent_key: str = "", sep: str = ".") -> dict:
│   │       items: list[tuple[str, Any]] = []
│   │       for k, v in data.items():
│   │           nk = f"{parent_key}{sep}{k}" if parent_key else k
│   │           if isinstance(v, dict):
│   │               items.extend(flatten_config(v, nk, sep=sep).items())
│   │           else:
│   │               items.append((nk, v))
│   │       return dict(items)
│   │   ```
│   │   
│   ├── exceptions.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/base.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Base error classes for the glam-app error hierarchy.
│   │   
│   │   This module defines the fundamental error types that all other
│   │   errors inherit from, following a three-tier model:
│   │   1. GlamBaseError - Root of all application errors
│   │   2. InfrastructureError - External system failures
│   │   3. DomainError - Business logic violations
│   │   """
│   │   
│   │   from typing import Any, Dict, Optional
│   │   
│   │   
│   │   class GlamBaseError(Exception):
│   │       """
│   │       Base class for all glam-app errors.
│   │   
│   │       Attributes:
│   │           code: Stable error code for clients (e.g., "VALIDATION_ERROR")
│   │           status: HTTP status code (default 500)
│   │           message: Human-readable error message
│   │           details: Additional error context
│   │           __cause__: Original exception if wrapped
│   │       """
│   │   
│   │       code: str = "INTERNAL_ERROR"
│   │       status: int = 500
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           code: Optional[str] = None,
│   │           status: Optional[int] = None,
│   │           details: Optional[Dict[str, Any]] = None,
│   │           cause: Optional[Exception] = None
│   │       ):
│   │           super().__init__(message)
│   │   
│   │           if code is not None:
│   │               self.code = code
│   │           if status is not None:
│   │               self.status = status
│   │   
│   │           self.message = message
│   │           self.details = details or {}
│   │   
│   │           # Preserve the original exception chain
│   │           if cause is not None:
│   │               self.__cause__ = cause
│   │   
│   │       def to_dict(self) -> Dict[str, Any]:
│   │           """Convert error to dictionary for JSON serialization."""
│   │           result: Dict[str, Any] = {
│   │               "code": self.code,
│   │               "message": self.message,
│   │           }
│   │   
│   │           if self.details:
│   │               result["details"] = self.details
│   │   
│   │           return result
│   │   
│   │   
│   │   class InfrastructureError(GlamBaseError):
│   │       """
│   │       Infrastructure/external system errors.
│   │   
│   │       These are failures in external dependencies like databases,
│   │       APIs, message queues, etc. They may be retryable.
│   │       """
│   │   
│   │       code = "INFRASTRUCTURE_ERROR"
│   │       status = 503  # Service Unavailable
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           service: Optional[str] = None,
│   │           retryable: bool = True,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if service:
│   │               self.details["service"] = service
│   │   
│   │           self.details["retryable"] = retryable
│   │           self.retryable = retryable
│   │   
│   │   
│   │   class DomainError(GlamBaseError):
│   │       """
│   │       Domain/business logic errors.
│   │   
│   │       These represent violations of business rules or invalid
│   │       operations within the application domain.
│   │       """
│   │   
│   │       code = "DOMAIN_ERROR"
│   │       status = 400  # Bad Request
│   │   
│   │   
│   │   # Common domain errors used across services
│   │   
│   │   
│   │   class ValidationError(DomainError):
│   │       """Invalid request data or parameters."""
│   │   
│   │       code = "VALIDATION_ERROR"
│   │       status = 422  # Unprocessable Entity
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           field: Optional[str] = None,
│   │           value: Optional[Any] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if field:
│   │               self.details["field"] = field
│   │           if value is not None:
│   │               self.details["value"] = str(value)
│   │   
│   │   
│   │   class NotFoundError(DomainError):
│   │       """Requested resource not found."""
│   │   
│   │       code = "NOT_FOUND"
│   │       status = 404
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           resource: Optional[str] = None,
│   │           resource_id: Optional[Any] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if resource:
│   │               self.details["resource"] = resource
│   │           if resource_id is not None:
│   │               self.details["resource_id"] = str(resource_id)
│   │   
│   │   
│   │   class ConflictError(DomainError):
│   │       """Operation conflicts with current state."""
│   │   
│   │       code = "CONFLICT"
│   │       status = 409
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           conflicting_resource: Optional[str] = None,
│   │           current_state: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if conflicting_resource:
│   │               self.details["conflicting_resource"] = conflicting_resource
│   │           if current_state:
│   │               self.details["current_state"] = current_state
│   │   
│   │   
│   │   class UnauthorizedError(DomainError):
│   │       """Authentication required or failed."""
│   │   
│   │       code = "UNAUTHORIZED"
│   │       status = 401
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "Authentication required",
│   │           *,
│   │           auth_type: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if auth_type:
│   │               self.details["auth_type"] = auth_type
│   │   
│   │   
│   │   class ForbiddenError(DomainError):
│   │       """Authenticated but insufficient permissions."""
│   │   
│   │       code = "FORBIDDEN"
│   │       status = 403
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "Insufficient permissions",
│   │           *,
│   │           required_permission: Optional[str] = None,
│   │           resource: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if required_permission:
│   │               self.details["required_permission"] = required_permission
│   │           if resource:
│   │               self.details["resource"] = resource
│   │   
│   │   
│   │   class RateLimitedError(DomainError):
│   │       """Too many requests."""
│   │   
│   │       code = "RATE_LIMITED"
│   │       status = 429
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "Rate limit exceeded",
│   │           *,
│   │           limit: Optional[int] = None,
│   │           window: Optional[str] = None,
│   │           retry_after: Optional[int] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if limit:
│   │               self.details["limit"] = limit
│   │           if window:
│   │               self.details["window"] = window
│   │           if retry_after:
│   │               self.details["retry_after"] = retry_after
│   │   
│   │   
│   │   class ServiceUnavailableError(InfrastructureError):
│   │       """Service temporarily unavailable."""
│   │   
│   │       code = "SERVICE_UNAVAILABLE"
│   │       status = 503
│   │   
│   │   
│   │   class RequestTimeoutError(InfrastructureError):
│   │       """Operation timed out."""
│   │   
│   │       code = "TIMEOUT"
│   │       status = 504
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           timeout_seconds: Optional[float] = None,
│   │           operation: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if timeout_seconds:
│   │               self.details["timeout_seconds"] = timeout_seconds
│   │           if operation:
│   │               self.details["operation"] = operation
│   │   
│   │   
│   │   class InternalError(GlamBaseError):
│   │       """Unexpected internal server error."""
│   │   
│   │       code = "INTERNAL_ERROR"
│   │       status = 500
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "An unexpected error occurred",
│   │           *,
│   │           error_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           # Never expose internal details in production
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if error_id:
│   │               self.details["error_id"] = error_id
│   │   ```
│   │   
│   ├── idempotency_key.py
│   │   
│   │   ```py
│   │   # shared/utils/idempotency.py
│   │   """Simple idempotency key generator."""
│   │   
│   │   from typing import Union, Optional
│   │   from uuid import UUID
│   │   
│   │   
│   │   def generate_idempotency_key(
│   │       system: str,
│   │       operation_type: str, 
│   │       identifier: Union[str, int, UUID],
│   │       extra: Optional[str] = None
│   │   ) -> str:
│   │       """
│   │       Generate idempotency key: SYSTEM_OPERATION_ID[_EXTRA]
│   │       
│   │       Examples:
│   │           generate_idempotency_key("SHOPIFY", "ORDER", "123456") 
│   │           → "SHOPIFY_ORDER_123456"
│   │           
│   │           generate_idempotency_key("STRIPE", "PAYMENT", "pi_abc123")
│   │           → "STRIPE_PAYMENT_pi_abc123"
│   │           
│   │           generate_idempotency_key("SHOPIFY", "ORDER", "123", "TESTSTORE")
│   │           → "SHOPIFY_ORDER_123_TESTSTORE"
│   │       """
│   │       # Normalize inputs
│   │       system = str(system).upper().replace('-', '_').replace('.', '_')
│   │       operation_type = str(operation_type).upper().replace('-', '_').replace('.', '_')
│   │       identifier = str(identifier)
│   │       
│   │       # Build key
│   │       parts = [system, operation_type, identifier]
│   │       
│   │       if extra:
│   │           parts.append(str(extra).upper().replace('-', '_').replace('.', '_'))
│   │       
│   │       return '_'.join(parts)
│   │   ```
│   │   
│   ├── logger.py
│   │   
│   │   ```py
│   │   # shared/utils/logger.py
│   │   import logging
│   │   import logging.handlers
│   │   import os
│   │   import json
│   │   from datetime import datetime
│   │   from typing import Dict, Any
│   │   from pathlib import Path
│   │   from contextvars import ContextVar
│   │   
│   │   
│   │   # Context variable for request-scoped data
│   │   request_context: ContextVar[Dict[str, Any]] = ContextVar('request_context', default={})
│   │   
│   │   
│   │   class ServiceLogger:
│   │       """
│   │       Service-specific logger that automatically includes service name and request context.
│   │       """
│   │       
│   │       def __init__(self, service_name: str):
│   │           self.service_name = service_name
│   │           self._setup_logging()
│   │           self._logger = logging.getLogger(service_name)
│   │       
│   │       def _setup_logging(self):
│   │           """Configure logging for this service"""
│   │           env = os.getenv("APP_ENV", "dev").lower()
│   │           log_level = os.getenv("LOG_LEVEL", "INFO").upper()
│   │           print(f"Setting up logger for {self.service_name} in {env} environment with level {log_level}")
│   │           
│   │           # Create logs directory
│   │           Path("logs").mkdir(exist_ok=True)
│   │           
│   │           # Configure formatters based on environment
│   │           if env == "prod":
│   │               formatter = JsonFormatter(self.service_name)
│   │           else:
│   │               formatter = ConsoleFormatter(self.service_name)
│   │           
│   │           # Set up handlers
│   │           console_handler = logging.StreamHandler()
│   │           console_handler.setFormatter(formatter)
│   │           console_handler.setLevel(log_level)
│   │           
│   │           # Configure the service logger
│   │           logger = logging.getLogger(self.service_name)
│   │           logger.setLevel(log_level)
│   │           logger.addHandler(console_handler)
│   │           
│   │           # Add file handler for production
│   │           if env == "prod":
│   │               file_handler = logging.handlers.RotatingFileHandler(
│   │                   f"logs/{self.service_name}.log",
│   │                   maxBytes=10485760,  # 10MB
│   │                   backupCount=5,
│   │                   encoding='utf8'
│   │               )
│   │               file_handler.setFormatter(formatter)
│   │               file_handler.setLevel(logging.INFO)
│   │               logger.addHandler(file_handler)
│   │           
│   │           # Prevent propagation to avoid duplicate logs
│   │           logger.propagate = False
│   │       
│   │       def set_request_context(self, **kwargs):
│   │           """Set request-scoped context (e.g., request_id, user_id)"""
│   │           ctx = request_context.get()
│   │           ctx.update(kwargs)
│   │           request_context.set(ctx)
│   │       
│   │       def clear_request_context(self):
│   │           """Clear request context"""
│   │           request_context.set({})
│   │       
│   │       def _log(self, level: int, msg: str, *args, **kwargs):
│   │           """Internal log method that adds context"""
│   │           # Get request context
│   │           ctx = request_context.get()
│   │           
│   │           # Add context to extra
│   │           extra = kwargs.get('extra', {})
│   │           extra.update(ctx)
│   │           kwargs['extra'] = extra
│   │           
│   │           self._logger.log(level, msg, *args, **kwargs)
│   │       
│   │       def debug(self, msg: str, *args, **kwargs):
│   │           self._log(logging.DEBUG, msg, *args, **kwargs)
│   │       
│   │       def info(self, msg: str, *args, **kwargs):
│   │           self._log(logging.INFO, msg, *args, **kwargs)
│   │       
│   │       def warning(self, msg: str, *args, **kwargs):
│   │           self._log(logging.WARNING, msg, *args, **kwargs)
│   │       
│   │       def error(self, msg: str, *args, **kwargs):
│   │           self._log(logging.ERROR, msg, *args, **kwargs)
│   │       
│   │       def critical(self, msg: str, *args, **kwargs):
│   │           self._log(logging.CRITICAL, msg, *args, **kwargs)
│   │   
│   │   
│   │   class ConsoleFormatter(logging.Formatter):
│   │       """Console formatter that includes service name and request context"""
│   │       
│   │       def __init__(self, service_name: str):
│   │           self.service_name = service_name
│   │           super().__init__()
│   │       
│   │       def format(self, record):
│   │           # Build context string from extra fields
│   │           context_parts = []
│   │           request_id = getattr(record, 'request_id', None)
│   │           if request_id is not None:
│   │               context_parts.append(f"request_id={request_id}")
│   │           user_id = getattr(record, 'user_id', None)
│   │           if user_id is not None:
│   │               context_parts.append(f"user_id={user_id}")
│   │           
│   │           # Add any other extra fields
│   │           for key in record.__dict__:
│   │               if key not in ['name', 'msg', 'args', 'created', 'filename', 'funcName',
│   │                             'levelname', 'levelno', 'lineno', 'module', 'msecs',
│   │                             'pathname', 'process', 'processName', 'relativeCreated',
│   │                             'thread', 'threadName', 'exc_info', 'exc_text', 'stack_info',
│   │                             'message', 'getMessage', 'request_id', 'user_id']:
│   │                   context_parts.append(f"{key}={getattr(record, key)}")
│   │           
│   │           # Format: 2024-01-15 10:30:45 - funding-service - INFO - [request_id=123] Processing order
│   │           timestamp = datetime.fromtimestamp(record.created).strftime('%Y-%m-%d %H:%M:%S')
│   │           
│   │           message = f"{timestamp} - {self.service_name} - {record.levelname}"
│   │           if context_parts:
│   │               message += f" - [{' '.join(context_parts)}]"
│   │           message += f" - {record.getMessage()}"
│   │           
│   │           if record.exc_info:
│   │               message += '\n' + self.formatException(record.exc_info)
│   │           
│   │           return message
│   │   
│   │   
│   │   class JsonFormatter(logging.Formatter):
│   │       """JSON formatter for production"""
│   │       
│   │       def __init__(self, service_name: str):
│   │           self.service_name = service_name
│   │           super().__init__()
│   │       
│   │       def format(self, record):
│   │           log_data = {
│   │               "timestamp": datetime.utcnow().isoformat(),
│   │               "service": self.service_name,
│   │               "level": record.levelname,
│   │               "message": record.getMessage(),
│   │               "environment": os.getenv("APP_ENV", "dev"),
│   │           }
│   │           
│   │           # Add request context from extra
│   │           request_id = getattr(record, 'request_id', None)
│   │           if request_id is not None:
│   │               log_data['request_id'] = request_id
│   │           user_id = getattr(record, 'user_id', None)
│   │           if user_id is not None:
│   │               log_data['user_id'] = user_id
│   │           
│   │           # Add any other extra fields
│   │           for key in record.__dict__:
│   │               if key not in ['name', 'msg', 'args', 'created', 'filename', 'funcName',
│   │                             'levelname', 'levelno', 'lineno', 'module', 'msecs',
│   │                             'pathname', 'process', 'processName', 'relativeCreated',
│   │                             'thread', 'threadName', 'exc_info', 'exc_text', 'stack_info',
│   │                             'message', 'getMessage', 'request_id', 'user_id']:
│   │                   log_data[key] = getattr(record, key)
│   │           
│   │           # Add exception if present
│   │           if record.exc_info:
│   │               log_data['exception'] = self.formatException(record.exc_info)
│   │           
│   │           return json.dumps(log_data)
│   │   
│   │   
│   │   # Factory function to create service logger
│   │   def create_logger(service_name: str) -> ServiceLogger:
│   │       """
│   │       Create a logger for a specific service.
│   │       
│   │       Args:
│   │           service_name: Name of the service
│   │           
│   │       Returns:
│   │           ServiceLogger instance
│   │       """
│   │       return ServiceLogger(service_name)
│   │   
│   │   
│   │   # ============ USAGE ============
│   │   
│   │   """
│   │   USAGE:
│   │   
│   │   1. In your service initialization (main.py or app.py):
│   │   ```python
│   │   from shared.utils.logger import create_logger
│   │   
│   │   # Create service-specific logger
│   │   logger = create_logger("funding-service")
│   │   ```
│   │   
│   │   2. Basic logging:
│   │   ```python
│   │   logger.info("Service started")
│   │   logger.error("Connection failed", extra={"host": "localhost", "port": 5432})
│   │   ```
│   │   
│   │   3. In FastAPI middleware or request handler:
│   │   ```python
│   │   @app.middleware("http")
│   │   async def add_request_context(request: Request, call_next):
│   │       # Set request context for all logs in this request
│   │       logger.set_request_context(
│   │           request_id=request.headers.get("X-Request-ID", str(uuid.uuid4())),
│   │           method=request.method,
│   │           path=request.url.path
│   │       )
│   │       
│   │       logger.info("Request started")
│   │       response = await call_next(request)
│   │       logger.info("Request completed", extra={"status_code": response.status_code})
│   │       
│   │       # Clear context after request
│   │       logger.clear_request_context()
│   │       return response
│   │   ```
│   │   
│   │   4. In any route or service method:
│   │   ```python
│   │   @app.post("/api/orders")
│   │   async def create_order(order: Order, user_id: str = Depends(get_current_user)):
│   │       # Add user context
│   │       logger.set_request_context(user_id=user_id)
│   │       
│   │       logger.info("Creating order", extra={"order_id": order.id})
│   │       # ... business logic ...
│   │       logger.info("Order created successfully")
│   │   ```
│   │   
│   │   5. Output examples:
│   │   
│   │   Development:
│   │   2024-01-15 10:30:45 - funding-service - INFO - [request_id=abc123 user_id=456] - Creating order
│   │   
│   │   Production (JSON):
│   │   {"timestamp": "2024-01-15T10:30:45.123Z", "service": "funding-service", "level": "INFO", "message": "Creating order", "request_id": "abc123", "user_id": "456", "order_id": "789"}
│   │   """
│   │   ```
│   │   
│   └── query_helpers.py
│       
│       ```py
│       # shared/database/helpers.py
│       """Common query helpers for Prisma operations."""
│       from typing import Dict, Any, Optional, List, Union
│       from enum import Enum
│       from uuid import UUID
│       
│       
│       def shop_filter(
│           shop_id: Optional[Union[str, UUID]] = None,
│           shop_domain: Optional[str] = None,
│           field_prefix: Optional[str] = None
│       ) -> Dict[str, Any]:
│           """
│           Generate filter for shop/merchant queries.
│           
│           Args:
│               shop_id: Shop/merchant UUID
│               shop_domain: Shop domain (e.g., "example.myshopify.com")
│               field_prefix: Field prefix for nested relations (e.g., "merchant" -> "merchantId")
│               
│           Returns:
│               Filter dictionary for Prisma where clause
│               
│           Example:
│               # Filter by shop_id
│               products = await db.product.find_many(
│                   where=shop_filter(shop_id="123e4567-e89b-12d3-a456-426614174000")
│               )
│               
│               # Filter by domain
│               products = await db.product.find_many(
│                   where=shop_filter(shop_domain="example.myshopify.com")
│               )
│               
│               # Filter nested relation
│               orders = await db.order.find_many(
│                   where=shop_filter(
│                       shop_id=shop_id,
│                       field_prefix="merchant"
│                   )
│               )
│               # This generates: {"merchantId": shop_id}
│           """
│           if not shop_id and not shop_domain:
│               return {}
│           
│           # Determine field names
│           id_field = f"{field_prefix}Id" if field_prefix else "shopId"
│           domain_field = f"{field_prefix}Domain" if field_prefix else "shopDomain"
│           
│           # Alternative common field names
│           if field_prefix:
│               # Already has prefix, use it as is
│               pass
│           else:
│               # Try to auto-detect common field names
│               # You can customize this based on your schema conventions
│               id_field_alternatives = ["shopId", "merchantId"]
│               domain_field_alternatives = ["shopDomain", "merchantDomain"]
│           
│           filters = {}
│           
│           if shop_id:
│               filters[id_field] = str(shop_id)
│           
│           if shop_domain:
│               filters[domain_field] = shop_domain
│           
│           # If both are provided, use AND logic
│           if shop_id and shop_domain:
│               return {"AND": [
│                   {id_field: str(shop_id)},
│                   {domain_field: shop_domain}
│               ]}
│           
│           return filters
│       
│       
│       def merchant_filter(
│           merchant_id: Optional[Union[str, UUID]] = None,
│           merchant_domain: Optional[str] = None
│       ) -> Dict[str, Any]:
│           """
│           Alias for shop_filter using merchant terminology.
│           
│           Args:
│               merchant_id: Merchant UUID
│               merchant_domain: Merchant domain
│               
│           Returns:
│               Filter dictionary with merchantId/merchantDomain fields
│               
│           Example:
│               products = await db.product.find_many(
│                   where=merchant_filter(merchant_id=merchant_id)
│               )
│           """
│           filters = {}
│           
│           if merchant_id:
│               filters["merchantId"] = str(merchant_id)
│           
│           if merchant_domain:
│               filters["merchantDomain"] = merchant_domain
│           
│           if merchant_id and merchant_domain:
│               return {"AND": [
│                   {"merchantId": str(merchant_id)},
│                   {"merchantDomain": merchant_domain}
│               ]}
│           
│           return filters
│       
│       
│       def soft_delete_filter(
│           include_deleted: bool = False,
│           table_alias: Optional[str] = None
│       ) -> Dict[str, Any]:
│           """
│           Generate filter for soft-deleted records.
│           
│           Args:
│               include_deleted: Whether to include soft-deleted records
│               table_alias: Optional table alias for nested queries
│               
│           Returns:
│               Filter dictionary for Prisma where clause
│               
│           Example:
│               # Exclude soft-deleted records (default)
│               products = await db.product.find_many(
│                   where=soft_delete_filter()
│               )
│               
│               # Include soft-deleted records
│               all_products = await db.product.find_many(
│                   where=soft_delete_filter(include_deleted=True)
│               )
│           """
│           if include_deleted:
│               return {}
│           
│           base_filter = {"isDeleted": False}
│           
│           if table_alias:
│               return {table_alias: base_filter}
│           
│           return base_filter
│       
│       
│       def pagination_args(
│           page: int = 1,
│           limit: int = 50,
│           max_limit: int = 1000
│       ) -> Dict[str, int]:
│           """
│           Generate pagination arguments for Prisma queries.
│           
│           Args:
│               page: Page number (1-based)
│               limit: Items per page
│               max_limit: Maximum allowed items per page
│               
│           Returns:
│               Dictionary with 'skip' and 'take' for Prisma
│               
│           Example:
│               products = await db.product.find_many(
│                   **pagination_args(page=2, limit=20)
│               )
│           """
│           # Ensure valid page
│           page = max(1, page)
│           
│           # Ensure limit is within bounds
│           limit = min(max(1, limit), max_limit)
│           
│           return {
│               "skip": (page - 1) * limit,
│               "take": limit
│           }
│       
│       
│       class OrderDirection(str, Enum):
│           """Order direction for sorting."""
│           ASC = "asc"
│           DESC = "desc"
│       
│       
│       def parse_order_by(
│           order_by: Optional[str] = None,
│           allowed_fields: Optional[List[str]] = None,
│           default_field: str = "createdAt",
│           default_direction: OrderDirection = OrderDirection.DESC
│       ) -> List[Dict[str, str]]:
│           """
│           Parse order_by string into Prisma orderBy format.
│           
│           Args:
│               order_by: Comma-separated fields with optional direction (e.g., "name,-createdAt")
│               allowed_fields: List of allowed field names (None allows all)
│               default_field: Default field to sort by
│               default_direction: Default sort direction
│               
│           Returns:
│               List of orderBy dictionaries for Prisma
│               
│           Example:
│               # Sort by name ascending, then createdAt descending
│               products = await db.product.find_many(
│                   order_by=parse_order_by("name,-createdAt")
│               )
│               
│               # With field restrictions
│               products = await db.product.find_many(
│                   order_by=parse_order_by(
│                       "name,-price",
│                       allowed_fields=["name", "price", "createdAt"]
│                   )
│               )
│           """
│           if not order_by:
│               return [{default_field: default_direction.value}]
│           
│           order_list = []
│           
│           for field_spec in order_by.split(","):
│               field_spec = field_spec.strip()
│               if not field_spec:
│                   continue
│                   
│               # Check for descending prefix
│               if field_spec.startswith("-"):
│                   field = field_spec[1:]
│                   direction = OrderDirection.DESC
│               else:
│                   field = field_spec
│                   direction = OrderDirection.ASC
│               
│               # Validate field if restrictions are set
│               if allowed_fields and field not in allowed_fields:
│                   continue
│                   
│               order_list.append({field: direction.value})
│           
│           # Use default if no valid fields
│           if not order_list:
│               return [{default_field: default_direction.value}]
│           
│           return order_list
│       
│       
│       # Optional: Add more helpers as needed
│       def build_search_filter(
│           search_term: Optional[str],
│           search_fields: List[str],
│           mode: str = "insensitive"
│       ) -> Dict[str, Any]:
│           """
│           Build a search filter for multiple fields.
│           
│           Args:
│               search_term: The search term
│               search_fields: List of fields to search in
│               mode: Prisma search mode ('insensitive' or 'default')
│               
│           Returns:
│               OR filter for Prisma where clause
│               
│           Example:
│               # Search in multiple fields
│               products = await db.product.find_many(
│                   where=build_search_filter(
│                       "shirt",
│                       ["name", "description", "sku"]
│                   )
│               )
│           """
│           if not search_term or not search_fields:
│               return {}
│           
│           return {
│               "OR": [
│                   {field: {"contains": search_term, "mode": mode}}
│                   for field in search_fields
│               ]
│           }
│       
│       
│       def combine_filters(*filters: Dict[str, Any]) -> Dict[str, Any]:
│           """
│           Combine multiple filter dictionaries with AND logic.
│           
│           Args:
│               *filters: Variable number of filter dictionaries
│               
│           Returns:
│               Combined filter dictionary
│               
│           Example:
│               products = await db.product.find_many(
│                   where=combine_filters(
│                       {"merchantId": merchant_id},
│                       soft_delete_filter(),
│                       build_search_filter(search, ["name", "sku"])
│                   )
│               )
│           """
│           # Remove empty filters
│           valid_filters = [f for f in filters if f]
│           
│           if not valid_filters:
│               return {}
│           
│           if len(valid_filters) == 1:
│               return valid_filters[0]
│           
│           return {"AND": valid_filters}
│       
│       
│       # ============ USAGE EXAMPLES ============
│       """
│       Common usage patterns for filtering:
│       
│       1. Filter products by shop:
│       ```python
│       # Using shop_filter
│       products = await db.product.find_many(
│           where=combine_filters(
│               shop_filter(shop_id=shop_id),
│               soft_delete_filter()
│           )
│       )
│       
│       # Using merchant_filter (same result, different field names)
│       products = await db.product.find_many(
│           where=combine_filters(
│               merchant_filter(merchant_id=merchant_id),
│               soft_delete_filter()
│           )
│       )
│       ```
│       
│       2. Filter with pagination and search:
│       ```python
│       products = await db.product.find_many(
│           where=combine_filters(
│               merchant_filter(merchant_id=merchant_id, merchant_domain=domain),
│               soft_delete_filter(),
│               build_search_filter(search_term, ["name", "description", "sku"])
│           ),
│           order_by=parse_order_by("-updatedAt,name"),
│           **pagination_args(page=2, limit=20)
│       )
│       ```
│       
│       3. Filter nested relations:
│       ```python
│       # If your schema has orders with a merchant relation
│       orders = await db.order.find_many(
│           where={
│               "merchant": merchant_filter(merchant_id=merchant_id)
│           },
│           include={"merchant": True}
│       )
│       ```
│       """
│       ```
│       
└── __init__.py
tests/
└── __init__.py
.python-version
poetry.lock
pyproject.toml

```toml
# shared/pyproject.toml
[tool.poetry]
name = "shared"
version = "0.1.0"
description = "Shared utilities for GLAM system services"
authors = ["GLAM Team <team@glam.com>"]

[tool.poetry.dependencies]
python = "^3.11"
nats-py = "^2.6.0"
pydantic = "^2.5.0"
python-json-logger = "^2.0.7"
tenacity = "^8.2.3"
pydantic-settings = "^2.10.1"
asyncio = "^3.4.3"
python-dotenv = "^1.1.1"
uuid7 = "^0.1.0"
prisma = "^0.15.0"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
```

README.md

================================================================================
Output includes file contents
================================================================================