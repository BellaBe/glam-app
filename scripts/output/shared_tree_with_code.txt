================================================================================
Directory Structure: /home/bellabe/glam-app/shared
================================================================================

shared/
shared/
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/api/__init__.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """
â”‚   â”‚   Unified API response models and utilities for glam-app microservices.
â”‚   â”‚   
â”‚   â”‚   This module provides a single, consistent approach to API responses
â”‚   â”‚   across all services.
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from .models import (
â”‚   â”‚       # Core models
â”‚   â”‚       ApiResponse,
â”‚   â”‚       Meta,
â”‚   â”‚       Pagination,
â”‚   â”‚       Links,
â”‚   â”‚       ErrorDetail,
â”‚   â”‚       T,  # Generic type
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .responses import (
â”‚   â”‚       # Response helpers
â”‚   â”‚       create_response,
â”‚   â”‚       success_response,
â”‚   â”‚       error_response,
â”‚   â”‚       paginated_response,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .dependencies import (
â”‚   â”‚       # FastAPI dependencies
â”‚   â”‚       PaginationDep,
â”‚   â”‚       RequestContextDep,
â”‚   â”‚       CorrelationIdDep,  # Re-exported from correlation
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .middleware import (
â”‚   â”‚       # Middleware
â”‚   â”‚       APIMiddleware,
â”‚   â”‚       setup_middleware,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .correlation import (
â”‚   â”‚       # Correlation utilities
â”‚   â”‚       get_correlation_id,
â”‚   â”‚       set_correlation_context,
â”‚   â”‚       get_correlation_context,
â”‚   â”‚       add_correlation_header,
â”‚   â”‚       add_correlation_to_event,
â”‚   â”‚       extract_correlation_from_event,
â”‚   â”‚       
â”‚   â”‚   )
â”‚   â”‚   from .tracing import (
â”‚   â”‚       set_trace_context,
â”‚   â”‚       get_trace_context,
â”‚   â”‚       TracingMiddleware,
â”‚   â”‚   )   
â”‚   â”‚   
â”‚   â”‚   __all__ = [
â”‚   â”‚       # Models
â”‚   â”‚       "ApiResponse",
â”‚   â”‚       "Meta",
â”‚   â”‚       "Pagination",
â”‚   â”‚       "Links",
â”‚   â”‚       "ErrorDetail",
â”‚   â”‚       "T",
â”‚   â”‚       
â”‚   â”‚       # Response helpers
â”‚   â”‚       "create_response",
â”‚   â”‚       "success_response",
â”‚   â”‚       "error_response",
â”‚   â”‚       "paginated_response",
â”‚   â”‚       
â”‚   â”‚       # Dependencies
â”‚   â”‚       "PaginationDep",
â”‚   â”‚       "RequestContextDep",
â”‚   â”‚       "CorrelationIdDep",
â”‚   â”‚       
â”‚   â”‚       # Correlation
â”‚   â”‚       "get_correlation_id",
â”‚   â”‚       "set_correlation_context",
â”‚   â”‚       "get_correlation_context",
â”‚   â”‚       "add_correlation_header",
â”‚   â”‚       "add_correlation_to_event",
â”‚   â”‚       "extract_correlation_from_event",
â”‚   â”‚       # Tracing
â”‚   â”‚       "set_trace_context",
â”‚   â”‚       "get_trace_context",
â”‚   â”‚       "TracingMiddleware",
â”‚   â”‚       
â”‚   â”‚       # Middleware
â”‚   â”‚       "APIMiddleware",
â”‚   â”‚       "setup_middleware",
â”‚   â”‚   ]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ correlation.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # File: shared/api/correlation.py
â”‚   â”‚   
â”‚   â”‚   """
â”‚   â”‚   Simplified correlation ID support for distributed tracing.
â”‚   â”‚   
â”‚   â”‚   Focuses on the essential functionality needed for request tracing
â”‚   â”‚   across services without over-engineering.
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from typing import Optional, Annotated
â”‚   â”‚   from contextvars import ContextVar
â”‚   â”‚   from fastapi import Request, Depends
â”‚   â”‚   import uuid
â”‚   â”‚   
â”‚   â”‚   # Context variable for async operations
â”‚   â”‚   _correlation_context: ContextVar[Optional[str]] = ContextVar(
â”‚   â”‚       "correlation_id", default=None
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def get_correlation_id(request: Request) -> str:
â”‚   â”‚       """
â”‚   â”‚       Get or generate correlation ID for the current request.
â”‚   â”‚   
â”‚   â”‚       Priority:
â”‚   â”‚       1. Request state (set by middleware)
â”‚   â”‚       2. X-Correlation-ID header (from upstream service)
â”‚   â”‚       3. Generate new one (originating request)
â”‚   â”‚       """
â”‚   â”‚       # Check request state first
â”‚   â”‚       if hasattr(request.state, "correlation_id"):
â”‚   â”‚           return request.state.correlation_id
â”‚   â”‚   
â”‚   â”‚       # Check headers from upstream service
â”‚   â”‚       correlation_id = request.headers.get("X-Correlation-ID")
â”‚   â”‚       if correlation_id:
â”‚   â”‚           return correlation_id
â”‚   â”‚   
â”‚   â”‚       # Generate new one
â”‚   â”‚       return f"corr_{uuid.uuid4().hex[:12]}"
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   # FastAPI dependency
â”‚   â”‚   CorrelationIdDep = Annotated[str, Depends(get_correlation_id)]
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def set_correlation_context(correlation_id: str) -> None:
â”‚   â”‚       """Set correlation ID in async context."""
â”‚   â”‚       _correlation_context.set(correlation_id)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def get_correlation_context() -> Optional[str]:
â”‚   â”‚       """Get correlation ID from async context."""
â”‚   â”‚       return _correlation_context.get()
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   # Essential integrations only
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def add_correlation_header(headers: dict) -> dict:
â”‚   â”‚       """
â”‚   â”‚       Add correlation ID to outgoing HTTP headers.
â”‚   â”‚   
â”‚   â”‚       Usage:
â”‚   â”‚           headers = add_correlation_header({"Content-Type": "application/json"})
â”‚   â”‚           response = await client.get(url, headers=headers)
â”‚   â”‚       """
â”‚   â”‚       correlation_id = get_correlation_context()
â”‚   â”‚       if correlation_id:
â”‚   â”‚           headers["X-Correlation-ID"] = correlation_id
â”‚   â”‚       return headers
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def add_correlation_to_event(event_data: dict) -> dict:
â”‚   â”‚       """
â”‚   â”‚       Add correlation ID to message bus events.
â”‚   â”‚   
â”‚   â”‚       Usage:
â”‚   â”‚           event_data = {"subject": "ORDER_CREATED", "data": {...}}
â”‚   â”‚           event_with_correlation = add_correlation_to_event(event_data)
â”‚   â”‚       """
â”‚   â”‚       correlation_id = get_correlation_context()
â”‚   â”‚       if correlation_id:
â”‚   â”‚           if "metadata" not in event_data:
â”‚   â”‚               event_data["metadata"] = {}
â”‚   â”‚           event_data["metadata"]["correlation_id"] = correlation_id
â”‚   â”‚       return event_data
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def extract_correlation_from_event(event_data: dict) -> Optional[str]:
â”‚   â”‚       """Extract correlation ID from event data."""
â”‚   â”‚       return event_data.get("metadata", {}).get("correlation_id")
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # File: shared/api/dependencies.py
â”‚   â”‚   
â”‚   â”‚   """
â”‚   â”‚   FastAPI dependencies for standardized API behavior.
â”‚   â”‚   
â”‚   â”‚   Simplified to focus on commonly used dependencies.
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from typing import Annotated
â”‚   â”‚   from fastapi import Query, Request, Depends
â”‚   â”‚   from pydantic import BaseModel, Field
â”‚   â”‚   from .correlation import get_correlation_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class PaginationParams(BaseModel):
â”‚   â”‚       """Standard pagination parameters."""
â”‚   â”‚       
â”‚   â”‚       page: int = Field(default=1, ge=1)
â”‚   â”‚       limit: int = Field(default=50, ge=1, le=1000)
â”‚   â”‚       
â”‚   â”‚       @property
â”‚   â”‚       def offset(self) -> int:
â”‚   â”‚           """Calculate offset for database queries."""
â”‚   â”‚           return (self.page - 1) * self.limit
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def get_pagination_params(
â”‚   â”‚       page: int = Query(1, ge=1, description="Page number"),
â”‚   â”‚       limit: int = Query(50, ge=1, le=1000, description="Items per page")
â”‚   â”‚   ) -> PaginationParams:
â”‚   â”‚       """
â”‚   â”‚       FastAPI dependency for pagination parameters.
â”‚   â”‚       
â”‚   â”‚       Usage:
â”‚   â”‚           @app.get("/items")
â”‚   â”‚           async def list_items(pagination: PaginationDep):
â”‚   â”‚               items = await db.query(offset=pagination.offset, limit=pagination.limit)
â”‚   â”‚       """
â”‚   â”‚       return PaginationParams(page=page, limit=limit)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def get_request_id(request: Request) -> str:
â”‚   â”‚       """
â”‚   â”‚       Get request ID from middleware-set state.
â”‚   â”‚       
â”‚   â”‚       Raises error if middleware hasn't run, ensuring proper initialization.
â”‚   â”‚       """
â”‚   â”‚       if not hasattr(request.state, "request_id"):
â”‚   â”‚           raise RuntimeError(
â”‚   â”‚               "Request ID not found. Ensure APIMiddleware is properly configured."
â”‚   â”‚           )
â”‚   â”‚       return request.state.request_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   # Type aliases for clean dependency injection
â”‚   â”‚   RequestIdDep = Annotated[str, Depends(get_request_id)]
â”‚   â”‚   PaginationDep = Annotated[PaginationParams, Depends(get_pagination_params)]
â”‚   â”‚   CorrelationIdDep = Annotated[str, Depends(get_correlation_id)]  # Re-export for convenience
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   # Optional: Simplified request context for logging
â”‚   â”‚   class RequestContext(BaseModel):
â”‚   â”‚       """Essential request context for logging/auditing."""
â”‚   â”‚       
â”‚   â”‚       request_id: str
â”‚   â”‚       trace_id: str
â”‚   â”‚       correlation_id: str
â”‚   â”‚       method: str
â”‚   â”‚       path: str
â”‚   â”‚       
â”‚   â”‚       @classmethod
â”‚   â”‚       def from_request(cls, request: Request) -> "RequestContext":
â”‚   â”‚           """Create context from FastAPI request."""
â”‚   â”‚           return cls(
â”‚   â”‚               request_id=get_request_id(request),
â”‚   â”‚               correlation_id=get_correlation_id(request),
â”‚   â”‚               trace_id=request.state.trace_id,
â”‚   â”‚               method=request.method,
â”‚   â”‚               path=str(request.url.path)
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def get_request_context(request: Request) -> RequestContext:
â”‚   â”‚       """Get essential request context."""
â”‚   â”‚       return RequestContext.from_request(request)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   RequestContextDep = Annotated[RequestContext, Depends(get_request_context)]
â”‚   â”‚   
â”‚   â”‚   def get_client_ip(request: Request) -> str:
â”‚   â”‚       """
â”‚   â”‚       Extract client IP address.
â”‚   â”‚       Only add if needed for rate limiting or security.
â”‚   â”‚       """
â”‚   â”‚       forwarded_for = request.headers.get("X-Forwarded-For")
â”‚   â”‚       if forwarded_for:
â”‚   â”‚           return forwarded_for.split(",")[0].strip()
â”‚   â”‚       return request.client.host if request.client else "unknown"
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   ClientIpDep = Annotated[str, Depends(get_client_ip)]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ health.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # glam-app/shared/api/health.py
â”‚   â”‚   
â”‚   â”‚   from fastapi import APIRouter, Request
â”‚   â”‚   from datetime import datetime, timezone
â”‚   â”‚   from shared.api.responses import success_response
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def create_health_router(service_name: str) -> APIRouter:
â”‚   â”‚       router = APIRouter()
â”‚   â”‚   
â”‚   â”‚       @router.get("/health", tags=["Health"])
â”‚   â”‚       async def health_check(request: Request):
â”‚   â”‚           """Basic health check endpoint with service name and timestamp"""
â”‚   â”‚           return success_response(
â”‚   â”‚               data={
â”‚   â”‚                   "status": "healthy",
â”‚   â”‚                   "service": service_name,
â”‚   â”‚                   "timestamp": datetime.now(timezone.utc).isoformat(),
â”‚   â”‚               },
â”‚   â”‚               request_id=getattr(request.state, "request_id", None),
â”‚   â”‚               correlation_id=getattr(request.state, "correlation_id", None),
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       return router
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ middleware.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/api/middleware.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Simplified API middleware."""
â”‚   â”‚   
â”‚   â”‚   import time
â”‚   â”‚   import uuid
â”‚   â”‚   import logging
â”‚   â”‚   from typing import Callable
â”‚   â”‚   
â”‚   â”‚   from fastapi import Request, Response
â”‚   â”‚   from fastapi import FastAPI
â”‚   â”‚   from fastapi.responses import JSONResponse
â”‚   â”‚   from starlette.middleware.base import BaseHTTPMiddleware
â”‚   â”‚   from fastapi.exceptions import RequestValidationError, HTTPException
â”‚   â”‚   
â”‚   â”‚   from ..errors import GlamBaseError
â”‚   â”‚   from ..metrics import PrometheusMiddleware, metrics_endpoint
â”‚   â”‚   
â”‚   â”‚   from .models import ErrorDetail
â”‚   â”‚   from .responses import error_response
â”‚   â”‚   from .correlation import get_correlation_id, set_correlation_context
â”‚   â”‚   from .tracing import TracingMiddleware
â”‚   â”‚   
â”‚   â”‚   logger = logging.getLogger(__name__)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class APIMiddleware(BaseHTTPMiddleware):
â”‚   â”‚       """Unified middleware for request/response handling."""
â”‚   â”‚       
â”‚   â”‚       def __init__(self, app, *, service_name: str = "glam-service"):
â”‚   â”‚           super().__init__(app)
â”‚   â”‚           self.service_name = service_name
â”‚   â”‚       
â”‚   â”‚       async def dispatch(self, request: Request, call_next: Callable) -> Response:
â”‚   â”‚           # Generate IDs
â”‚   â”‚           request_id = request.headers.get("X-Request-ID", f"req_{uuid.uuid4().hex[:12]}")
â”‚   â”‚           
â”‚   â”‚           # Get correlation ID (this will check headers and generate if needed)
â”‚   â”‚           correlation_id = get_correlation_id(request)
â”‚   â”‚           
â”‚   â”‚           # Store in request state for easy access in the request
â”‚   â”‚           request.state.request_id = request_id
â”‚   â”‚           request.state.correlation_id = correlation_id
â”‚   â”‚           
â”‚   â”‚           # IMPORTANT: Set correlation context for async operations
â”‚   â”‚           # This makes correlation_id available throughout the request lifecycle
â”‚   â”‚           set_correlation_context(correlation_id)
â”‚   â”‚           
â”‚   â”‚           # Track timing
â”‚   â”‚           start_time = time.perf_counter()
â”‚   â”‚           
â”‚   â”‚           try:
â”‚   â”‚               response = await call_next(request)
â”‚   â”‚               
â”‚   â”‚               # Add standard headers
â”‚   â”‚               response.headers["X-Request-ID"] = request_id
â”‚   â”‚               response.headers["X-Correlation-ID"] = correlation_id
â”‚   â”‚               response.headers["X-Service-Name"] = self.service_name
â”‚   â”‚               
â”‚   â”‚               return response
â”‚   â”‚               
â”‚   â”‚           except Exception as exc:
â”‚   â”‚               # Convert to standard error response
â”‚   â”‚               error_resp = self._handle_exception(exc, request_id, correlation_id)
â”‚   â”‚               
â”‚   â”‚               # Determine status code
â”‚   â”‚               status_code = 500
â”‚   â”‚               if isinstance(exc, GlamBaseError):
â”‚   â”‚                   status_code = exc.status
â”‚   â”‚               elif isinstance(exc, HTTPException):
â”‚   â”‚                   status_code = exc.status_code
â”‚   â”‚               elif isinstance(exc, RequestValidationError):
â”‚   â”‚                   status_code = 422
â”‚   â”‚               
â”‚   â”‚               # Log error
â”‚   â”‚               duration_ms = (time.perf_counter() - start_time) * 1000
â”‚   â”‚               logger.error(
â”‚   â”‚                   "Request failed",
â”‚   â”‚                   extra={
â”‚   â”‚                       "request_id": request_id,
â”‚   â”‚                       "correlation_id": correlation_id,
â”‚   â”‚                       "method": request.method,
â”‚   â”‚                       "path": request.url.path,
â”‚   â”‚                       "status": status_code,
â”‚   â”‚                       "duration_ms": round(duration_ms, 2),
â”‚   â”‚                       "error_code": error_resp.error.code if error_resp.error else "UNKNOWN",
â”‚   â”‚                       "service": self.service_name
â”‚   â”‚                   }
â”‚   â”‚               )
â”‚   â”‚               
â”‚   â”‚               response = JSONResponse(
â”‚   â”‚                   content=error_resp.model_dump(mode="json", exclude_none=True),
â”‚   â”‚                   status_code=status_code
â”‚   â”‚               )
â”‚   â”‚               
â”‚   â”‚               # Add standard headers
â”‚   â”‚               response.headers["X-Request-ID"] = request_id
â”‚   â”‚               response.headers["X-Correlation-ID"] = correlation_id
â”‚   â”‚               response.headers["X-Service-Name"] = self.service_name
â”‚   â”‚               
â”‚   â”‚               return response
â”‚   â”‚       
â”‚   â”‚       def _handle_exception(self, exc: Exception, request_id: str, correlation_id: str):
â”‚   â”‚           """Convert exception to error response."""
â”‚   â”‚           
â”‚   â”‚           if isinstance(exc, GlamBaseError):
â”‚   â”‚               return error_response(
â”‚   â”‚                   code=exc.code,
â”‚   â”‚                   message=exc.message,
â”‚   â”‚                   details=exc.details,
â”‚   â”‚                   request_id=request_id,
â”‚   â”‚                   correlation_id=correlation_id
â”‚   â”‚               )
â”‚   â”‚           
â”‚   â”‚           elif isinstance(exc, RequestValidationError):
â”‚   â”‚               validation_errors = []
â”‚   â”‚               for error in exc.errors():
â”‚   â”‚                   field_path = ".".join(str(loc) for loc in error["loc"])
â”‚   â”‚                   validation_errors.append({
â”‚   â”‚                       "field": field_path,
â”‚   â”‚                       "message": error["msg"],
â”‚   â”‚                       "type": error["type"]
â”‚   â”‚                   })
â”‚   â”‚               
â”‚   â”‚               return error_response(
â”‚   â”‚                   code="VALIDATION_ERROR",
â”‚   â”‚                   message="Request validation failed",
â”‚   â”‚                   details={"validation_errors": validation_errors},
â”‚   â”‚                   request_id=request_id,
â”‚   â”‚                   correlation_id=correlation_id
â”‚   â”‚               )
â”‚   â”‚           
â”‚   â”‚           elif isinstance(exc, HTTPException):
â”‚   â”‚               return error_response(
â”‚   â”‚                   code=f"HTTP_{exc.status_code}",
â”‚   â”‚                   message=exc.detail,
â”‚   â”‚                   request_id=request_id,
â”‚   â”‚                   correlation_id=correlation_id
â”‚   â”‚               )
â”‚   â”‚           
â”‚   â”‚           else:
â”‚   â”‚               logger.exception(
â”‚   â”‚                   "Unhandled exception",
â”‚   â”‚                   extra={
â”‚   â”‚                       "request_id": request_id,
â”‚   â”‚                       "correlation_id": correlation_id,
â”‚   â”‚                       "error_type": type(exc).__name__
â”‚   â”‚                   }
â”‚   â”‚               )
â”‚   â”‚               
â”‚   â”‚               return error_response(
â”‚   â”‚                   code="INTERNAL_ERROR",
â”‚   â”‚                   message="An unexpected error occurred",
â”‚   â”‚                   request_id=request_id,
â”‚   â”‚                   correlation_id=correlation_id
â”‚   â”‚               )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def setup_middleware(
â”‚   â”‚       app: FastAPI,
â”‚   â”‚       *,
â”‚   â”‚       service_name: str,
â”‚   â”‚       enable_tracing: bool = True,
â”‚   â”‚       enable_metrics: bool = True,
â”‚   â”‚       metrics_path: str = "/metrics",
â”‚   â”‚   ):
â”‚   â”‚       """
â”‚   â”‚       Set up all standard middleware for a service.
â”‚   â”‚       
â”‚   â”‚       This sets up middleware in the correct order:
â”‚   â”‚       1. Prometheus metrics (if enabled) - captures all requests
â”‚   â”‚       2. API middleware - handles responses and errors
â”‚   â”‚       
â”‚   â”‚       Args:
â”‚   â”‚           app: FastAPI application
â”‚   â”‚           service_name: Name of the service
â”‚   â”‚           enable_metrics: Whether to enable Prometheus metrics
â”‚   â”‚           metrics_path: Path for metrics endpoint
â”‚   â”‚           debug: Whether to include error details in responses
â”‚   â”‚       """
â”‚   â”‚       # Add Prometheus middleware FIRST (captures all requests)
â”‚   â”‚       if enable_metrics:
â”‚   â”‚           app.add_middleware(PrometheusMiddleware, service_name=service_name)
â”‚   â”‚           
â”‚   â”‚           # Add metrics endpoint
â”‚   â”‚           app.add_api_route(
â”‚   â”‚               metrics_path,
â”‚   â”‚               metrics_endpoint,
â”‚   â”‚               methods=["GET"],
â”‚   â”‚               include_in_schema=False,
â”‚   â”‚               tags=["monitoring"]
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       if enable_tracing:
â”‚   â”‚           app.add_middleware(TracingMiddleware)
â”‚   â”‚   
â”‚   â”‚       # Add API middleware for standardized responses
â”‚   â”‚       app.add_middleware(APIMiddleware, service_name=service_name)
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ models.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/api/models.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """
â”‚   â”‚   Unified API response models for glam-app services.
â”‚   â”‚   Consolidates all response structures into a single, consistent pattern.
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from typing import TypeVar, Generic, Optional, Any, Dict, List
â”‚   â”‚   from datetime import datetime, timezone
â”‚   â”‚   from pydantic import BaseModel, Field, ConfigDict
â”‚   â”‚   import uuid
â”‚   â”‚   
â”‚   â”‚   # Generic type for response data
â”‚   â”‚   T = TypeVar("T")
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class Meta(BaseModel):
â”‚   â”‚       """Metadata included in all responses."""
â”‚   â”‚       request_id: str = Field(description="Unique request identifier")
â”‚   â”‚       correlation_id: Optional[str] = Field(None, description="Distributed tracing ID")
â”‚   â”‚       timestamp: datetime = Field(
â”‚   â”‚           default_factory=lambda: datetime.now(timezone.utc),
â”‚   â”‚           description="Response timestamp in UTC"
â”‚   â”‚       )
â”‚   â”‚       
â”‚   â”‚       model_config = ConfigDict(
â”‚   â”‚           json_encoders={datetime: lambda v: v.isoformat()}
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class Pagination(BaseModel):
â”‚   â”‚       """Pagination metadata for list responses."""
â”‚   â”‚       page: int = Field(ge=1)
â”‚   â”‚       limit: int = Field(ge=1, le=1000)
â”‚   â”‚       total: int = Field(ge=0)
â”‚   â”‚       pages: int = Field(ge=0)
â”‚   â”‚       has_next: bool
â”‚   â”‚       has_previous: bool
â”‚   â”‚       
â”‚   â”‚       @classmethod
â”‚   â”‚       def create(cls, page: int, limit: int, total: int) -> "Pagination":
â”‚   â”‚           """Create pagination from parameters."""
â”‚   â”‚           pages = (total + limit - 1) // limit if total > 0 else 0
â”‚   â”‚           return cls(
â”‚   â”‚               page=page,
â”‚   â”‚               limit=limit,
â”‚   â”‚               total=total,
â”‚   â”‚               pages=pages,
â”‚   â”‚               has_next=page < pages,
â”‚   â”‚               has_previous=page > 1
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class Links(BaseModel):
â”‚   â”‚       """HATEOAS links for resource navigation."""
â”‚   â”‚       self: str
â”‚   â”‚       next: Optional[str] = None
â”‚   â”‚       previous: Optional[str] = None
â”‚   â”‚       first: Optional[str] = None
â”‚   â”‚       last: Optional[str] = None
â”‚   â”‚       
â”‚   â”‚       @classmethod
â”‚   â”‚       def create_paginated(
â”‚   â”‚           cls, 
â”‚   â”‚           base_url: str, 
â”‚   â”‚           page: int, 
â”‚   â”‚           limit: int, 
â”‚   â”‚           pages: int,
â”‚   â”‚           **query_params
â”‚   â”‚       ) -> "Links":
â”‚   â”‚           """Create pagination links."""
â”‚   â”‚           def build_url(page_num: int) -> str:
â”‚   â”‚               params = {**query_params, "page": page_num, "limit": limit}
â”‚   â”‚               query = "&".join(f"{k}={v}" for k, v in params.items())
â”‚   â”‚               return f"{base_url}?{query}"
â”‚   â”‚           
â”‚   â”‚           return cls(
â”‚   â”‚               self=build_url(page),
â”‚   â”‚               next=build_url(page + 1) if page < pages else None,
â”‚   â”‚               previous=build_url(page - 1) if page > 1 else None,
â”‚   â”‚               first=build_url(1) if pages > 0 else None,
â”‚   â”‚               last=build_url(pages) if pages > 0 else None
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ErrorDetail(BaseModel):
â”‚   â”‚       """Error information."""
â”‚   â”‚       code: str
â”‚   â”‚       message: str
â”‚   â”‚       details: Optional[Dict[str, Any]] = None
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ApiResponse(BaseModel, Generic[T]):
â”‚   â”‚       """
â”‚   â”‚       Unified API response structure.
â”‚   â”‚       Used for both success and error responses.
â”‚   â”‚       """
â”‚   â”‚       # For success responses
â”‚   â”‚       data: Optional[T] = None
â”‚   â”‚       
â”‚   â”‚       # For error responses
â”‚   â”‚       error: Optional[ErrorDetail] = None
â”‚   â”‚       
â”‚   â”‚       # Always present
â”‚   â”‚       meta: Meta
â”‚   â”‚       
â”‚   â”‚       # Optional for paginated responses
â”‚   â”‚       pagination: Optional[Pagination] = None
â”‚   â”‚       links: Optional[Links] = None
â”‚   â”‚       
â”‚   â”‚       model_config = ConfigDict(
â”‚   â”‚           json_encoders={datetime: lambda v: v.isoformat()}
â”‚   â”‚       )
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ responses.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/api/responses.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Response helper functions."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional, Dict, Any, List, Tuple
â”‚   â”‚   import uuid
â”‚   â”‚   from .models import ApiResponse, Meta, ErrorDetail, Pagination, Links, T
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def create_response(
â”‚   â”‚       data: Optional[T] = None,
â”‚   â”‚       error: Optional[ErrorDetail] = None,
â”‚   â”‚       request_id: Optional[str] = None,
â”‚   â”‚       correlation_id: Optional[str] = None,
â”‚   â”‚       pagination: Optional[Pagination] = None,
â”‚   â”‚       links: Optional[Links] = None
â”‚   â”‚   ) -> ApiResponse[T]:
â”‚   â”‚       """Create a unified API response."""
â”‚   â”‚       if request_id is None:
â”‚   â”‚           request_id = f"req_{uuid.uuid4().hex[:12]}"
â”‚   â”‚       
â”‚   â”‚       meta = Meta(request_id=request_id, correlation_id=correlation_id)
â”‚   â”‚       
â”‚   â”‚       return ApiResponse(
â”‚   â”‚           data=data,
â”‚   â”‚           error=error,
â”‚   â”‚           meta=meta,
â”‚   â”‚           pagination=pagination,
â”‚   â”‚           links=links
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def success_response(
â”‚   â”‚       data: T,
â”‚   â”‚       request_id: Optional[str] = None,
â”‚   â”‚       correlation_id: Optional[str] = None,
â”‚   â”‚       links: Optional[Links] = None
â”‚   â”‚   ) -> ApiResponse[T]:
â”‚   â”‚       """Create a success response."""
â”‚   â”‚       return create_response(
â”‚   â”‚           data=data,
â”‚   â”‚           request_id=request_id,
â”‚   â”‚           correlation_id=correlation_id,
â”‚   â”‚           links=links
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def error_response(
â”‚   â”‚       code: str,
â”‚   â”‚       message: str,
â”‚   â”‚       details: Optional[Dict[str, Any]] = None,
â”‚   â”‚       request_id: Optional[str] = None,
â”‚   â”‚       correlation_id: Optional[str] = None
â”‚   â”‚   ) -> ApiResponse[None]:
â”‚   â”‚       """Create an error response."""
â”‚   â”‚       error = ErrorDetail(code=code, message=message, details=details)
â”‚   â”‚       return create_response(
â”‚   â”‚           error=error,
â”‚   â”‚           request_id=request_id,
â”‚   â”‚           correlation_id=correlation_id
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def paginated_response(
â”‚   â”‚       data: List[T],
â”‚   â”‚       page: int,
â”‚   â”‚       limit: int,
â”‚   â”‚       total: int,
â”‚   â”‚       base_url: str,
â”‚   â”‚       request_id: Optional[str] = None,
â”‚   â”‚       correlation_id: Optional[str] = None,
â”‚   â”‚       **query_params
â”‚   â”‚   ) -> ApiResponse[List[T]]:
â”‚   â”‚       """Create a paginated response."""
â”‚   â”‚       pagination = Pagination.create(page, limit, total)
â”‚   â”‚       links = Links.create_paginated(base_url, page, limit, pagination.pages, **query_params)
â”‚   â”‚       
â”‚   â”‚       return create_response(
â”‚   â”‚           data=data,
â”‚   â”‚           request_id=request_id,
â”‚   â”‚           correlation_id=correlation_id,
â”‚   â”‚           pagination=pagination,
â”‚   â”‚           links=links
â”‚   â”‚       )
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ tracing.py
â”‚       
â”‚       ```py
â”‚       # shared/api/tracing.py
â”‚       from typing import Optional
â”‚       from fastapi import Request
â”‚       from contextvars import ContextVar
â”‚       from uuid7 import uuid7
â”‚       from starlette.middleware.base import BaseHTTPMiddleware
â”‚       from .correlation import set_correlation_context
â”‚       
â”‚       _trace_ctx: ContextVar[Optional[str]] = ContextVar("trace_id", default=None)
â”‚                                       
â”‚       
â”‚       def set_trace_context(trace_id: Optional[str]) -> None:
â”‚           _trace_ctx.set(trace_id)
â”‚       
â”‚       def get_trace_context() -> Optional[str]:
â”‚           return _trace_ctx.get()
â”‚       
â”‚       class TracingMiddleware(BaseHTTPMiddleware):
â”‚           """Middleware to handle trace_id and correlation_id for all requests"""
â”‚           
â”‚           async def dispatch(self, request: Request, call_next):
â”‚               # ðŸ†• Extract or generate trace_id from W3C traceparent
â”‚               trace_id = self._extract_trace_id(request) or str(uuid7())
â”‚               
â”‚               # Extract or generate correlation_id
â”‚               correlation_id = request.headers.get("x-correlation-id") or trace_id
â”‚               
â”‚               # Set context for this request
â”‚               set_trace_context(trace_id)
â”‚               set_correlation_context(correlation_id)
â”‚               
â”‚               # Add to request state
â”‚               request.state.trace_id = trace_id
â”‚               request.state.correlation_id = correlation_id
â”‚               
â”‚               # Process request
â”‚               response = await call_next(request)
â”‚               
â”‚               # Add headers to response
â”‚               response.headers["x-trace-id"] = trace_id
â”‚               response.headers["x-correlation-id"] = correlation_id
â”‚               
â”‚               return response
â”‚           
â”‚           def _extract_trace_id(self, request: Request) -> Optional[str]:
â”‚               """Extract trace ID from W3C traceparent header"""
â”‚               traceparent = request.headers.get("traceparent")
â”‚               if traceparent:
â”‚                   # W3C traceparent format: version-trace_id-parent_id-flags
â”‚                   parts = traceparent.split("-")
â”‚                   if len(parts) >= 2:
â”‚                       return parts[1]  # Return trace_id part
â”‚               return None
â”‚       
â”‚       
â”‚       
â”‚       ```
â”‚       
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ loader.py
â”‚       
â”‚       ```py
â”‚       from __future__ import annotations
â”‚       from pathlib import Path
â”‚       from typing import Any, Dict
â”‚       
â”‚       import os
â”‚       import yaml
â”‚       from dotenv import load_dotenv
â”‚       
â”‚       
â”‚       _REPO_ROOT = Path(__file__).resolve()    
â”‚       
â”‚       while _REPO_ROOT.name != "glam-app":
â”‚           if _REPO_ROOT.parent == _REPO_ROOT:
â”‚               raise RuntimeError("Unable to locate glam-app root directory")
â”‚           _REPO_ROOT = _REPO_ROOT.parent
â”‚       
â”‚       _CONFIG_DIR = _REPO_ROOT / "config"                     # ./config
â”‚       _SHARED_CONFIG = _CONFIG_DIR / "shared.yml"            # ./config/shared.yml
â”‚       _SVC_CFG_DIR = _CONFIG_DIR / "services"                 # ./config/services
â”‚       _ENV_FILE = _REPO_ROOT / ".env"                         # optional
â”‚       
â”‚       
â”‚       # Check if files exist
â”‚       print(f"\nFile existence check:")
â”‚       print(f"  .env exists: {_ENV_FILE.exists()}")
â”‚       print(f"  shared.yml exists: {_SHARED_CONFIG.exists()}")
â”‚       print(f"  config/services/ exists: {_SVC_CFG_DIR.exists()}")
â”‚       
â”‚       # Load .env once so os.environ is ready (local runs)
â”‚       if _ENV_FILE.exists():
â”‚           load_dotenv(_ENV_FILE)
â”‚       
â”‚       
â”‚       def _load_yaml_file(path: Path) -> Dict[str, Any]:
â”‚           """Load a YAML file and return dict"""
â”‚           if not path.is_file():
â”‚               return {}
â”‚           with path.open() as f:
â”‚               return yaml.safe_load(f) or {}
â”‚       
â”‚       
â”‚       def _deep_merge(base: Dict[str, Any], override: Dict[str, Any]) -> Dict[str, Any]:
â”‚           """Deep merge two dictionaries, override takes precedence"""
â”‚           result = base.copy()
â”‚           
â”‚           for key, value in override.items():
â”‚               if (key in result and 
â”‚                   isinstance(result[key], dict) and 
â”‚                   isinstance(value, dict)):
â”‚                   result[key] = _deep_merge(result[key], value)
â”‚               else:
â”‚                   result[key] = value
â”‚           
â”‚           return result
â”‚       
â”‚       
â”‚       def merged_config(service: str, *, env_prefix: str) -> Dict[str, Any]:
â”‚           """
â”‚           Load configuration in order of precedence:
â”‚           1. config/shared.yml              -> baseline shared config
â”‚           2. config/services/{service}.yml  -> service-specific config  
â”‚           3. Environment variables           -> runtime overrides
â”‚           
â”‚           YAML                      -> baseline
â”‚           (prefixed) env variables  -> override keys in YAML
â”‚           RESULT                    -> dict ready for Pydantic
â”‚           """
â”‚           
â”‚           # 1. Load shared configuration (baseline)
â”‚           cfg = _load_yaml_file(_SHARED_CONFIG)
â”‚           
â”‚           # 2. Load service-specific configuration and merge
â”‚           service_config_path = _SVC_CFG_DIR / f"{service}.yml"
â”‚           if not service_config_path.is_file():
â”‚               raise FileNotFoundError(f"Service config not found: {service_config_path}")
â”‚           
â”‚           service_config = _load_yaml_file(service_config_path)
â”‚           cfg = _deep_merge(cfg, service_config)
â”‚           
â”‚           # 3. Apply environment variable overrides
â”‚           prefix = f"{env_prefix.upper()}_"
â”‚           for key, val in os.environ.items():
â”‚               if key.startswith(prefix):
â”‚                   yaml_key = key[len(prefix):].lower()
â”‚                   
â”‚                   # Handle nested keys with double underscore
â”‚                   if "__" in yaml_key:
â”‚                       parts = yaml_key.split("__")
â”‚                       current = cfg
â”‚                       
â”‚                       # Navigate/create nested structure
â”‚                       for part in parts[:-1]:
â”‚                           if part not in current:
â”‚                               current[part] = {}
â”‚                           current = current[part]
â”‚                       
â”‚                       # Set the final value
â”‚                       current[parts[-1]] = val
â”‚                   else:
â”‚                       cfg[yaml_key] = val
â”‚           
â”‚           return cfg
â”‚       
â”‚       def flatten_config(data: dict, parent_key: str = '', sep: str = '.') -> dict:
â”‚           """Flatten nested dict for Pydantic validation_alias to work"""
â”‚           items = []
â”‚           for k, v in data.items():
â”‚               new_key = f"{parent_key}{sep}{k}" if parent_key else k
â”‚               if isinstance(v, dict):
â”‚                   items.extend(flatten_config(v, new_key, sep=sep).items())
â”‚               else:
â”‚                   items.append((new_key, v))
â”‚           return dict(items)
â”‚       ```
â”‚       
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # glam-app/shared/database/__init__.py
â”‚   â”‚   """
â”‚   â”‚   Shared database utilities for GLAM microservices.
â”‚   â”‚   
â”‚   â”‚   This package provides:
â”‚   â”‚   - Base SQLAlchemy models and mixins
â”‚   â”‚   - Async session management
â”‚   â”‚   - Generic repository pattern
â”‚   â”‚   - FastAPI dependencies
â”‚   â”‚   - Alembic migration utilities
â”‚   â”‚   - Database configuration
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from .base import Base, TimestampedMixin, SoftDeleteMixin
â”‚   â”‚   from .session import DatabaseSessionManager
â”‚   â”‚   from .repository import Repository
â”‚   â”‚   from .dependencies import (
â”‚   â”‚       DBSessionDep,
â”‚   â”‚       get_db_session,
â”‚   â”‚       set_database_manager,
â”‚   â”‚       get_database_manager,
â”‚   â”‚       get_database_health,
â”‚   â”‚   )
â”‚   â”‚   from .config import DatabaseConfig, create_database_config
â”‚   â”‚   from .migrations import MigrationManager, create_alembic_env_template
â”‚   â”‚   
â”‚   â”‚   __all__ = [
â”‚   â”‚       # Base classes
â”‚   â”‚       "Base",
â”‚   â”‚       "TimestampedMixin",
â”‚   â”‚       "SoftDeleteMixin",
â”‚   â”‚       
â”‚   â”‚       # Session management
â”‚   â”‚       "DatabaseSessionManager",
â”‚   â”‚       
â”‚   â”‚       # Repository pattern
â”‚   â”‚       "Repository",
â”‚   â”‚       
â”‚   â”‚       # FastAPI dependencies
â”‚   â”‚       "DBSessionDep",
â”‚   â”‚       "get_db_session",
â”‚   â”‚       "set_database_manager",
â”‚   â”‚       "get_database_manager",
â”‚   â”‚       "get_database_health",
â”‚   â”‚       
â”‚   â”‚       # Configuration
â”‚   â”‚       "DatabaseConfig",
â”‚   â”‚       "create_database_config",
â”‚   â”‚       
â”‚   â”‚       # Migrations
â”‚   â”‚       "MigrationManager",
â”‚   â”‚       "create_alembic_env_template",
â”‚   â”‚   ]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   
â”‚   â”‚   # glam-app/shared/database/base.py
â”‚   â”‚   from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
â”‚   â”‚   from sqlalchemy.ext.asyncio import AsyncAttrs
â”‚   â”‚   from sqlalchemy.dialects.postgresql import UUID as PGUUID
â”‚   â”‚   from sqlalchemy import DateTime, String, func, Index, MetaData
â”‚   â”‚   from datetime import datetime
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class Base(AsyncAttrs, DeclarativeBase):
â”‚   â”‚       __abstract__ = True            # <- prevents accidental table mapping
â”‚   â”‚   
â”‚   â”‚       # optional: naming convention for Alembic
â”‚   â”‚       metadata = MetaData(naming_convention={
â”‚   â”‚           "ix": "ix_%(column_0_label)s",
â”‚   â”‚           "uq": "uq_%(table_name)s_%(column_0_name)s",
â”‚   â”‚           "ck": "ck_%(table_name)s_%(constraint_name)s",
â”‚   â”‚           "fk": "fk_%(table_name)s_%(column_0_name)s_%(referred_table_name)s",
â”‚   â”‚           "pk": "pk_%(table_name)s"
â”‚   â”‚       })
â”‚   â”‚   
â”‚   â”‚   class MerchantMixin:
â”‚   â”‚       """Mixin to add merchant_id to any model"""
â”‚   â”‚       merchant_id: Mapped[UUID] = mapped_column(
â”‚   â”‚           PGUUID(as_uuid=True), 
â”‚   â”‚           nullable=False, 
â”‚   â”‚           index=True
â”‚   â”‚       )
â”‚   â”‚       merchant_domain: Mapped[str] = mapped_column(
â”‚   â”‚           String(255), 
â”‚   â”‚           nullable=False, 
â”‚   â”‚           index=True
â”‚   â”‚       )
â”‚   â”‚       __table_args__ = (
â”‚   â”‚       Index("idx_merchant_id_domain", "merchant_id", "merchant_domain"),)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class TimestampedMixin:
â”‚   â”‚       """Mixin to add created_at and updated_at to any model"""
â”‚   â”‚       created_at = mapped_column( DateTime(timezone=True), server_default=func.now(), nullable=False, index=True )
â”‚   â”‚       updated_at = mapped_column( DateTime(timezone=True), server_default=func.now(), server_onupdate=func.now(), nullable=False )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class SoftDeleteMixin:
â”‚   â”‚       """Mixin to add soft delete functionality"""
â”‚   â”‚       deleted_at: Mapped[datetime | None] = mapped_column(
â”‚   â”‚           DateTime(timezone=True),
â”‚   â”‚           default=None)
â”‚   â”‚       is_deleted: Mapped[bool] = mapped_column(default=False, index=True)
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # glam-app/shared/database/config.py
â”‚   â”‚   from __future__ import annotations
â”‚   â”‚   from pydantic_settings import BaseSettings, SettingsConfigDict
â”‚   â”‚   from pydantic import Field
â”‚   â”‚   from typing import Any, Dict
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class DatabaseConfig(BaseSettings):
â”‚   â”‚       # â”€â”€ connection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”‚       DB_HOST: str
â”‚   â”‚       DB_PORT: int = 5432
â”‚   â”‚       DB_PORT_EXTERNAL: int | None = None
â”‚   â”‚       DB_NAME: str
â”‚   â”‚       DB_USER: str
â”‚   â”‚       DB_PASSWORD: str
â”‚   â”‚       DB_ENABLED: bool = True
â”‚   â”‚   
â”‚   â”‚       # â”€â”€ pool / driver â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”‚       DB_POOL_SIZE: int = 5
â”‚   â”‚       DB_MAX_OVERFLOW: int = 10
â”‚   â”‚       DB_POOL_PRE_PING: bool = True
â”‚   â”‚       DB_POOL_RECYCLE: int = 3600
â”‚   â”‚       DB_ASYNC_DRIVER: str = "asyncpg"
â”‚   â”‚       DB_ECHO: bool = False
â”‚   â”‚   
â”‚   â”‚       # defaults: `.env` at repo root, strict case match
â”‚   â”‚       model_config = SettingsConfigDict(
â”‚   â”‚           env_file=".env",
â”‚   â”‚           env_file_encoding="utf-8",
â”‚   â”‚           case_sensitive=True,          # "CREDIT_DB_HOST" must match exactly
â”‚   â”‚           populate_by_name=True,
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚       # â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â”‚   â”‚       def model_post_init(self, _ctx: Any) -> None:
â”‚   â”‚           if self.DB_PORT is None:
â”‚   â”‚               if self.DB_HOST in {"localhost", "127.0.0.1", "host.docker.internal"}:
â”‚   â”‚                   self.DB_PORT = self.DB_PORT_EXTERNAL or 5432
â”‚   â”‚               else:
â”‚   â”‚                   self.DB_PORT = 5432
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def effective_port(self) -> int:
â”‚   â”‚           """Return host-side port when talking to localhost, else the container port."""
â”‚   â”‚           if self.DB_HOST in {"localhost", "127.0.0.1", "host.docker.internal"}:
â”‚   â”‚               return self.DB_PORT_EXTERNAL or self.DB_PORT
â”‚   â”‚           return self.DB_PORT
â”‚   â”‚       
â”‚   â”‚       @property
â”‚   â”‚       def database_url(self) -> str:
â”‚   â”‚           return (
â”‚   â”‚               f"postgresql+{self.DB_ASYNC_DRIVER}://"
â”‚   â”‚               f"{self.DB_USER}:{self.DB_PASSWORD}@"
â”‚   â”‚               f"{self.DB_HOST}:{self.effective_port}/{self.DB_NAME}"
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       def engine_kwargs(self) -> Dict[str, Any]:
â”‚   â”‚           return dict(
â”‚   â”‚               echo=self.DB_ECHO,
â”‚   â”‚               pool_size=self.DB_POOL_SIZE,
â”‚   â”‚               max_overflow=self.DB_MAX_OVERFLOW,
â”‚   â”‚               pool_pre_ping=self.DB_POOL_PRE_PING,
â”‚   â”‚               pool_recycle=self.DB_POOL_RECYCLE,
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def create_database_config(prefix: str) -> DatabaseConfig:
â”‚   â”‚       """Factory that applies the per-service prefix (CREDIT_, NOTIFICATION_, â€¦)."""
â”‚   â”‚       class Prefixed(DatabaseConfig):
â”‚   â”‚           model_config = SettingsConfigDict(
â”‚   â”‚               env_prefix=prefix,         # CREDIT_DB_HOST, etc.
â”‚   â”‚               env_file=".env",
â”‚   â”‚               case_sensitive=True,
â”‚   â”‚               populate_by_name=True,
â”‚   â”‚           )
â”‚   â”‚       return Prefixed() # type: ignore[call-arg]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # glam-app/shared/database/dependencies.py
â”‚   â”‚   from typing import Annotated, AsyncGenerator
â”‚   â”‚   from fastapi import Depends
â”‚   â”‚   from sqlalchemy.ext.asyncio import AsyncSession
â”‚   â”‚   from .session import DatabaseSessionManager
â”‚   â”‚   
â”‚   â”‚   # Global database manager instance - each service will set this
â”‚   â”‚   from typing import Optional
â”‚   â”‚   
â”‚   â”‚   _db_manager: Optional[DatabaseSessionManager] = None
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def set_database_manager(manager: DatabaseSessionManager):
â”‚   â”‚       """Set the global database manager for the service"""
â”‚   â”‚       global _db_manager
â”‚   â”‚       _db_manager = manager
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def get_database_manager() -> DatabaseSessionManager:
â”‚   â”‚       """Get the current database manager"""
â”‚   â”‚       if _db_manager is None:
â”‚   â”‚           raise RuntimeError(
â”‚   â”‚               "Database manager not initialized. "
â”‚   â”‚               "Call set_database_manager() during app startup."
â”‚   â”‚           )
â”‚   â”‚       return _db_manager
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   async def get_db_session() -> AsyncGenerator[AsyncSession, None]:
â”‚   â”‚       """FastAPI dependency to get a database session"""
â”‚   â”‚       manager = get_database_manager()
â”‚   â”‚       async with manager.session() as session:
â”‚   â”‚           yield session
â”‚   â”‚           
â”‚   â”‚   async def get_database_health() -> bool:
â”‚   â”‚       """Check if the database is healthy"""
â”‚   â”‚       manager = get_database_manager()
â”‚   â”‚       try:
â”‚   â”‚           async with manager.session() as session:
â”‚   â”‚               # Perform a simple query to check connectivity
â”‚   â”‚               from sqlalchemy.sql import text
â”‚   â”‚               await session.execute(text("SELECT 1"))
â”‚   â”‚           return True
â”‚   â”‚       except Exception as e:
â”‚   â”‚           # Log the error or handle it as needed
â”‚   â”‚           print(f"Database health check failed: {e}")
â”‚   â”‚           return False
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   # Type alias for dependency injection
â”‚   â”‚   DBSessionDep = Annotated[AsyncSession, Depends(get_db_session)]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ migrations.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # glam-app/shared/database/migrations.py
â”‚   â”‚   import os
â”‚   â”‚   from pathlib import Path
â”‚   â”‚   from alembic import command
â”‚   â”‚   from alembic.config import Config
â”‚   â”‚   from sqlalchemy import text
â”‚   â”‚   from sqlalchemy.ext.asyncio import AsyncEngine
â”‚   â”‚   import logging
â”‚   â”‚   
â”‚   â”‚   logger = logging.getLogger(__name__)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class MigrationManager:
â”‚   â”‚       """Manages Alembic migrations for a microservice"""
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           service_name: str,
â”‚   â”‚           alembic_ini_path: str,
â”‚   â”‚           migrations_path: str,
â”‚   â”‚           database_url: str
â”‚   â”‚       ):
â”‚   â”‚           self.service_name = service_name
â”‚   â”‚           self.alembic_ini_path = Path(alembic_ini_path)
â”‚   â”‚           self.migrations_path = Path(migrations_path)
â”‚   â”‚           self.database_url = database_url
â”‚   â”‚           
â”‚   â”‚           # Verify paths exist
â”‚   â”‚           if not self.alembic_ini_path.exists():
â”‚   â”‚               raise FileNotFoundError(f"Alembic config not found: {alembic_ini_path}")
â”‚   â”‚           
â”‚   â”‚           # Create migrations directory if it doesn't exist
â”‚   â”‚           self.migrations_path.mkdir(parents=True, exist_ok=True)
â”‚   â”‚       
â”‚   â”‚       def get_alembic_config(self) -> Config:
â”‚   â”‚           """Get Alembic configuration"""
â”‚   â”‚           config = Config(str(self.alembic_ini_path))
â”‚   â”‚           config.set_main_option("sqlalchemy.url", self.database_url)
â”‚   â”‚           config.set_main_option("script_location", str(self.migrations_path))
â”‚   â”‚           return config
â”‚   â”‚       
â”‚   â”‚       def init_alembic(self):
â”‚   â”‚           """Initialize Alembic for the service (run once)"""
â”‚   â”‚           config = self.get_alembic_config()
â”‚   â”‚           command.init(config, str(self.migrations_path))
â”‚   â”‚           logger.info(f"Initialized Alembic for {self.service_name}")
â”‚   â”‚       
â”‚   â”‚       def create_migration(self, message: str):
â”‚   â”‚           """Create a new migration"""
â”‚   â”‚           config = self.get_alembic_config()
â”‚   â”‚           command.revision(config, message=message, autogenerate=True)
â”‚   â”‚           logger.info(f"Created migration: {message}")
â”‚   â”‚       
â”‚   â”‚       def upgrade(self, revision: str = "head"):
â”‚   â”‚           """Apply migrations up to a specific revision"""
â”‚   â”‚           config = self.get_alembic_config()
â”‚   â”‚           command.upgrade(config, revision)
â”‚   â”‚           logger.info(f"Upgraded database to {revision}")
â”‚   â”‚       
â”‚   â”‚       def downgrade(self, revision: str):
â”‚   â”‚           """Downgrade to a specific revision"""
â”‚   â”‚           config = self.get_alembic_config()
â”‚   â”‚           command.downgrade(config, revision)
â”‚   â”‚           logger.info(f"Downgraded database to {revision}")
â”‚   â”‚       
â”‚   â”‚       def get_current_revision(self) -> str:
â”‚   â”‚           """Get the current migration revision"""
â”‚   â”‚           config = self.get_alembic_config()
â”‚   â”‚           # This would require more implementation
â”‚   â”‚           return "Not implemented"
â”‚   â”‚       
â”‚   â”‚       async def ensure_schema_exists(self, engine: AsyncEngine, schema_name: str):
â”‚   â”‚           """Ensure a database schema exists (PostgreSQL specific)"""
â”‚   â”‚           async with engine.connect() as conn:
â”‚   â”‚               await conn.execute(
â”‚   â”‚                   text(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
â”‚   â”‚               )
â”‚   â”‚               await conn.commit()
â”‚   â”‚           logger.info(f"Ensured schema exists: {schema_name}")
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def create_alembic_env_template(service_name: str, base_module: str) -> str:
â”‚   â”‚       """Generate env.py template for a service"""
â”‚   â”‚       return f'''"""Alembic environment script for {service_name}"""
â”‚   â”‚   from logging.config import fileConfig
â”‚   â”‚   from sqlalchemy import engine_from_config, pool
â”‚   â”‚   from alembic import context
â”‚   â”‚   
â”‚   â”‚   # Import your service's Base metadata
â”‚   â”‚   from {base_module} import Base
â”‚   â”‚   
â”‚   â”‚   config = context.config
â”‚   â”‚   
â”‚   â”‚   if config.config_file_name is not None:
â”‚   â”‚       fileConfig(config.config_file_name)
â”‚   â”‚   
â”‚   â”‚   target_metadata = Base.metadata
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def run_migrations_offline() -> None:
â”‚   â”‚       """Run migrations in 'offline' mode."""
â”‚   â”‚       url = config.get_main_option("sqlalchemy.url")
â”‚   â”‚       context.configure(
â”‚   â”‚           url=url,
â”‚   â”‚           target_metadata=target_metadata,
â”‚   â”‚           literal_binds=True,
â”‚   â”‚           dialect_opts={{"paramstyle": "named"}},
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚       with context.begin_transaction():
â”‚   â”‚           context.run_migrations()
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def run_migrations_online() -> None:
â”‚   â”‚       """Run migrations in 'online' mode."""
â”‚   â”‚       connectable = engine_from_config(
â”‚   â”‚           config.get_section(config.config_ini_section),
â”‚   â”‚           prefix="sqlalchemy.",
â”‚   â”‚           poolclass=pool.NullPool,
â”‚   â”‚       )
â”‚   â”‚   
â”‚   â”‚       with connectable.connect() as connection:
â”‚   â”‚           context.configure(
â”‚   â”‚               connection=connection,
â”‚   â”‚               target_metadata=target_metadata
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚           with context.begin_transaction():
â”‚   â”‚               context.run_migrations()
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   if context.is_offline_mode():
â”‚   â”‚       run_migrations_offline()
â”‚   â”‚   else:
â”‚   â”‚       run_migrations_online()
â”‚   â”‚   '''
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ repository.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # glam-app/shared/database/repository.py
â”‚   â”‚   from sqlalchemy import select
â”‚   â”‚   from typing import TypeVar, Generic, Type, AsyncIterator
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   from sqlalchemy.ext.asyncio import async_sessionmaker
â”‚   â”‚   from sqlalchemy.ext.asyncio import AsyncSession
â”‚   â”‚   from .base import Base
â”‚   â”‚   
â”‚   â”‚   T = TypeVar("T", bound=Base)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class Repository(Generic[T]):
â”‚   â”‚       """
â”‚   â”‚       Generic repository providing basic CRUD operations.
â”‚   â”‚       Services can extend this for specific domain needs.
â”‚   â”‚       """
â”‚   â”‚       
â”‚   â”‚       def __init__(self, model: Type[T], session_factory: async_sessionmaker[AsyncSession]):
â”‚   â”‚           self.model = model
â”‚   â”‚           self.session_factory = session_factory
â”‚   â”‚   
â”‚   â”‚       # helper used by child methods
â”‚   â”‚       async def _session(self) -> AsyncIterator[AsyncSession]:
â”‚   â”‚           async with self.session_factory() as session:
â”‚   â”‚               yield session
â”‚   â”‚   
â”‚   â”‚       async def save(self, instance: T) -> T | None:
â”‚   â”‚           """Save an instance to the database"""
â”‚   â”‚           async for session in self._session():
â”‚   â”‚               session.add(instance)
â”‚   â”‚               await session.commit()
â”‚   â”‚               return instance
â”‚   â”‚       
â”‚   â”‚       async def update(self, instance: T) -> T | None:
â”‚   â”‚           """Update an existing instance"""
â”‚   â”‚           async for session in self._session():
â”‚   â”‚               await session.merge(instance)
â”‚   â”‚               await session.commit()
â”‚   â”‚               return instance
â”‚   â”‚           
â”‚   â”‚       async def delete(self, instance: T) -> None:
â”‚   â”‚           """Delete an instance from the database"""
â”‚   â”‚           async for session in self._session():
â”‚   â”‚               await session.delete(instance)
â”‚   â”‚               await session.commit()
â”‚   â”‚       
â”‚   â”‚       async def delete_by_id(self, id: str | UUID) -> None:
â”‚   â”‚           """Delete an instance by its ID"""
â”‚   â”‚           async for session in self._session():
â”‚   â”‚               instance = await session.get(self.model, id)
â”‚   â”‚               if instance:
â”‚   â”‚                   await session.delete(instance)
â”‚   â”‚                   await session.commit()
â”‚   â”‚           
â”‚   â”‚       async def find_by_id(self, id: str | UUID) -> T | None:
â”‚   â”‚           """Find an instance by its ID"""
â”‚   â”‚           async for session in self._session():
â”‚   â”‚               result = await session.get(self.model, id)
â”‚   â”‚               return result
â”‚   â”‚           
â”‚   â”‚       async def find_all(
â”‚   â”‚           self,
â”‚   â”‚           * ,
â”‚   â”‚           limit: int | None = None,
â”‚   â”‚           offset: int | None = None,
â”‚   â”‚           **filters
â”‚   â”‚       ) -> list[T] | None:
â”‚   â”‚           """
â”‚   â”‚           Return a list of model instances.
â”‚   â”‚           Optional keyword filters map column names to values (exact match).
â”‚   â”‚           You can also page results with limit/offset.
â”‚   â”‚           """
â”‚   â”‚           async for session in self._session():
â”‚   â”‚               stmt = select(self.model)
â”‚   â”‚   
â”‚   â”‚               # Apply column == value filters
â”‚   â”‚               for col, val in filters.items():
â”‚   â”‚                   try:
â”‚   â”‚                       stmt = stmt.where(getattr(self.model, col) == val)
â”‚   â”‚                   except AttributeError:
â”‚   â”‚                       raise ValueError(f"{col!r} is not a valid column on {self.model.__name__}")
â”‚   â”‚   
â”‚   â”‚               # Pagination
â”‚   â”‚               if offset is not None:
â”‚   â”‚                   stmt = stmt.offset(offset)
â”‚   â”‚               if limit is not None:
â”‚   â”‚                   stmt = stmt.limit(limit)
â”‚   â”‚   
â”‚   â”‚               result = await session.execute(stmt)
â”‚   â”‚               return list(result.scalars().all())
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ session.py
â”‚       
â”‚       ```py
â”‚       # glam-app/shared/database/session.py
â”‚       from sqlalchemy.ext.asyncio import (
â”‚           create_async_engine,
â”‚           AsyncSession,
â”‚           async_sessionmaker,
â”‚           AsyncEngine
â”‚       )
â”‚       from contextlib import asynccontextmanager
â”‚       from typing import AsyncGenerator, Optional
â”‚       import logging
â”‚       
â”‚       logger = logging.getLogger(__name__)
â”‚       
â”‚       
â”‚       class DatabaseSessionManager:
â”‚           """
â”‚           Manages database connections and sessions for a microservice.
â”‚           Each service creates its own instance with its specific configuration.
â”‚           """
â”‚           
â”‚           def __init__(
â”‚               self,
â”‚               database_url: str,
â”‚               echo: bool = False,
â”‚               pool_size: int = 5,
â”‚               max_overflow: int = 10,
â”‚               pool_pre_ping: bool = True,
â”‚               pool_recycle: int = 3600
â”‚           ):
â”‚               self.database_url = database_url
â”‚               self._engine: Optional[AsyncEngine] = None
â”‚               self._session_factory: Optional[async_sessionmaker[AsyncSession]] = None
â”‚               
â”‚               # Engine configuration
â”‚               self.engine_config = {
â”‚                   "echo": echo,
â”‚                   "pool_size": pool_size,
â”‚                   "max_overflow": max_overflow,
â”‚                   "pool_pre_ping": pool_pre_ping,
â”‚                   "pool_recycle": pool_recycle,
â”‚               }
â”‚           
â”‚           async def init(self):
â”‚               """Initialize the database engine and session factory"""
â”‚               if self._engine is not None:
â”‚                   raise RuntimeError("Database session manager already initialized")
â”‚               
â”‚               self._engine = create_async_engine(
â”‚                   self.database_url,
â”‚                   **self.engine_config
â”‚               )
â”‚               
â”‚               self._session_factory = async_sessionmaker(
â”‚                   bind=self._engine,
â”‚                   class_=AsyncSession,
â”‚                   autocommit=False,
â”‚                   autoflush=False,
â”‚                   expire_on_commit=False
â”‚               )
â”‚               
â”‚               logger.info(f"Database engine initialized with URL: {self.database_url}")
â”‚           
â”‚           async def close(self):
â”‚               """Close the database engine"""
â”‚               if self._engine is None:
â”‚                   raise RuntimeError("Database session manager not initialized")
â”‚               
â”‚               await self._engine.dispose()
â”‚               self._engine = None
â”‚               self._session_factory = None
â”‚               logger.info("Database engine closed")
â”‚           
â”‚           @asynccontextmanager
â”‚           async def get_session(self) -> AsyncGenerator[AsyncSession, None]:
â”‚               if self._session_factory is None:
â”‚                   raise RuntimeError("Database session manager not initialized")
â”‚               
â”‚               async with self._session_factory() as session:
â”‚                   try:
â”‚                       yield session
â”‚                       await session.commit()
â”‚                   except Exception:
â”‚                       await session.rollback()
â”‚                       raise
â”‚                   finally:
â”‚                       await session.close()
â”‚           
â”‚           @property
â”‚           def engine(self) -> AsyncEngine:
â”‚               """Get the underlying SQLAlchemy engine"""
â”‚               if self._engine is None:
â”‚                   raise RuntimeError("Database session manager not initialized")
â”‚               return self._engine
â”‚           
â”‚           @property
â”‚           def session_factory(self) -> async_sessionmaker[AsyncSession]:
â”‚               """Get the session factory"""
â”‚               if self._session_factory is None:
â”‚                   raise RuntimeError("Database session manager not initialized")
â”‚               return self._session_factory
â”‚       ```
â”‚       
â”œâ”€â”€ errors/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/__init__.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """
â”‚   â”‚   Shared error handling module for glam-app microservices.
â”‚   â”‚   
â”‚   â”‚   This module provides a consistent error hierarchy and handling patterns
â”‚   â”‚   across all services, following the three-tier model:
â”‚   â”‚   - BaseError (root)
â”‚   â”‚   - InfrastructureError (external failures)
â”‚   â”‚   - DomainError (business logic failures)
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from .base import (
â”‚   â”‚       GlamBaseError,
â”‚   â”‚       InfrastructureError,
â”‚   â”‚       DomainError,
â”‚   â”‚       ValidationError,
â”‚   â”‚       NotFoundError,
â”‚   â”‚       ConflictError,
â”‚   â”‚       UnauthorizedError,
â”‚   â”‚       ForbiddenError,
â”‚   â”‚       RateLimitedError,
â”‚   â”‚       ServiceUnavailableError,
â”‚   â”‚       RequestTimeoutError,
â”‚   â”‚       InternalError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .catalog import (
â”‚   â”‚       SyncInProgressError,
â”‚   â”‚       SyncNotFoundError,
â”‚   â”‚       SyncNotResumableError,
â”‚   â”‚       SyncNotCancellableError,
â”‚   â”‚       ItemNotFoundError,
â”‚   â”‚       ParentSyncNotFoundError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .profile import (
â”‚   â”‚       ProfileNotFoundError,
â”‚   â”‚       ProfileAlreadyExistsError,
â”‚   â”‚       ProfileCreationFailedError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .analysis import (
â”‚   â”‚       AnalysisInProgressError,
â”‚   â”‚       AnalysisNotFoundError,
â”‚   â”‚       AnalysisNotCancellableError,
â”‚   â”‚       NoCurrentAnalysisError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .selfie import (
â”‚   â”‚       SelfieNotFoundError,
â”‚   â”‚       InvalidImageFormatError,
â”‚   â”‚       ImageTooLargeError,
â”‚   â”‚       ImageTooSmallError,
â”‚   â”‚       NoFaceDetectedError,
â”‚   â”‚       MultipleFacesDetectedError,
â”‚   â”‚       PoorImageQualityError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .notification import (
â”‚   â”‚       NotificationNotFoundError,
â”‚   â”‚       TemplateNotFoundError,
â”‚   â”‚       TemplateRenderError,
â”‚   â”‚       InvalidRecipientError,
â”‚   â”‚       PreferencesNotFoundError,
â”‚   â”‚       EmailProviderError,
â”‚   â”‚       UnsubscribedError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .infrastructure import (
â”‚   â”‚       DatabaseError,
â”‚   â”‚       RedisError,
â”‚   â”‚       S3Error,
â”‚   â”‚       UpstreamServiceError,
â”‚   â”‚       CircuitOpenError,
â”‚   â”‚       MessageBusError,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   from .utils import (
â”‚   â”‚       wrap_external_error,
â”‚   â”‚       classify_http_error,
â”‚   â”‚       is_retryable_error,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   __all__ = [
â”‚   â”‚       # Base errors
â”‚   â”‚       "GlamBaseError",
â”‚   â”‚       "InfrastructureError",
â”‚   â”‚       "DomainError",
â”‚   â”‚       # Common domain errors
â”‚   â”‚       "ValidationError",
â”‚   â”‚       "NotFoundError",
â”‚   â”‚       "ConflictError",
â”‚   â”‚       "UnauthorizedError",
â”‚   â”‚       "ForbiddenError",
â”‚   â”‚       "RateLimitedError",
â”‚   â”‚       "ServiceUnavailableError",
â”‚   â”‚       "InternalError",
â”‚   â”‚       # Catalog errors
â”‚   â”‚       "SyncInProgressError",
â”‚   â”‚       "SyncNotFoundError",
â”‚   â”‚       "SyncNotResumableError",
â”‚   â”‚       "SyncNotCancellableError",
â”‚   â”‚       "ItemNotFoundError",
â”‚   â”‚       "ParentSyncNotFoundError",
â”‚   â”‚       # Profile errors
â”‚   â”‚       "ProfileNotFoundError",
â”‚   â”‚       "ProfileAlreadyExistsError",
â”‚   â”‚       "ProfileCreationFailedError",
â”‚   â”‚       # Analysis errors
â”‚   â”‚       "AnalysisInProgressError",
â”‚   â”‚       "AnalysisNotFoundError",
â”‚   â”‚       "AnalysisNotCancellableError",
â”‚   â”‚       "NoCurrentAnalysisError",
â”‚   â”‚       # Selfie errors
â”‚   â”‚       "SelfieNotFoundError",
â”‚   â”‚       "InvalidImageFormatError",
â”‚   â”‚       "ImageTooLargeError",
â”‚   â”‚       "ImageTooSmallError",
â”‚   â”‚       "NoFaceDetectedError",
â”‚   â”‚       "MultipleFacesDetectedError",
â”‚   â”‚       "PoorImageQualityError",
â”‚   â”‚       # Notification errors
â”‚   â”‚       "NotificationNotFoundError",
â”‚   â”‚       "TemplateNotFoundError",
â”‚   â”‚       "TemplateRenderError",
â”‚   â”‚       "InvalidRecipientError",
â”‚   â”‚       "PreferencesNotFoundError",
â”‚   â”‚       "EmailProviderError",
â”‚   â”‚       "UnsubscribedError",
â”‚   â”‚       # Infrastructure errors
â”‚   â”‚       "DatabaseError",
â”‚   â”‚       "RedisError",
â”‚   â”‚       "S3Error",
â”‚   â”‚       "UpstreamServiceError",
â”‚   â”‚       "CircuitOpenError",
â”‚   â”‚       "MessageBusError",
â”‚   â”‚       # Handlers and utilities
â”‚   â”‚       "wrap_external_error",
â”‚   â”‚       "classify_http_error",
â”‚   â”‚       "is_retryable_error",
â”‚   â”‚   ]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ analysis.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/analysis.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Analysis service specific errors."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional
â”‚   â”‚   from .base import ConflictError, NotFoundError
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class AnalysisInProgressError(ConflictError):
â”‚   â”‚       """Another analysis is already in progress."""
â”‚   â”‚       
â”‚   â”‚       code = "ANALYSIS_IN_PROGRESS"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Another analysis is already in progress",
â”‚   â”‚           *,
â”‚   â”‚           current_analysis_id: Optional[str] = None,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           started_at: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if current_analysis_id:
â”‚   â”‚               self.details["current_analysis_id"] = current_analysis_id
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚           if started_at:
â”‚   â”‚               self.details["started_at"] = started_at
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class AnalysisNotFoundError(NotFoundError):
â”‚   â”‚       """Analysis not found."""
â”‚   â”‚       
â”‚   â”‚       code = "ANALYSIS_NOT_FOUND"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           analysis_id: Optional[str] = None,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, resource="analysis", resource_id=analysis_id, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class AnalysisNotCancellableError(ConflictError):
â”‚   â”‚       """Analysis cannot be cancelled in its current state."""
â”‚   â”‚       
â”‚   â”‚       code = "ANALYSIS_NOT_CANCELLABLE"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           analysis_id: Optional[str] = None,
â”‚   â”‚           current_status: Optional[str] = None,
â”‚   â”‚           reason: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if analysis_id:
â”‚   â”‚               self.details["analysis_id"] = analysis_id
â”‚   â”‚           if current_status:
â”‚   â”‚               self.details["current_status"] = current_status
â”‚   â”‚           if reason:
â”‚   â”‚               self.details["reason"] = reason
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class NoCurrentAnalysisError(NotFoundError):
â”‚   â”‚       """No completed analysis available."""
â”‚   â”‚       
â”‚   â”‚       code = "NO_CURRENT_ANALYSIS"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "No completed analysis available",
â”‚   â”‚           *,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, resource="current_analysis", **kwargs)
â”‚   â”‚           
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/base.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """
â”‚   â”‚   Base error classes for the glam-app error hierarchy.
â”‚   â”‚   
â”‚   â”‚   This module defines the fundamental error types that all other
â”‚   â”‚   errors inherit from, following a three-tier model:
â”‚   â”‚   1. GlamBaseError - Root of all application errors
â”‚   â”‚   2. InfrastructureError - External system failures
â”‚   â”‚   3. DomainError - Business logic violations
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from typing import Any, Dict, Optional
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class GlamBaseError(Exception):
â”‚   â”‚       """
â”‚   â”‚       Base class for all glam-app errors.
â”‚   â”‚   
â”‚   â”‚       Attributes:
â”‚   â”‚           code: Stable error code for clients (e.g., "VALIDATION_ERROR")
â”‚   â”‚           status: HTTP status code (default 500)
â”‚   â”‚           message: Human-readable error message
â”‚   â”‚           details: Additional error context
â”‚   â”‚           __cause__: Original exception if wrapped
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       code: str = "INTERNAL_ERROR"
â”‚   â”‚       status: int = 500
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           code: Optional[str] = None,
â”‚   â”‚           status: Optional[int] = None,
â”‚   â”‚           details: Optional[Dict[str, Any]] = None,
â”‚   â”‚           cause: Optional[Exception] = None
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message)
â”‚   â”‚   
â”‚   â”‚           if code is not None:
â”‚   â”‚               self.code = code
â”‚   â”‚           if status is not None:
â”‚   â”‚               self.status = status
â”‚   â”‚   
â”‚   â”‚           self.message = message
â”‚   â”‚           self.details = details or {}
â”‚   â”‚   
â”‚   â”‚           # Preserve the original exception chain
â”‚   â”‚           if cause is not None:
â”‚   â”‚               self.__cause__ = cause
â”‚   â”‚   
â”‚   â”‚       def to_dict(self) -> Dict[str, Any]:
â”‚   â”‚           """Convert error to dictionary for JSON serialization."""
â”‚   â”‚           result: Dict[str, Any] = {
â”‚   â”‚               "code": self.code,
â”‚   â”‚               "message": self.message,
â”‚   â”‚           }
â”‚   â”‚   
â”‚   â”‚           if self.details:
â”‚   â”‚               result["details"] = self.details
â”‚   â”‚   
â”‚   â”‚           return result
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class InfrastructureError(GlamBaseError):
â”‚   â”‚       """
â”‚   â”‚       Infrastructure/external system errors.
â”‚   â”‚   
â”‚   â”‚       These are failures in external dependencies like databases,
â”‚   â”‚       APIs, message queues, etc. They may be retryable.
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       code = "INFRASTRUCTURE_ERROR"
â”‚   â”‚       status = 503  # Service Unavailable
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           service: Optional[str] = None,
â”‚   â”‚           retryable: bool = True,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if service:
â”‚   â”‚               self.details["service"] = service
â”‚   â”‚   
â”‚   â”‚           self.details["retryable"] = retryable
â”‚   â”‚           self.retryable = retryable
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class DomainError(GlamBaseError):
â”‚   â”‚       """
â”‚   â”‚       Domain/business logic errors.
â”‚   â”‚   
â”‚   â”‚       These represent violations of business rules or invalid
â”‚   â”‚       operations within the application domain.
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       code = "DOMAIN_ERROR"
â”‚   â”‚       status = 400  # Bad Request
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   # Common domain errors used across services
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ValidationError(DomainError):
â”‚   â”‚       """Invalid request data or parameters."""
â”‚   â”‚   
â”‚   â”‚       code = "VALIDATION_ERROR"
â”‚   â”‚       status = 422  # Unprocessable Entity
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           field: Optional[str] = None,
â”‚   â”‚           value: Optional[Any] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if field:
â”‚   â”‚               self.details["field"] = field
â”‚   â”‚           if value is not None:
â”‚   â”‚               self.details["value"] = str(value)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class NotFoundError(DomainError):
â”‚   â”‚       """Requested resource not found."""
â”‚   â”‚   
â”‚   â”‚       code = "NOT_FOUND"
â”‚   â”‚       status = 404
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           resource: Optional[str] = None,
â”‚   â”‚           resource_id: Optional[Any] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if resource:
â”‚   â”‚               self.details["resource"] = resource
â”‚   â”‚           if resource_id is not None:
â”‚   â”‚               self.details["resource_id"] = str(resource_id)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ConflictError(DomainError):
â”‚   â”‚       """Operation conflicts with current state."""
â”‚   â”‚   
â”‚   â”‚       code = "CONFLICT"
â”‚   â”‚       status = 409
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           conflicting_resource: Optional[str] = None,
â”‚   â”‚           current_state: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if conflicting_resource:
â”‚   â”‚               self.details["conflicting_resource"] = conflicting_resource
â”‚   â”‚           if current_state:
â”‚   â”‚               self.details["current_state"] = current_state
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class UnauthorizedError(DomainError):
â”‚   â”‚       """Authentication required or failed."""
â”‚   â”‚   
â”‚   â”‚       code = "UNAUTHORIZED"
â”‚   â”‚       status = 401
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Authentication required",
â”‚   â”‚           *,
â”‚   â”‚           auth_type: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if auth_type:
â”‚   â”‚               self.details["auth_type"] = auth_type
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ForbiddenError(DomainError):
â”‚   â”‚       """Authenticated but insufficient permissions."""
â”‚   â”‚   
â”‚   â”‚       code = "FORBIDDEN"
â”‚   â”‚       status = 403
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Insufficient permissions",
â”‚   â”‚           *,
â”‚   â”‚           required_permission: Optional[str] = None,
â”‚   â”‚           resource: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if required_permission:
â”‚   â”‚               self.details["required_permission"] = required_permission
â”‚   â”‚           if resource:
â”‚   â”‚               self.details["resource"] = resource
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class RateLimitedError(DomainError):
â”‚   â”‚       """Too many requests."""
â”‚   â”‚   
â”‚   â”‚       code = "RATE_LIMITED"
â”‚   â”‚       status = 429
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Rate limit exceeded",
â”‚   â”‚           *,
â”‚   â”‚           limit: Optional[int] = None,
â”‚   â”‚           window: Optional[str] = None,
â”‚   â”‚           retry_after: Optional[int] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if limit:
â”‚   â”‚               self.details["limit"] = limit
â”‚   â”‚           if window:
â”‚   â”‚               self.details["window"] = window
â”‚   â”‚           if retry_after:
â”‚   â”‚               self.details["retry_after"] = retry_after
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ServiceUnavailableError(InfrastructureError):
â”‚   â”‚       """Service temporarily unavailable."""
â”‚   â”‚   
â”‚   â”‚       code = "SERVICE_UNAVAILABLE"
â”‚   â”‚       status = 503
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class RequestTimeoutError(InfrastructureError):
â”‚   â”‚       """Operation timed out."""
â”‚   â”‚   
â”‚   â”‚       code = "TIMEOUT"
â”‚   â”‚       status = 504
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           timeout_seconds: Optional[float] = None,
â”‚   â”‚           operation: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if timeout_seconds:
â”‚   â”‚               self.details["timeout_seconds"] = timeout_seconds
â”‚   â”‚           if operation:
â”‚   â”‚               self.details["operation"] = operation
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class InternalError(GlamBaseError):
â”‚   â”‚       """Unexpected internal server error."""
â”‚   â”‚   
â”‚   â”‚       code = "INTERNAL_ERROR"
â”‚   â”‚       status = 500
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "An unexpected error occurred",
â”‚   â”‚           *,
â”‚   â”‚           error_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           # Never expose internal details in production
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if error_id:
â”‚   â”‚               self.details["error_id"] = error_id
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ catalog.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/catalog.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Catalog service specific errors."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional
â”‚   â”‚   from .base import ConflictError, NotFoundError
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class SyncInProgressError(ConflictError):
â”‚   â”‚       """Another sync operation is already running."""
â”‚   â”‚       
â”‚   â”‚       code = "SYNC_IN_PROGRESS"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Another sync is already in progress",
â”‚   â”‚           *,
â”‚   â”‚           current_sync_id: Optional[str] = None,
â”‚   â”‚           merchant_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if current_sync_id:
â”‚   â”‚               self.details["current_sync_id"] = current_sync_id
â”‚   â”‚           if merchant_id:
â”‚   â”‚               self.details["merchant_id"] = merchant_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class SyncNotFoundError(NotFoundError):
â”‚   â”‚       """Sync operation not found."""
â”‚   â”‚       
â”‚   â”‚       code = "SYNC_NOT_FOUND"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           sync_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, resource="sync", resource_id=sync_id, **kwargs)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class SyncNotResumableError(ConflictError):
â”‚   â”‚       """Sync cannot be resumed in its current state."""
â”‚   â”‚       
â”‚   â”‚       code = "SYNC_NOT_RESUMABLE"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           sync_id: Optional[str] = None,
â”‚   â”‚           sync_status: Optional[str] = None,
â”‚   â”‚           reason: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if sync_id:
â”‚   â”‚               self.details["sync_id"] = sync_id
â”‚   â”‚           if sync_status:
â”‚   â”‚               self.details["sync_status"] = sync_status
â”‚   â”‚           if reason:
â”‚   â”‚               self.details["reason"] = reason
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class SyncNotCancellableError(ConflictError):
â”‚   â”‚       """Sync cannot be cancelled in its current state."""
â”‚   â”‚       
â”‚   â”‚       code = "SYNC_NOT_CANCELLABLE"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           sync_id: Optional[str] = None,
â”‚   â”‚           sync_status: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if sync_id:
â”‚   â”‚               self.details["sync_id"] = sync_id
â”‚   â”‚           if sync_status:
â”‚   â”‚               self.details["sync_status"] = sync_status
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ItemNotFoundError(NotFoundError):
â”‚   â”‚       """Item not found in catalog."""
â”‚   â”‚       
â”‚   â”‚       code = "ITEM_NOT_FOUND"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           item_id: Optional[str] = None,
â”‚   â”‚           merchant_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, resource="item", resource_id=item_id, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if merchant_id:
â”‚   â”‚               self.details["merchant_id"] = merchant_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ParentSyncNotFoundError(NotFoundError):
â”‚   â”‚       """Parent sync operation not found for resume."""
â”‚   â”‚       
â”‚   â”‚       code = "PARENT_SYNC_NOT_FOUND"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           parent_sync_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(
â”‚   â”‚               message,
â”‚   â”‚               resource="parent_sync",
â”‚   â”‚               resource_id=parent_sync_id,
â”‚   â”‚               **kwargs
â”‚   â”‚           )
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ infrastructure.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/infrastructure.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Infrastructure-specific error classes."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional
â”‚   â”‚   from .base import InfrastructureError
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class DatabaseError(InfrastructureError):
â”‚   â”‚       """Database operation failed."""
â”‚   â”‚   
â”‚   â”‚       code = "DATABASE_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           operation: Optional[str] = None,
â”‚   â”‚           table: Optional[str] = None,
â”‚   â”‚           error_code: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, service="database", **kwargs)
â”‚   â”‚   
â”‚   â”‚           if operation:
â”‚   â”‚               self.details["operation"] = operation
â”‚   â”‚           if table:
â”‚   â”‚               self.details["table"] = table
â”‚   â”‚           if error_code:
â”‚   â”‚               self.details["error_code"] = error_code
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class RedisError(InfrastructureError):
â”‚   â”‚       """Redis operation failed."""
â”‚   â”‚   
â”‚   â”‚       code = "REDIS_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           operation: Optional[str] = None,
â”‚   â”‚           key: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, service="redis", **kwargs)
â”‚   â”‚   
â”‚   â”‚           if operation:
â”‚   â”‚               self.details["operation"] = operation
â”‚   â”‚           if key:
â”‚   â”‚               self.details["key"] = key
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class S3Error(InfrastructureError):
â”‚   â”‚       """S3 operation failed."""
â”‚   â”‚   
â”‚   â”‚       code = "S3_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           operation: Optional[str] = None,
â”‚   â”‚           bucket: Optional[str] = None,
â”‚   â”‚           key: Optional[str] = None,
â”‚   â”‚           error_code: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, service="s3", **kwargs)
â”‚   â”‚   
â”‚   â”‚           if operation:
â”‚   â”‚               self.details["operation"] = operation
â”‚   â”‚           if bucket:
â”‚   â”‚               self.details["bucket"] = bucket
â”‚   â”‚           if key:
â”‚   â”‚               self.details["key"] = key
â”‚   â”‚           if error_code:
â”‚   â”‚               self.details["error_code"] = error_code
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class UpstreamServiceError(InfrastructureError):
â”‚   â”‚       """Upstream service call failed."""
â”‚   â”‚   
â”‚   â”‚       code = "UPSTREAM_SERVICE_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           upstream_service: Optional[str] = None,
â”‚   â”‚           upstream_status: Optional[int] = None,
â”‚   â”‚           upstream_error: Optional[str] = None,
â”‚   â”‚           endpoint: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, service=upstream_service, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if upstream_status:
â”‚   â”‚               self.details["upstream_status"] = upstream_status
â”‚   â”‚           if upstream_error:
â”‚   â”‚               self.details["upstream_error"] = upstream_error
â”‚   â”‚           if endpoint:
â”‚   â”‚               self.details["endpoint"] = endpoint
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class CircuitOpenError(InfrastructureError):
â”‚   â”‚       """Circuit breaker is open."""
â”‚   â”‚   
â”‚   â”‚       code = "CIRCUIT_OPEN"
â”‚   â”‚       status = 503
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           service_name: Optional[str] = None,
â”‚   â”‚           failure_count: Optional[int] = None,
â”‚   â”‚           open_until: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(
â”‚   â”‚               message,
â”‚   â”‚               service=service_name,
â”‚   â”‚               retryable=False,  # Don't retry when circuit is open
â”‚   â”‚               **kwargs
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚           if failure_count:
â”‚   â”‚               self.details["failure_count"] = failure_count
â”‚   â”‚           if open_until:
â”‚   â”‚               self.details["open_until"] = open_until
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class MessageBusError(InfrastructureError):
â”‚   â”‚       """Message bus operation failed."""
â”‚   â”‚   
â”‚   â”‚       code = "MESSAGE_BUS_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           operation: Optional[str] = None,
â”‚   â”‚           stream: Optional[str] = None,
â”‚   â”‚           subject: Optional[str] = None,
â”‚   â”‚           subject: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, service="nats", **kwargs)
â”‚   â”‚   
â”‚   â”‚           if operation:
â”‚   â”‚               self.details["operation"] = operation
â”‚   â”‚           if stream:
â”‚   â”‚               self.details["stream"] = stream
â”‚   â”‚           if subject:
â”‚   â”‚               self.details["subject"] = subject
â”‚   â”‚           if subject:
â”‚   â”‚               self.details["subject"] = subject
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ notification.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/notification.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   
â”‚   â”‚   """Notification service specific errors."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional
â”‚   â”‚   from .base import NotFoundError, ValidationError, InfrastructureError, ConflictError
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class NotificationNotFoundError(NotFoundError):
â”‚   â”‚       """Notification not found."""
â”‚   â”‚   
â”‚   â”‚       code = "NOTIFICATION_NOT_FOUND"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           notification_id: Optional[UUID] = None,
â”‚   â”‚           merchant_id: Optional[UUID] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(
â”‚   â”‚               message, resource="notification", resource_id=notification_id, **kwargs
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚           if merchant_id:
â”‚   â”‚               self.details["merchant_id"] = merchant_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class TemplateNotFoundError(NotFoundError):
â”‚   â”‚       """Email template not found."""
â”‚   â”‚   
â”‚   â”‚       code = "TEMPLATE_NOT_FOUND"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           template_name: Optional[str] = None,
â”‚   â”‚           template_type: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(
â”‚   â”‚               message, resource="template", resource_id=template_name, **kwargs
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚           if template_type:
â”‚   â”‚               self.details["template_type"] = template_type
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class TemplateRenderError(ValidationError):
â”‚   â”‚       """Failed to render email template."""
â”‚   â”‚   
â”‚   â”‚       code = "TEMPLATE_RENDER_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           template_name: Optional[str] = None,
â”‚   â”‚           missing_variables: Optional[list] = None,
â”‚   â”‚           render_error: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if template_name:
â”‚   â”‚               self.details["template_name"] = template_name
â”‚   â”‚           if missing_variables:
â”‚   â”‚               self.details["missing_variables"] = missing_variables
â”‚   â”‚           if render_error:
â”‚   â”‚               self.details["render_error"] = render_error
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class InvalidRecipientError(ValidationError):
â”‚   â”‚       """Invalid recipient email address."""
â”‚   â”‚   
â”‚   â”‚       code = "INVALID_RECIPIENT"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           recipient: Optional[str] = None,
â”‚   â”‚           reason: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, field="recipient", value=recipient, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if reason:
â”‚   â”‚               self.details["reason"] = reason
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class PreferencesNotFoundError(NotFoundError):
â”‚   â”‚       """Notification preferences not found."""
â”‚   â”‚   
â”‚   â”‚       code = "PREFERENCES_NOT_FOUND"
â”‚   â”‚   
â”‚   â”‚       def __init__(self, message: str, *, user_id: Optional[str] = None, **kwargs):
â”‚   â”‚           super().__init__(
â”‚   â”‚               message, resource="notification_preferences", resource_id=user_id, **kwargs
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class EmailProviderError(InfrastructureError):
â”‚   â”‚       """Email provider API error."""
â”‚   â”‚   
â”‚   â”‚       code = "EMAIL_PROVIDER_ERROR"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           provider: Optional[str] = None,
â”‚   â”‚           provider_error_code: Optional[str] = None,
â”‚   â”‚           provider_message: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, service=provider, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if provider_error_code:
â”‚   â”‚               self.details["provider_error_code"] = provider_error_code
â”‚   â”‚           if provider_message:
â”‚   â”‚               self.details["provider_message"] = provider_message
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class UnsubscribedError(ConflictError):
â”‚   â”‚       """Recipient has unsubscribed."""
â”‚   â”‚   
â”‚   â”‚       code = "UNSUBSCRIBED"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Recipient has unsubscribed from notifications",
â”‚   â”‚           *,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           notification_type: Optional[str] = None,
â”‚   â”‚           unsubscribed_at: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚           if notification_type:
â”‚   â”‚               self.details["notification_type"] = notification_type
â”‚   â”‚           if unsubscribed_at:
â”‚   â”‚               self.details["unsubscribed_at"] = unsubscribed_at
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ profile.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/profile.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Profile service specific errors."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional
â”‚   â”‚   from .base import NotFoundError, ConflictError, DomainError
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ProfileNotFoundError(NotFoundError):
â”‚   â”‚       """User profile not found."""
â”‚   â”‚       
â”‚   â”‚       code = "PROFILE_NOT_FOUND"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           profile_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, resource="profile", **kwargs)
â”‚   â”‚           
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚           if profile_id:
â”‚   â”‚               self.details["profile_id"] = profile_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ProfileAlreadyExistsError(ConflictError):
â”‚   â”‚       """Profile already exists for this user."""
â”‚   â”‚       
â”‚   â”‚       code = "PROFILE_ALREADY_EXISTS"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           existing_profile_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(
â”‚   â”‚               message,
â”‚   â”‚               conflicting_resource="profile",
â”‚   â”‚               **kwargs
â”‚   â”‚           )
â”‚   â”‚           
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚           if existing_profile_id:
â”‚   â”‚               self.details["existing_profile_id"] = existing_profile_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ProfileCreationFailedError(DomainError):
â”‚   â”‚       """Failed to create profile."""
â”‚   â”‚       
â”‚   â”‚       code = "PROFILE_CREATION_FAILED"
â”‚   â”‚       status = 422
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           reason: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚           if reason:
â”‚   â”‚               self.details["reason"] = reason
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ selfie.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/errors/selfie.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Selfie service specific errors."""
â”‚   â”‚   
â”‚   â”‚   from typing import Optional, List
â”‚   â”‚   from .base import NotFoundError, ValidationError
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class SelfieNotFoundError(NotFoundError):
â”‚   â”‚       """Selfie not found."""
â”‚   â”‚       
â”‚   â”‚       code = "SELFIE_NOT_FOUND"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           selfie_id: Optional[str] = None,
â”‚   â”‚           user_id: Optional[str] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, resource="selfie", resource_id=selfie_id, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if user_id:
â”‚   â”‚               self.details["user_id"] = user_id
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class InvalidImageFormatError(ValidationError):
â”‚   â”‚       """Image format not supported."""
â”‚   â”‚       
â”‚   â”‚       code = "INVALID_IMAGE_FORMAT"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           provided_format: Optional[str] = None,
â”‚   â”‚           supported_formats: Optional[List[str]] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if provided_format:
â”‚   â”‚               self.details["provided_format"] = provided_format
â”‚   â”‚           if supported_formats:
â”‚   â”‚               self.details["supported_formats"] = supported_formats
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ImageTooLargeError(ValidationError):
â”‚   â”‚       """Image exceeds size limit."""
â”‚   â”‚       
â”‚   â”‚       code = "IMAGE_TOO_LARGE"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           size_bytes: Optional[int] = None,
â”‚   â”‚           max_size_bytes: Optional[int] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if size_bytes:
â”‚   â”‚               self.details["size_bytes"] = size_bytes
â”‚   â”‚           if max_size_bytes:
â”‚   â”‚               self.details["max_size_bytes"] = max_size_bytes
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ImageTooSmallError(ValidationError):
â”‚   â”‚       """Image below minimum dimensions."""
â”‚   â”‚       
â”‚   â”‚       code = "IMAGE_TOO_SMALL"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str,
â”‚   â”‚           *,
â”‚   â”‚           width: Optional[int] = None,
â”‚   â”‚           height: Optional[int] = None,
â”‚   â”‚           min_width: Optional[int] = None,
â”‚   â”‚           min_height: Optional[int] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if width:
â”‚   â”‚               self.details["width"] = width
â”‚   â”‚           if height:
â”‚   â”‚               self.details["height"] = height
â”‚   â”‚           if min_width:
â”‚   â”‚               self.details["min_width"] = min_width
â”‚   â”‚           if min_height:
â”‚   â”‚               self.details["min_height"] = min_height
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class NoFaceDetectedError(ValidationError):
â”‚   â”‚       """No face detected in image."""
â”‚   â”‚       
â”‚   â”‚       code = "NO_FACE_DETECTED"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "No face detected in the image",
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class MultipleFacesDetectedError(ValidationError):
â”‚   â”‚       """Multiple faces detected."""
â”‚   â”‚       
â”‚   â”‚       code = "MULTIPLE_FACES_DETECTED"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Multiple faces detected in the image",
â”‚   â”‚           *,
â”‚   â”‚           face_count: Optional[int] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if face_count:
â”‚   â”‚               self.details["face_count"] = face_count
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class PoorImageQualityError(ValidationError):
â”‚   â”‚       """Image quality too low for analysis."""
â”‚   â”‚       
â”‚   â”‚       code = "POOR_IMAGE_QUALITY"
â”‚   â”‚       
â”‚   â”‚       def __init__(
â”‚   â”‚           self,
â”‚   â”‚           message: str = "Image quality too low for analysis",
â”‚   â”‚           *,
â”‚   â”‚           quality_score: Optional[float] = None,
â”‚   â”‚           min_quality_score: Optional[float] = None,
â”‚   â”‚           quality_issues: Optional[List[str]] = None,
â”‚   â”‚           **kwargs
â”‚   â”‚       ):
â”‚   â”‚           super().__init__(message, **kwargs)
â”‚   â”‚           
â”‚   â”‚           if quality_score is not None:
â”‚   â”‚               self.details["quality_score"] = quality_score
â”‚   â”‚           if min_quality_score is not None:
â”‚   â”‚               self.details["min_quality_score"] = min_quality_score
â”‚   â”‚           if quality_issues:
â”‚   â”‚               self.details["quality_issues"] = quality_issues
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ utils.py
â”‚       
â”‚       ```py
â”‚       # -------------------------------
â”‚       # shared/errors/utils.py
â”‚       # -------------------------------
â”‚       
â”‚       """
â”‚       Utility functions for error handling and classification.
â”‚       
â”‚       This module provides helpers for wrapping external errors,
â”‚       classifying HTTP errors, and determining retry behavior.
â”‚       """
â”‚       
â”‚       from typing import Type, Callable, TypeVar
â”‚       import httpx
â”‚       import asyncio
â”‚       from functools import wraps
â”‚       
â”‚       from .base import (
â”‚           GlamBaseError,
â”‚           InfrastructureError,
â”‚           RequestTimeoutError,
â”‚           ServiceUnavailableError,
â”‚           RateLimitedError,
â”‚       )
â”‚       from .infrastructure import UpstreamServiceError
â”‚       
â”‚       T = TypeVar("T")
â”‚       
â”‚       
â”‚       def wrap_external_error(
â”‚           error_class: Type[GlamBaseError], message: str, *, cause: Exception, **kwargs
â”‚       ) -> GlamBaseError:
â”‚           """
â”‚           Wrap an external exception in a domain-specific error.
â”‚       
â”‚           This preserves the original exception chain while providing
â”‚           a clean domain error for upper layers.
â”‚       
â”‚           Args:
â”‚               error_class: The error class to wrap with
â”‚               message: Human-readable error message
â”‚               cause: The original exception
â”‚               **kwargs: Additional arguments for the error class
â”‚       
â”‚           Returns:
â”‚               Instance of error_class with proper cause chain
â”‚           """
â”‚           return error_class(message, cause=cause, **kwargs)
â”‚       
â”‚       
â”‚       def classify_http_error(
â”‚           exc: httpx.HTTPError, *, service_name: str = "upstream"
â”‚       ) -> InfrastructureError | RateLimitedError:
â”‚           """
â”‚           Classify HTTP errors into appropriate infrastructure errors.
â”‚       
â”‚           Args:
â”‚               exc: The HTTP exception to classify
â”‚               service_name: Name of the upstream service
â”‚       
â”‚           Returns:
â”‚               Appropriate InfrastructureError subclass
â”‚           """
â”‚           if isinstance(exc, httpx.TimeoutException):
â”‚               return RequestTimeoutError(
â”‚                   f"Request to {service_name} timed out", cause=exc, operation="http_request"
â”‚               )
â”‚       
â”‚           if isinstance(exc, httpx.HTTPStatusError):
â”‚               status = exc.response.status_code
â”‚       
â”‚               if status == 429:
â”‚                   # Extract retry-after if available
â”‚                   retry_after = exc.response.headers.get("Retry-After")
â”‚                   return RateLimitedError(
â”‚                       f"Rate limited by {service_name}",
â”‚                       cause=exc,
â”‚                       retry_after=int(retry_after) if retry_after else None,
â”‚                   )
â”‚       
â”‚               if status == 503:
â”‚                   return ServiceUnavailableError(
â”‚                       f"{service_name} is temporarily unavailable", cause=exc
â”‚                   )
â”‚       
â”‚               if 500 <= status < 600:
â”‚                   return UpstreamServiceError(
â”‚                       f"{service_name} returned {status}",
â”‚                       cause=exc,
â”‚                       upstream_service=service_name,
â”‚                       upstream_status=status,
â”‚                       endpoint=str(exc.request.url),
â”‚                   )
â”‚       
â”‚               # 4xx errors - usually client errors, not retryable
â”‚               return UpstreamServiceError(
â”‚                   f"{service_name} rejected request: {status}",
â”‚                   cause=exc,
â”‚                   upstream_service=service_name,
â”‚                   upstream_status=status,
â”‚                   endpoint=str(exc.request.url),
â”‚                   retryable=False,
â”‚               )
â”‚       
â”‚           # Generic connection errors
â”‚           return InfrastructureError(
â”‚               f"Failed to connect to {service_name}", cause=exc, service=service_name
â”‚           )
â”‚       
â”‚       
â”‚       def is_retryable_error(exc: Exception) -> bool:
â”‚           """
â”‚           Determine if an error should be retried.
â”‚       
â”‚           Args:
â”‚               exc: The exception to check
â”‚       
â”‚           Returns:
â”‚               True if the error is retryable
â”‚           """
â”‚           if isinstance(exc, InfrastructureError):
â”‚               return exc.retryable
â”‚       
â”‚           # Specific exceptions that are retryable
â”‚           retryable_types = (
â”‚               asyncio.TimeoutError,
â”‚               ConnectionError,
â”‚               RequestTimeoutError,
â”‚           )
â”‚       
â”‚           return isinstance(exc, retryable_types)
â”‚       
â”‚       
â”‚       def with_error_mapping(
â”‚           mappings: dict[Type[Exception], Type[GlamBaseError]],
â”‚           *,
â”‚           default_error: Type[GlamBaseError] = InfrastructureError,
â”‚           default_message: str = "Operation failed",
â”‚       ):
â”‚           """
â”‚           Decorator to automatically map exceptions to domain errors.
â”‚       
â”‚           Example:
â”‚               @with_error_mapping({
â”‚                   FileNotFoundError: NotFoundError,
â”‚                   PermissionError: ForbiddenError,
â”‚               })
â”‚               async def read_file(path: str):
â”‚                   ...
â”‚       
â”‚           Args:
â”‚               mappings: Dict mapping exception types to error classes
â”‚               default_error: Error class for unmapped exceptions
â”‚               default_message: Default message for unmapped errors
â”‚           """
â”‚       
â”‚           def decorator(func: Callable[..., T]) -> Callable[..., T]:
â”‚               @wraps(func)
â”‚               async def async_wrapper(*args, **kwargs):
â”‚                   try:
â”‚                       result = func(*args, **kwargs)
â”‚                       if asyncio.iscoroutine(result):
â”‚                           return await result
â”‚                       return result
â”‚                   except Exception as exc:
â”‚                       # Check if we have a mapping for this exception
â”‚                       for exc_type, error_class in mappings.items():
â”‚                           if isinstance(exc, exc_type):
â”‚                               raise error_class(
â”‚                                   str(exc) or default_message, cause=exc
â”‚                               ) from exc
â”‚       
â”‚                       # No mapping found - use default
â”‚                       if isinstance(exc, GlamBaseError):
â”‚                           # Already our error type - let it bubble
â”‚                           raise
â”‚       
â”‚                       raise default_error(str(exc) or default_message, cause=exc) from exc
â”‚       
â”‚               @wraps(func)
â”‚               def sync_wrapper(*args, **kwargs):
â”‚                   try:
â”‚                       return func(*args, **kwargs)
â”‚                   except Exception as exc:
â”‚                       # Same logic as async version
â”‚                       for exc_type, error_class in mappings.items():
â”‚                           if isinstance(exc, exc_type):
â”‚                               raise error_class(
â”‚                                   str(exc) or default_message, cause=exc
â”‚                               ) from exc
â”‚       
â”‚                       if isinstance(exc, GlamBaseError):
â”‚                           raise
â”‚       
â”‚                       raise default_error(str(exc) or default_message, cause=exc) from exc
â”‚       
â”‚               # Return appropriate wrapper based on function type
â”‚               if asyncio.iscoroutinefunction(func):
â”‚                   return async_wrapper  # type: ignore
â”‚               else:
â”‚                   return sync_wrapper
â”‚       
â”‚           return decorator
â”‚       ```
â”‚       
â”œâ”€â”€ events/
â”‚   â”œâ”€â”€ catalog/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ types.py
â”‚   â”‚       
â”‚   â”‚       ```py
â”‚   â”‚       from pydantic import BaseModel, Field
â”‚   â”‚       from typing import Dict, Optional, List, Any
â”‚   â”‚       
â”‚   â”‚       from uuid import UUID
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       from ..base import EventWrapper
â”‚   â”‚       
â”‚   â”‚       class CatalogCommands:
â”‚   â”‚           """Catalog command types"""
â”‚   â”‚           CATALOG_SYNC_INITIAL = "cmd.catalog.sync_initial"
â”‚   â”‚           CATALOG_SYNC_UPDATE = "cmd.catalog.sync_update"
â”‚   â”‚           CATALOG_PROCESS_IMAGES = "cmd.catalog.process_images"
â”‚   â”‚           CATALOG_ANALYZE_ITEMS = "cmd.catalog.analyze_items"
â”‚   â”‚           CATALOG_ENRICH_WITH_AI = "cmd.catalog.enrich_with_ai"
â”‚   â”‚           
â”‚   â”‚       class CatalogEvents:
â”‚   â”‚           """Catalog event types"""
â”‚   â”‚           CATALOG_SYNC_STARTED = "evt.catalog.sync_started"
â”‚   â”‚           CATALOG_SYNC_COMPLETED = "evt.catalog.sync_completed"
â”‚   â”‚           CATALOG_SYNC_FAILED = "evt.catalog.sync_failed"
â”‚   â”‚           CATALOG_IMAGES_PROCESSED = "evt.catalog.images_processed"
â”‚   â”‚           CATALOG_ITEMS_ANALYZED = "evt.catalog.items_analyzed"
â”‚   â”‚           CATALOG_AI_ENRICHED = "evt.catalog.ai_enriched"
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncInitialPayload(BaseModel):
â”‚   â”‚           """Payload for initial catalog sync command"""
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           source: str  # e.g. "shopify", "woocommerce"
â”‚   â”‚           sync_type: str  # e.g. "full", "incremental"
â”‚   â”‚           webhook_url: Optional[str] = None  # Optional webhook for updates
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncUpdatePayload(BaseModel):
â”‚   â”‚           """Payload for catalog sync update command"""
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           items: List[Dict[str, Any]]  # List of items to update
â”‚   â”‚           job_id: Optional[str] = None  # Optional job ID for tracking
â”‚   â”‚           
â”‚   â”‚       class CatalogProcessImagesPayload(BaseModel):
â”‚   â”‚           """Payload for processing catalog images"""
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           items: List[Dict[str, Any]]  # List of items with images to process
â”‚   â”‚           job_id: Optional[str] = None  # Optional job ID for tracking
â”‚   â”‚           
â”‚   â”‚       class CatalogAnalyzeItemsPayload(BaseModel):
â”‚   â”‚           """Payload for analyzing catalog items"""
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           items: List[Dict[str, Any]]  # List of items to analyze
â”‚   â”‚           job_id: Optional[str] = None  # Optional job ID for tracking
â”‚   â”‚           
â”‚   â”‚       class CatalogEnrichWithAIPayload(BaseModel):
â”‚   â”‚           """Payload for enriching catalog with AI"""
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           items: List[Dict[str, Any]]  # List of items to enrich
â”‚   â”‚           job_id: Optional[str] = None  # Optional job ID for tracking
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncInitialCommand(EventWrapper):
â”‚   â”‚           """Command to initiate initial catalog sync"""
â”‚   â”‚           subject: str = CatalogCommands.CATALOG_SYNC_INITIAL
â”‚   â”‚           data: CatalogSyncInitialPayload
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncUpdateCommand(EventWrapper):
â”‚   â”‚           """Command to update catalog with new items"""
â”‚   â”‚           subject: str = CatalogCommands.CATALOG_SYNC_UPDATE
â”‚   â”‚           data: CatalogSyncUpdatePayload
â”‚   â”‚           
â”‚   â”‚       class CatalogProcessImagesCommand(EventWrapper):
â”‚   â”‚           """Command to process catalog images"""
â”‚   â”‚           subject: str = CatalogCommands.CATALOG_PROCESS_IMAGES
â”‚   â”‚           data: CatalogProcessImagesPayload
â”‚   â”‚           
â”‚   â”‚       class CatalogAnalyzeItemsCommand(EventWrapper):
â”‚   â”‚           """Command to analyze catalog items"""
â”‚   â”‚           subject: str = CatalogCommands.CATALOG_ANALYZE_ITEMS
â”‚   â”‚           data: CatalogAnalyzeItemsPayload
â”‚   â”‚           
â”‚   â”‚       class CatalogEnrichWithAICommand(EventWrapper):
â”‚   â”‚           """Command to enrich catalog with AI"""
â”‚   â”‚           subject: str = CatalogCommands.CATALOG_ENRICH_WITH_AI
â”‚   â”‚           data: CatalogEnrichWithAIPayload
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncStartedEvent(EventWrapper):
â”‚   â”‚           """Event emitted when catalog sync starts"""
â”‚   â”‚           subject: str = CatalogEvents.CATALOG_SYNC_STARTED
â”‚   â”‚           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncCompletedEvent(EventWrapper):
â”‚   â”‚           """Event emitted when catalog sync completes"""
â”‚   â”‚           subject: str = CatalogEvents.CATALOG_SYNC_COMPLETED
â”‚   â”‚           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
â”‚   â”‚           
â”‚   â”‚       class CatalogSyncFailedEvent(EventWrapper):
â”‚   â”‚           """Event emitted when catalog sync fails"""
â”‚   â”‚           subject: str = CatalogEvents.CATALOG_SYNC_FAILED
â”‚   â”‚           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
â”‚   â”‚           error_message: Optional[str] = None  # Optional error message for failure
â”‚   â”‚           
â”‚   â”‚       class CatalogImagesProcessedEvent(EventWrapper):
â”‚   â”‚           """Event emitted when catalog images are processed"""
â”‚   â”‚           subject: str = CatalogEvents.CATALOG_IMAGES_PROCESSED
â”‚   â”‚           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
â”‚   â”‚           
â”‚   â”‚       class CatalogItemsAnalyzedEvent(EventWrapper):
â”‚   â”‚           """Event emitted when catalog items are analyzed"""
â”‚   â”‚           subject: str = CatalogEvents.CATALOG_ITEMS_ANALYZED
â”‚   â”‚           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
â”‚   â”‚           
â”‚   â”‚       class CatalogAIEnrichedEvent(EventWrapper):
â”‚   â”‚           """Event emitted when catalog items are enriched with AI"""
â”‚   â”‚           subject: str = CatalogEvents.CATALOG_AI_ENRICHED
â”‚   â”‚           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
â”‚   â”‚           enrichment_details: Optional[Dict[str, Any]] = None  # Optional details about the enrichment process
â”‚   â”‚           
â”‚   â”‚           
â”‚   â”‚       ```
â”‚   â”‚       
â”‚   â”œâ”€â”€ credit/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ types.py
â”‚   â”‚       
â”‚   â”‚       ```py
â”‚   â”‚       # shared/events/notification/types.py
â”‚   â”‚       from pydantic import BaseModel, Field
â”‚   â”‚       from typing import Dict, List, Any
â”‚   â”‚       from datetime import datetime
â”‚   â”‚       from uuid import UUID
â”‚   â”‚       
â”‚   â”‚       from ..base import EventWrapper  # Now generic
â”‚   â”‚       from ..context import EventContext  # Keep this!
â”‚   â”‚       
â”‚   â”‚       class CreditEvents:
â”‚   â”‚           "Credit command types"
â”‚   â”‚           ORDER_UPDATED = "evt.order.updated" 
â”‚   â”‚           ACCOUNT_CREATED = "evt.account.created"
â”‚   â”‚           SUBSCRIPTION_RENEWED = "evt.subscription.renewed"
â”‚   â”‚           MERCHANT_CREATED="evt.merchant.created"
â”‚   â”‚       ```
â”‚   â”‚       
â”‚   â”œâ”€â”€ notification/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ helpers.py
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚   ```py
â”‚   â”‚   â”‚   # shared/events/notification/helpers.py
â”‚   â”‚   â”‚   from datetime import datetime, timezone
â”‚   â”‚   â”‚   import hashlib
â”‚   â”‚   â”‚   from typing import Dict, Optional, List, Any
â”‚   â”‚   â”‚   from uuid import UUID
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚   from ..context import EventContext
â”‚   â”‚   â”‚   from .types import (
â”‚   â”‚   â”‚       Recipient,
â”‚   â”‚   â”‚       SendEmailBulkCommand,
â”‚   â”‚   â”‚       SendEmailCommand,
â”‚   â”‚   â”‚   )
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚   def create_send_email_command(
â”‚   â”‚   â”‚       merchant_id: UUID,
â”‚   â”‚   â”‚       merchant_domain: str,
â”‚   â”‚   â”‚       recipient_email: str,
â”‚   â”‚   â”‚       notification_type: str,
â”‚   â”‚   â”‚       dynamic_content: Dict[str, Any],
â”‚   â”‚   â”‚       unsubscribe_token: str,
â”‚   â”‚   â”‚       idempotency_key: Optional[str] = None,
â”‚   â”‚   â”‚       correlation_id: Optional[str] = None,
â”‚   â”‚   â”‚       metadata: Optional[Dict[str, Any]] = None,
â”‚   â”‚   â”‚   ) -> Dict[str, Any]:
â”‚   â”‚   â”‚       """
â”‚   â”‚   â”‚       Create a send email command with idempotency support and context.
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       If no idempotency_key provided, generates one based on:
â”‚   â”‚   â”‚       - merchant_id + notification_type + recipient_email + timestamp (hourly bucket)
â”‚   â”‚   â”‚       This prevents duplicate emails within the same hour.
â”‚   â”‚   â”‚       """
â”‚   â”‚   â”‚       if not idempotency_key:
â”‚   â”‚   â”‚           # Create deterministic key with hourly bucket to prevent duplicates
â”‚   â”‚   â”‚           hour_bucket = datetime.now(timezone.utc).strftime("%Y%m%d%H")
â”‚   â”‚   â”‚           key_data = f"{merchant_id}:{notification_type}:{recipient_email}:{hour_bucket}"
â”‚   â”‚   â”‚           idempotency_key = f"send_{hashlib.sha256(key_data.encode()).hexdigest()[:16]}"
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       # Create event context
â”‚   â”‚   â”‚       context = EventContext.create(
â”‚   â”‚   â”‚           subject="cmd.notification.send_email",
â”‚   â”‚   â”‚           source_service=(
â”‚   â”‚   â”‚               metadata.get("source_service", "unknown") if metadata else "unknown"
â”‚   â”‚   â”‚           ),
â”‚   â”‚   â”‚           correlation_id=correlation_id,
â”‚   â”‚   â”‚           idempotency_key=idempotency_key,
â”‚   â”‚   â”‚           metadata=metadata,
â”‚   â”‚   â”‚       )
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       recipient = Recipient(
â”‚   â”‚   â”‚           merchant_id=merchant_id,
â”‚   â”‚   â”‚           merchant_domain=merchant_domain,
â”‚   â”‚   â”‚           email=recipient_email,
â”‚   â”‚   â”‚           unsubscribe_token=unsubscribe_token,
â”‚   â”‚   â”‚           dynamic_content=dynamic_content,
â”‚   â”‚   â”‚       )
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       command = SendEmailCommand.create_from_context(
â”‚   â”‚   â”‚           context=context, notification_type=notification_type, recipient=recipient
â”‚   â”‚   â”‚       )
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       return command.to_event_dict()
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚   def create_bulk_email_command(
â”‚   â”‚   â”‚       notification_type: str,
â”‚   â”‚   â”‚       recipients: List[Dict[str, Any]],
â”‚   â”‚   â”‚       idempotency_key: Optional[str] = None,
â”‚   â”‚   â”‚       correlation_id: Optional[str] = None,
â”‚   â”‚   â”‚       metadata: Optional[Dict[str, Any]] = None,
â”‚   â”‚   â”‚   ) -> Dict[str, Any]:
â”‚   â”‚   â”‚       """
â”‚   â”‚   â”‚       Create a bulk email command with idempotency support and context.
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       If no idempotency_key provided, generates one based on:
â”‚   â”‚   â”‚       - notification_type + recipient_count + timestamp
â”‚   â”‚   â”‚       """
â”‚   â”‚   â”‚       if not idempotency_key:
â”‚   â”‚   â”‚           # Create unique key for this bulk operation
â”‚   â”‚   â”‚           timestamp = datetime.now(timezone.utc).isoformat()
â”‚   â”‚   â”‚           key_data = f"bulk:{notification_type}:{len(recipients)}:{timestamp}"
â”‚   â”‚   â”‚           idempotency_key = f"bulk_{hashlib.sha256(key_data.encode()).hexdigest()[:16]}"
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       # Create event context
â”‚   â”‚   â”‚       context = EventContext.create(
â”‚   â”‚   â”‚           subject="cmd.notification.bulk_send",
â”‚   â”‚   â”‚           source_service=(
â”‚   â”‚   â”‚               metadata.get("source_service", "unknown") if metadata else "unknown"
â”‚   â”‚   â”‚           ),
â”‚   â”‚   â”‚           correlation_id=correlation_id,
â”‚   â”‚   â”‚           idempotency_key=idempotency_key,
â”‚   â”‚   â”‚           metadata=metadata,
â”‚   â”‚   â”‚       )
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       # Convert recipient dicts to typed objects
â”‚   â”‚   â”‚       typed_recipients = [
â”‚   â”‚   â”‚           Recipient(
â”‚   â”‚   â”‚               merchant_id=r["merchant_id"],
â”‚   â”‚   â”‚               merchant_domain=r["merchant_domain"],
â”‚   â”‚   â”‚               email=r["email"],
â”‚   â”‚   â”‚               unsubscribe_token=r["unsubscribe_token"],
â”‚   â”‚   â”‚               dynamic_content=r.get("dynamic_content", {}),
â”‚   â”‚   â”‚           )
â”‚   â”‚   â”‚           for r in recipients
â”‚   â”‚   â”‚       ]
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       command = SendEmailBulkCommand.create_from_context(
â”‚   â”‚   â”‚           context=context,
â”‚   â”‚   â”‚           notification_type=notification_type,
â”‚   â”‚   â”‚           recipients=typed_recipients,
â”‚   â”‚   â”‚       )
â”‚   â”‚   â”‚   
â”‚   â”‚   â”‚       return command.to_event_dict()
â”‚   â”‚   â”‚   ```
â”‚   â”‚   â”‚   
â”‚   â”‚   â””â”€â”€ types.py
â”‚   â”‚       
â”‚   â”‚       ```py
â”‚   â”‚       # shared/events/notification/types.py
â”‚   â”‚       from pydantic import BaseModel, Field
â”‚   â”‚       from typing import Dict, List, Any
â”‚   â”‚       from datetime import datetime
â”‚   â”‚       from uuid import UUID
â”‚   â”‚       
â”‚   â”‚       from ..base import EventWrapper  # Now generic
â”‚   â”‚       from ..context import EventContext  # Keep this!
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class NotificationCommands:
â”‚   â”‚           """Notification command types"""
â”‚   â”‚       
â”‚   â”‚           NOTIFICATION_SEND_EMAIL = "cmd.notification.send_email"
â”‚   â”‚           NOTIFICATION_SEND_BULK = "cmd.notification.bulk_send"
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class NotificationEvents:
â”‚   â”‚           """Notification event types"""
â”‚   â”‚       
â”‚   â”‚           NOTIFICATION_EMAIL_SENT = "evt.notification.email.sent"
â”‚   â”‚           NOTIFICATION_EMAIL_FAILED = "evt.notification.email.failed"
â”‚   â”‚           NOTIFICATION_BULK_SEND_COMPLETED = "evt.notification.bulk_send.completed"
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class Recipient(BaseModel):
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           merchant_domain: str
â”‚   â”‚           email: str
â”‚   â”‚           unsubscribe_token: str
â”‚   â”‚           dynamic_content: Dict[str, Any] = Field(default_factory=dict)
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class SendEmailCommandPayload(BaseModel):
â”‚   â”‚           """Payload for sending a single email"""
â”‚   â”‚       
â”‚   â”‚           notification_type: str
â”‚   â”‚           recipient: Recipient
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class SendEmailBulkCommandPayload(BaseModel):
â”‚   â”‚           """Payload for sending bulk emails by notification type"""
â”‚   â”‚       
â”‚   â”‚           notification_type: str
â”‚   â”‚           recipients: List[Recipient]
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       # Event payloads remain the same
â”‚   â”‚       class EmailSentEventPayload(BaseModel):
â”‚   â”‚           """Payload for NOTIFICATION_EMAIL_SENT event"""
â”‚   â”‚       
â”‚   â”‚           notification_id: UUID
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           notification_type: str
â”‚   â”‚           provider: str
â”‚   â”‚           provider_message_id: str
â”‚   â”‚           sent_at: datetime
â”‚   â”‚           metadata: Dict[str, Any] = Field(default_factory=dict)
â”‚   â”‚       
â”‚   â”‚           class Config:
â”‚   â”‚               json_encoders = {UUID: str, datetime: lambda v: v.isoformat()}
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class EmailFailedEventPayload(BaseModel):
â”‚   â”‚           """Payload for NOTIFICATION_EMAIL_FAILED event"""
â”‚   â”‚       
â”‚   â”‚           notification_id: UUID
â”‚   â”‚           merchant_id: UUID
â”‚   â”‚           notification_type: str
â”‚   â”‚           error: str
â”‚   â”‚           error_code: str
â”‚   â”‚           retry_count: int
â”‚   â”‚           will_retry: bool
â”‚   â”‚           failed_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class BulkCompletedEventPayload(BaseModel):
â”‚   â”‚           """Payload for bulk send completion"""
â”‚   â”‚       
â”‚   â”‚           bulk_job_id: UUID
â”‚   â”‚           notification_type: str
â”‚   â”‚           total_recipients: int
â”‚   â”‚           total_sent: int
â”‚   â”‚           total_failed: int
â”‚   â”‚           total_skipped: int
â”‚   â”‚           duration_seconds: float
â”‚   â”‚           completed_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       # Enhanced command wrappers that integrate with EventContext
â”‚   â”‚       # The only change is adding the Generic type parameter [PayloadType]
â”‚   â”‚       class SendEmailCommand(EventWrapper[SendEmailCommandPayload]):
â”‚   â”‚           """Command to send a single email"""
â”‚   â”‚       
â”‚   â”‚           subject: str = NotificationCommands.NOTIFICATION_SEND_EMAIL
â”‚   â”‚       
â”‚   â”‚           @classmethod
â”‚   â”‚           def create_from_context(
â”‚   â”‚               cls,
â”‚   â”‚               context: EventContext,  # Still using context!
â”‚   â”‚               notification_type: str,
â”‚   â”‚               recipient: Recipient,
â”‚   â”‚           ) -> "SendEmailCommand":
â”‚   â”‚               """Create command with context"""
â”‚   â”‚               return cls(
â”‚   â”‚                   subject=cls.subject,
â”‚   â”‚                   idempotency_key=context.idempotency_key,
â”‚   â”‚                   event_id=context.event_id,
â”‚   â”‚                   correlation_id=context.correlation_id,
â”‚   â”‚                   timestamp=context.timestamp,
â”‚   â”‚                   metadata=context.metadata,
â”‚   â”‚                   data=SendEmailCommandPayload(
â”‚   â”‚                       notification_type=notification_type, recipient=recipient
â”‚   â”‚                   ),
â”‚   â”‚               )
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class SendEmailBulkCommand(EventWrapper[SendEmailBulkCommandPayload]):
â”‚   â”‚           """Command to send bulk emails with same notification type"""
â”‚   â”‚       
â”‚   â”‚           subject: str = NotificationCommands.NOTIFICATION_SEND_BULK
â”‚   â”‚       
â”‚   â”‚           @classmethod
â”‚   â”‚           def create_from_context(
â”‚   â”‚               cls,
â”‚   â”‚               context: EventContext,  # Still using context!
â”‚   â”‚               notification_type: str,
â”‚   â”‚               recipients: List[Recipient],
â”‚   â”‚           ) -> "SendEmailBulkCommand":
â”‚   â”‚               """Create bulk command with context"""
â”‚   â”‚               return cls(
â”‚   â”‚                   subject=cls.subject,
â”‚   â”‚                   idempotency_key=context.idempotency_key,
â”‚   â”‚                   event_id=context.event_id,
â”‚   â”‚                   correlation_id=context.correlation_id,
â”‚   â”‚                   timestamp=context.timestamp,
â”‚   â”‚                   metadata=context.metadata,
â”‚   â”‚                   data=SendEmailBulkCommandPayload(
â”‚   â”‚                       notification_type=notification_type, recipients=recipients
â”‚   â”‚                   ),
â”‚   â”‚               )
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       # Enhanced event wrappers
â”‚   â”‚       class EmailSentEvent(EventWrapper[EmailSentEventPayload]):
â”‚   â”‚           """Event emitted when an email is successfully sent"""
â”‚   â”‚       
â”‚   â”‚           subject: str = NotificationEvents.NOTIFICATION_EMAIL_SENT
â”‚   â”‚       
â”‚   â”‚           @classmethod
â”‚   â”‚           def create_from_context(
â”‚   â”‚               cls,
â”‚   â”‚               context: EventContext,  # Still using context!
â”‚   â”‚               payload: EmailSentEventPayload,
â”‚   â”‚           ) -> "EmailSentEvent":
â”‚   â”‚               """Create event with context"""
â”‚   â”‚               return cls(
â”‚   â”‚                   subject=cls.subject,
â”‚   â”‚                   idempotency_key=context.idempotency_key,
â”‚   â”‚                   event_id=context.event_id,
â”‚   â”‚                   correlation_id=context.correlation_id,
â”‚   â”‚                   timestamp=context.timestamp,
â”‚   â”‚                   metadata=context.metadata,
â”‚   â”‚                   data=payload,
â”‚   â”‚               )
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class EmailDeliveryFailedEvent(EventWrapper[EmailFailedEventPayload]):
â”‚   â”‚           """Event emitted when email delivery fails"""
â”‚   â”‚       
â”‚   â”‚           subject: str = NotificationEvents.NOTIFICATION_EMAIL_FAILED
â”‚   â”‚       
â”‚   â”‚           @classmethod
â”‚   â”‚           def create_from_context(
â”‚   â”‚               cls,
â”‚   â”‚               context: EventContext,  # Still using context!
â”‚   â”‚               payload: EmailFailedEventPayload,
â”‚   â”‚           ) -> "EmailDeliveryFailedEvent":
â”‚   â”‚               """Create event with context"""
â”‚   â”‚               return cls(
â”‚   â”‚                   subject=cls.subject,
â”‚   â”‚                   idempotency_key=context.idempotency_key,
â”‚   â”‚                   event_id=context.event_id,
â”‚   â”‚                   correlation_id=context.correlation_id,
â”‚   â”‚                   timestamp=context.timestamp,
â”‚   â”‚                   metadata=context.metadata,
â”‚   â”‚                   data=payload,
â”‚   â”‚               )
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class BulkSendCompletedEvent(EventWrapper[BulkCompletedEventPayload]):
â”‚   â”‚           """Event emitted when a bulk email send operation completes"""
â”‚   â”‚       
â”‚   â”‚           subject: str = NotificationEvents.NOTIFICATION_BULK_SEND_COMPLETED
â”‚   â”‚       
â”‚   â”‚           @classmethod
â”‚   â”‚           def create_from_context(
â”‚   â”‚               cls,
â”‚   â”‚               context: EventContext,  # Still using context!
â”‚   â”‚               payload: BulkCompletedEventPayload,
â”‚   â”‚           ) -> "BulkSendCompletedEvent":
â”‚   â”‚               """Create event with context"""
â”‚   â”‚               return cls(
â”‚   â”‚                   subject=cls.subject,
â”‚   â”‚                   idempotency_key=context.idempotency_key,
â”‚   â”‚                   event_id=context.event_id,
â”‚   â”‚                   correlation_id=context.correlation_id,
â”‚   â”‚                   timestamp=context.timestamp,
â”‚   â”‚                   metadata=context.metadata,
â”‚   â”‚                   data=payload,
â”‚   â”‚               )
â”‚   â”‚       ```
â”‚   â”‚       
â”‚   â”œâ”€â”€ scheduler/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ types.py
â”‚   â”‚       
â”‚   â”‚       ```py
â”‚   â”‚       # shared/events/scheduler/types.py
â”‚   â”‚       from pydantic import BaseModel, Field
â”‚   â”‚       from typing import Dict, List, Any, Optional
â”‚   â”‚       from datetime import datetime
â”‚   â”‚       from uuid import UUID
â”‚   â”‚       from enum import Enum
â”‚   â”‚       
â”‚   â”‚       from shared.events.base import EventWrapper
â”‚   â”‚       from shared.events.context import EventContext
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ScheduleType(str, Enum):
â”‚   â”‚           """Schedule type enumeration"""
â”‚   â”‚           CRON = "cron"
â”‚   â”‚           INTERVAL = "interval"
â”‚   â”‚           ONE_TIME = "one_time"
â”‚   â”‚           IMMEDIATE = "immediate"
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ExecutionStatus(str, Enum):
â”‚   â”‚           """Execution status enumeration"""
â”‚   â”‚           PENDING = "pending"
â”‚   â”‚           RUNNING = "running"
â”‚   â”‚           SUCCESS = "success"
â”‚   â”‚           FAILED = "failed"
â”‚   â”‚           SKIPPED = "skipped"
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class SchedulerCommands:
â”‚   â”‚           """Scheduler command types"""
â”‚   â”‚           SCHEDULE_CREATE = "cmd.scheduler.schedule.create"
â”‚   â”‚           SCHEDULE_UPDATE = "cmd.scheduler.schedule.update"
â”‚   â”‚           SCHEDULE_DELETE = "cmd.scheduler.schedule.delete"
â”‚   â”‚           SCHEDULE_PAUSE = "cmd.scheduler.schedule.pause"
â”‚   â”‚           SCHEDULE_RESUME = "cmd.scheduler.schedule.resume"
â”‚   â”‚           SCHEDULE_TRIGGER = "cmd.scheduler.schedule.trigger"
â”‚   â”‚           EXECUTE_IMMEDIATE = "cmd.scheduler.execute.immediate"
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class SchedulerEvents:
â”‚   â”‚           """Scheduler event types"""
â”‚   â”‚           SCHEDULE_CREATED = "evt.scheduler.schedule.created"
â”‚   â”‚           SCHEDULE_UPDATED = "evt.scheduler.schedule.updated"
â”‚   â”‚           SCHEDULE_DELETED = "evt.scheduler.schedule.deleted"
â”‚   â”‚           SCHEDULE_PAUSED = "evt.scheduler.schedule.paused"
â”‚   â”‚           SCHEDULE_RESUMED = "evt.scheduler.schedule.resumed"
â”‚   â”‚           SCHEDULE_TRIGGERED = "evt.scheduler.schedule.triggered"
â”‚   â”‚           EXECUTION_STARTED = "evt.scheduler.execution.started"
â”‚   â”‚           EXECUTION_COMPLETED = "evt.scheduler.execution.completed"
â”‚   â”‚           EXECUTION_FAILED = "evt.scheduler.execution.failed"
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       # Command Payloads
â”‚   â”‚       class CreateScheduleCommandPayload(BaseModel):
â”‚   â”‚           """Payload for creating a schedule"""
â”‚   â”‚           name: str
â”‚   â”‚           description: Optional[str] = None
â”‚   â”‚           
â”‚   â”‚           # Scheduling configuration
â”‚   â”‚           schedule_type: ScheduleType
â”‚   â”‚           cron_expression: Optional[str] = None
â”‚   â”‚           interval_seconds: Optional[int] = None
â”‚   â”‚           scheduled_at: Optional[datetime] = None
â”‚   â”‚           timezone: str = "UTC"
â”‚   â”‚           
â”‚   â”‚           # Execution configuration
â”‚   â”‚           target_command: str
â”‚   â”‚           command_payload: Dict[str, Any] = Field(default_factory=dict)
â”‚   â”‚           
â”‚   â”‚           # Metadata
â”‚   â”‚           tags: List[str] = Field(default_factory=list)
â”‚   â”‚           priority: int = Field(default=5, ge=1, le=10)
â”‚   â”‚           max_retries: int = Field(default=3, ge=0)
â”‚   â”‚           retry_delay_seconds: int = Field(default=300, ge=0)
â”‚   â”‚           
â”‚   â”‚           # Optional fields
â”‚   â”‚           created_by: Optional[str] = None
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class UpdateScheduleCommandPayload(BaseModel):
â”‚   â”‚           """Payload for updating a schedule"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           name: Optional[str] = None
â”‚   â”‚           description: Optional[str] = None
â”‚   â”‚           
â”‚   â”‚           # Scheduling configuration
â”‚   â”‚           schedule_type: Optional[ScheduleType] = None
â”‚   â”‚           cron_expression: Optional[str] = None
â”‚   â”‚           interval_seconds: Optional[int] = None
â”‚   â”‚           scheduled_at: Optional[datetime] = None
â”‚   â”‚           timezone: Optional[str] = None
â”‚   â”‚           
â”‚   â”‚           # Execution configuration
â”‚   â”‚           target_command: Optional[str] = None
â”‚   â”‚           command_payload: Optional[Dict[str, Any]] = None
â”‚   â”‚           
â”‚   â”‚           # Metadata
â”‚   â”‚           tags: Optional[List[str]] = None
â”‚   â”‚           priority: Optional[int] = Field(None, ge=1, le=10)
â”‚   â”‚           max_retries: Optional[int] = Field(None, ge=0)
â”‚   â”‚           retry_delay_seconds: Optional[int] = Field(None, ge=0)
â”‚   â”‚           
â”‚   â”‚           # State
â”‚   â”‚           is_active: Optional[bool] = None
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class DeleteScheduleCommandPayload(BaseModel):
â”‚   â”‚           """Payload for deleting a schedule"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           hard_delete: bool = False  # If true, delete permanently; if false, soft delete
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class PauseScheduleCommandPayload(BaseModel):
â”‚   â”‚           """Payload for pausing a schedule"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           reason: Optional[str] = None
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ResumeScheduleCommandPayload(BaseModel):
â”‚   â”‚           """Payload for resuming a schedule"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class TriggerScheduleCommandPayload(BaseModel):
â”‚   â”‚           """Payload for triggering a schedule immediately"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           override_payload: Optional[Dict[str, Any]] = None
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ExecuteImmediateCommandPayload(BaseModel):
â”‚   â”‚           """Payload for immediate execution without scheduling"""
â”‚   â”‚           target_command: str
â”‚   â”‚           command_payload: Dict[str, Any] = Field(default_factory=dict)
â”‚   â”‚           priority: int = Field(default=5, ge=1, le=10)
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       # Event Payloads
â”‚   â”‚       class ScheduleCreatedEventPayload(BaseModel):
â”‚   â”‚           """Payload for SCHEDULE_CREATED event"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           name: str
â”‚   â”‚           schedule_type: ScheduleType
â”‚   â”‚           target_command: str
â”‚   â”‚           next_run_at: Optional[datetime]
â”‚   â”‚           created_by: str
â”‚   â”‚           created_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ScheduleUpdatedEventPayload(BaseModel):
â”‚   â”‚           """Payload for SCHEDULE_UPDATED event"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           updated_fields: List[str]
â”‚   â”‚           next_run_at: Optional[datetime]
â”‚   â”‚           updated_by: str
â”‚   â”‚           updated_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ScheduleDeletedEventPayload(BaseModel):
â”‚   â”‚           """Payload for SCHEDULE_DELETED event"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           deleted_by: str
â”‚   â”‚           deleted_at: datetime
â”‚   â”‚           hard_delete: bool
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class SchedulePausedEventPayload(BaseModel):
â”‚   â”‚           """Payload for SCHEDULE_PAUSED event"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           reason: Optional[str]
â”‚   â”‚           paused_by: str
â”‚   â”‚           paused_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ScheduleResumedEventPayload(BaseModel):
â”‚   â”‚           """Payload for SCHEDULE_RESUMED event"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           next_run_at: Optional[datetime]
â”‚   â”‚           resumed_by: str
â”‚   â”‚           resumed_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ScheduleTriggeredEventPayload(BaseModel):
â”‚   â”‚           """Payload for SCHEDULE_TRIGGERED event"""
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           execution_id: UUID
â”‚   â”‚           triggered_by: str
â”‚   â”‚           triggered_at: datetime
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ExecutionStartedEventPayload(BaseModel):
â”‚   â”‚           """Payload for EXECUTION_STARTED event"""
â”‚   â”‚           execution_id: UUID
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           schedule_name: str
â”‚   â”‚           target_command: str
â”‚   â”‚           scheduled_for: datetime
â”‚   â”‚           started_at: datetime
â”‚   â”‚           attempt_number: int = 1
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ExecutionCompletedEventPayload(BaseModel):
â”‚   â”‚           """Payload for EXECUTION_COMPLETED event"""
â”‚   â”‚           execution_id: UUID
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           status: ExecutionStatus
â”‚   â”‚           duration_ms: int
â”‚   â”‚           completed_at: datetime
â”‚   â”‚           next_run_at: Optional[datetime]
â”‚   â”‚       
â”‚   â”‚       
â”‚   â”‚       class ExecutionFailedEventPayload(BaseModel):
â”‚   â”‚           """Payload for EXECUTION_FAILED event"""
â”‚   â”‚           execution_id: UUID
â”‚   â”‚           schedule_id: UUID
â”‚   â”‚           error_message: str
â”‚   â”‚           error_type: Optional[str]
â”‚   â”‚           will_retry: bool
â”‚   â”‚           retry_at: Optional[datetime]
â”‚   â”‚           attempt_number: int
â”‚   â”‚           failed_at: datetime
â”‚   â”‚       ```
â”‚   â”‚       
â”‚   â”œâ”€â”€ webhook/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/events/__init__.py
â”‚   â”‚   """
â”‚   â”‚   Shared event handling module for glam-app microservices.
â”‚   â”‚   
â”‚   â”‚   This module provides:
â”‚   â”‚   - Event type definitions and stream mapping
â”‚   â”‚   - Base publisher/subscriber classes
â”‚   â”‚   - Event context management
â”‚   â”‚   - Stream configuration
â”‚   â”‚   """
â”‚   â”‚   
â”‚   â”‚   from .base import (
â”‚   â”‚       Streams,
â”‚   â”‚       EventWrapper,
â”‚   â”‚       # EventDefinition removed
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .context import (
â”‚   â”‚       EventContext,
â”‚   â”‚       EventPayload,
â”‚   â”‚       EventContextManager,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   from .base_publisher import DomainEventPublisher
â”‚   â”‚   from .base_subscriber import DomainEventSubscriber
â”‚   â”‚   
â”‚   â”‚   from .mappers import (
â”‚   â”‚       # EVENT_REGISTRY removed
â”‚   â”‚       SERVICE_STREAM_MAP,
â”‚   â”‚       get_stream_subjects,
â”‚   â”‚       get_stream_for_service,
â”‚   â”‚       get_stream_from_subject,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   __all__ = [
â”‚   â”‚       # Base types
â”‚   â”‚       "Streams",
â”‚   â”‚       "EventWrapper",
â”‚   â”‚       # Context management
â”‚   â”‚       "EventContext",
â”‚   â”‚       "EventPayload",
â”‚   â”‚       "EventContextManager",
â”‚   â”‚       # Publishers/Subscribers
â”‚   â”‚       "DomainEventPublisher",
â”‚   â”‚       "DomainEventSubscriber",
â”‚   â”‚       # Mappers
â”‚   â”‚       "SERVICE_STREAM_MAP",
â”‚   â”‚       "get_stream_subjects",
â”‚   â”‚       "get_stream_for_service",
â”‚   â”‚       "get_stream_from_subject",
â”‚   â”‚   ]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/events/base.py
â”‚   â”‚   from pydantic import BaseModel, Field
â”‚   â”‚   from typing import Dict, Optional, List, Any, TypeVar, Generic
â”‚   â”‚   from datetime import datetime
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   from enum import Enum
â”‚   â”‚   
â”‚   â”‚   from .context import EventContext
â”‚   â”‚   
â”‚   â”‚   # Generic type for event data
â”‚   â”‚   TData = TypeVar("TData", bound=BaseModel)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class Streams(str, Enum):
â”‚   â”‚       """JetStream streams organized by domain"""
â”‚   â”‚   
â”‚   â”‚       # Core Business Domains
â”‚   â”‚       CATALOG = "CATALOG"  # Catalog management
â”‚   â”‚       MERCHANT = "MERCHANT"  # Merchant management
â”‚   â”‚       BILLING = "BILLING"  # Billing management
â”‚   â”‚       CREDIT = "CREDIT"  # Credit management
â”‚   â”‚   
â”‚   â”‚       PROFILE = "PROFILE"  # Merchant users profiles
â”‚   â”‚   
â”‚   â”‚       # Platform Services
â”‚   â”‚       NOTIFICATION = "NOTIFICATION"  # Notification delivery
â”‚   â”‚       ANALYTICS = "ANALYTICS"  # Analytics and reporting
â”‚   â”‚       WEBHOOKS = "WEBHOOKS"  # Webhook delivery
â”‚   â”‚       SCHEDULER = "SCHEDULER"  # Scheduled jobs
â”‚   â”‚   
â”‚   â”‚       # AI Services
â”‚   â”‚       AI_PROCESSING = "AI_PROCESSING"  # AI/ML processing tasks
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class EventWrapper(BaseModel, Generic[TData]):
â”‚   â”‚       """Base wrapper for all events with context support"""
â”‚   â”‚   
â”‚   â”‚       subject: str
â”‚   â”‚       idempotency_key: Optional[str] = None
â”‚   â”‚   
â”‚   â”‚       # Context fields
â”‚   â”‚       event_id: Optional[str] = None
â”‚   â”‚       trace_id: Optional[str] = None
â”‚   â”‚       correlation_id: Optional[str] = None
â”‚   â”‚       timestamp: Optional[datetime] = None
â”‚   â”‚       metadata: Optional[Dict[str, Any]] = None
â”‚   â”‚   
â”‚   â”‚       # Data field is now generic
â”‚   â”‚       data: TData
â”‚   â”‚   
â”‚   â”‚       class Config:
â”‚   â”‚           json_encoders = {UUID: str, datetime: lambda v: v.isoformat()}
â”‚   â”‚   
â”‚   â”‚       @classmethod
â”‚   â”‚       def from_context(
â”‚   â”‚           cls, context: EventContext, data: TData, subject: Optional[str] = None
â”‚   â”‚       ) -> "EventWrapper[TData]":
â”‚   â”‚           """Create EventWrapper from EventContext and data"""
â”‚   â”‚           if not subject:
â”‚   â”‚               subject = context.subject
â”‚   â”‚   
â”‚   â”‚           return cls(
â”‚   â”‚               subject=subject,
â”‚   â”‚               idempotency_key=context.idempotency_key,
â”‚   â”‚               event_id=context.event_id,
â”‚   â”‚               trace_id=context.trace_id,
â”‚   â”‚               correlation_id=context.correlation_id,
â”‚   â”‚               timestamp=context.timestamp,
â”‚   â”‚               metadata=context.metadata,
â”‚   â”‚               data=data,
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       def to_event_dict(self) -> Dict[str, Any]:
â”‚   â”‚           """Convert to event dictionary for publishing"""
â”‚   â”‚           return {
â”‚   â”‚               "event_id": self.event_id,
â”‚   â”‚               "trace_id": self.trace_id,
â”‚   â”‚               "subject": self.subject,
â”‚   â”‚               "correlation_id": self.correlation_id,
â”‚   â”‚               "idempotency_key": self.idempotency_key,
â”‚   â”‚               "timestamp": self.timestamp.isoformat() if self.timestamp else None,
â”‚   â”‚               "metadata": self.metadata or {},
â”‚   â”‚               "payload": (
â”‚   â”‚                   self.data.model_dump() if isinstance(self.data, BaseModel) else {}
â”‚   â”‚               ),
â”‚   â”‚           }
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ base_publisher.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   from typing import Dict, Any, Optional
â”‚   â”‚   
â”‚   â”‚   from .base import Streams
â”‚   â”‚   from .mappers import get_stream_from_subject, get_stream_subjects
â”‚   â”‚   from shared.messaging.publisher import JetStreamEventPublisher
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class DomainEventPublisher(JetStreamEventPublisher):
â”‚   â”‚       """
â”‚   â”‚       Smart publisher that:
â”‚   â”‚       1. Auto-configures streams based on domain
â”‚   â”‚       2. Validates events belong to the correct stream
â”‚   â”‚       3. Provides domain-specific helpers
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       # Concrete classes just set these two properties
â”‚   â”‚       domain_stream: Optional[Streams] = None
â”‚   â”‚       service_name_override: Optional[str] = None
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def stream_name(self) -> str:
â”‚   â”‚           """Auto-determined from domain_stream"""
â”‚   â”‚           if not self.domain_stream:
â”‚   â”‚               raise NotImplementedError("domain_stream must be set")
â”‚   â”‚           return self.domain_stream.value
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def subjects(self) -> list[str]:
â”‚   â”‚           """Auto-determined from domain_stream"""
â”‚   â”‚           if not self.domain_stream:
â”‚   â”‚               raise NotImplementedError("domain_stream must be set")
â”‚   â”‚           return get_stream_subjects(self.domain_stream)
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def service_name(self) -> str:
â”‚   â”‚           """Uses override or defaults"""
â”‚   â”‚           return self.service_name_override or "unknown-service"
â”‚   â”‚   
â”‚   â”‚       def _validate_subject(self, subject: str):
â”‚   â”‚           """
â”‚   â”‚           Ensures you can't accidentally publish a billing event
â”‚   â”‚           from the catalog service
â”‚   â”‚           """
â”‚   â”‚           try:
â”‚   â”‚               # Try to infer stream from event type
â”‚   â”‚               inferred_stream = get_stream_from_subject(subject)
â”‚   â”‚               if inferred_stream != self.domain_stream:
â”‚   â”‚                   raise ValueError(
â”‚   â”‚                       f"Event {subject} belongs to {inferred_stream}, "
â”‚   â”‚                       f"not {self.domain_stream}"
â”‚   â”‚                   )
â”‚   â”‚           except ValueError:
â”‚   â”‚               # For events not following standard pattern, check prefix matches subjects
â”‚   â”‚               if not any(
â”‚   â”‚                   subject.startswith(subj.replace("*", "")) for subj in self.subjects
â”‚   â”‚               ):
â”‚   â”‚                   raise ValueError(
â”‚   â”‚                       f"Event {subject} doesn't match any subject pattern "
â”‚   â”‚                       f"for stream {self.domain_stream}"
â”‚   â”‚                   )
â”‚   â”‚   
â”‚   â”‚       async def publish_event(
â”‚   â”‚           self,
â”‚   â”‚           subject: str,
â”‚   â”‚           payload: Dict[str, Any],
â”‚   â”‚           subject: Optional[str] = None,
â”‚   â”‚           correlation_id: Optional[str] = None,
â”‚   â”‚           idempotency_key: Optional[str] = None,
â”‚   â”‚           metadata: Optional[Dict[str, Any]] = None,
â”‚   â”‚       ) -> str:
â”‚   â”‚           """Override with same signature, adds validation"""
â”‚   â”‚           self._validate_subject(subject)
â”‚   â”‚   
â”‚   â”‚           # Call parent with all parameters
â”‚   â”‚           return await super().publish_event(
â”‚   â”‚               subject=subject,
â”‚   â”‚               payload=payload,
â”‚   â”‚               subject=subject,
â”‚   â”‚               correlation_id=correlation_id,
â”‚   â”‚               idempotency_key=idempotency_key,
â”‚   â”‚               metadata=metadata,
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       async def publish_command(
â”‚   â”‚           self, command_type: str, payload: Dict[str, Any], **kwargs
â”‚   â”‚       ) -> str:
â”‚   â”‚           """Override to add validation"""
â”‚   â”‚           # Ensure command format
â”‚   â”‚           if not command_type.startswith("cmd."):
â”‚   â”‚               command_type = f"cmd.{command_type}"
â”‚   â”‚   
â”‚   â”‚           self._validate_subject(command_type)
â”‚   â”‚   
â”‚   â”‚           return await super().publish_command(command_type, payload, **kwargs)
â”‚   â”‚   
â”‚   â”‚       async def publish_event_response(
â”‚   â”‚           self, subject: str, payload: Dict[str, Any], **kwargs
â”‚   â”‚       ) -> str:
â”‚   â”‚           """Override to add validation"""
â”‚   â”‚           # Ensure event format
â”‚   â”‚           if not subject.startswith("evt."):
â”‚   â”‚               subject = f"evt.{subject}"
â”‚   â”‚   
â”‚   â”‚           self._validate_subject(subject)
â”‚   â”‚   
â”‚   â”‚           return await super().publish_event_response(subject, payload, **kwargs)
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ base_subscriber.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # File: shared/shared/events/base_subscriber.py
â”‚   â”‚   from .mappers import get_stream_from_subject
â”‚   â”‚   from shared.messaging.subscriber import JetStreamEventSubscriber
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class DomainEventSubscriber(JetStreamEventSubscriber):
â”‚   â”‚       """
â”‚   â”‚       Smart subscriber that:
â”‚   â”‚       1. Auto-determines stream from event type
â”‚   â”‚       2. Provides helpers for cross-domain subscriptions
â”‚   â”‚       3. Validates event structure
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def stream_name(self) -> str:
â”‚   â”‚           """Auto-determine stream from event type"""
â”‚   â”‚           try:
â”‚   â”‚               stream = get_stream_from_subject(self.subject)
â”‚   â”‚               return stream.value
â”‚   â”‚           except ValueError:
â”‚   â”‚               # For events not following standard pattern, must override
â”‚   â”‚               return self._stream_name_override()
â”‚   â”‚   
â”‚   â”‚       def _stream_name_override(self) -> str:
â”‚   â”‚           """Override when subscribing to events not following standard pattern"""
â”‚   â”‚           raise NotImplementedError(
â”‚   â”‚               f"Event {self.subject} doesn't follow standard pattern, "
â”‚   â”‚               f"must override _stream_name_override"
â”‚   â”‚           )
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ context.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/events/context.py
â”‚   â”‚   """
â”‚   â”‚   Standardized event context management for all services.
â”‚   â”‚   """
â”‚   â”‚   from uuid7 import uuid7
â”‚   â”‚   from uuid import uuid4
â”‚   â”‚   from typing import Dict, Any, Optional, TypeVar, Generic
â”‚   â”‚   from dataclasses import dataclass
â”‚   â”‚   from datetime import datetime, timezone
â”‚   â”‚   
â”‚   â”‚   from ..api.correlation import set_correlation_context, get_correlation_context
â”‚   â”‚   from shared.api.tracing import set_trace_context, get_trace_context
â”‚   â”‚   
â”‚   â”‚   T = TypeVar("T")
â”‚   â”‚   
â”‚   â”‚   @dataclass
â”‚   â”‚   class EventContext:
â”‚   â”‚       """Standard context for all events across the platform"""
â”‚   â”‚   
â”‚   â”‚       event_id: str
â”‚   â”‚       trace_id: str
â”‚   â”‚       subject: str
â”‚   â”‚       correlation_id: Optional[str]
â”‚   â”‚       timestamp: datetime
â”‚   â”‚       source_service: str
â”‚   â”‚       idempotency_key: Optional[str] = None
â”‚   â”‚       metadata: Optional[Dict[str, Any]] = None
â”‚   â”‚   
â”‚   â”‚       def __post_init__(self):
â”‚   â”‚           if self.metadata is None:
â”‚   â”‚               self.metadata = {}
â”‚   â”‚   
â”‚   â”‚       @classmethod
â”‚   â”‚       def from_event(cls, event: Dict[str, Any]) -> "EventContext":
â”‚   â”‚           """Extract context from incoming event"""
â”‚   â”‚           return cls(
â”‚   â”‚               event_id=event.get("event_id", ""),
â”‚   â”‚               trace_id=event.get("trace_id", ""),
â”‚   â”‚               subject=event.get("subject", ""),
â”‚   â”‚               correlation_id=event.get("correlation_id"),
â”‚   â”‚               timestamp=datetime.fromisoformat(
â”‚   â”‚                   event.get("timestamp", datetime.now(timezone.utc).isoformat())
â”‚   â”‚               ),
â”‚   â”‚               source_service=event.get("metadata", {}).get("source_service", "unknown"),
â”‚   â”‚               idempotency_key=event.get("idempotency_key"),
â”‚   â”‚               metadata=event.get("metadata", {}),
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       @classmethod
â”‚   â”‚       def create(
â”‚   â”‚           cls,
â”‚   â”‚           *,
â”‚   â”‚           subject: str,
â”‚   â”‚           source_service: str,
â”‚   â”‚           correlation_id: Optional[str] = None,
â”‚   â”‚           idempotency_key: Optional[str] = None,
â”‚   â”‚           metadata: Optional[Dict[str, Any]] = None,
â”‚   â”‚           trace_id: Optional[str] = None,
â”‚   â”‚       ) -> "EventContext":
â”‚   â”‚           """Create new event context"""
â”‚   â”‚           if not correlation_id:
â”‚   â”‚               correlation_id = get_correlation_context()
â”‚   â”‚           if not trace_id:
â”‚   â”‚               trace_id = get_trace_context() or correlation_id or str(uuid7())
â”‚   â”‚           return cls(
â”‚   â”‚               event_id=str(uuid4()),
â”‚   â”‚               trace_id=trace_id,
â”‚   â”‚               subject=subject,
â”‚   â”‚               correlation_id=correlation_id,
â”‚   â”‚               timestamp=datetime.now(timezone.utc),
â”‚   â”‚               source_service=source_service,
â”‚   â”‚               idempotency_key=idempotency_key,
â”‚   â”‚               metadata=metadata or {},
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       def to_dict(self) -> Dict[str, Any]:
â”‚   â”‚           """Convert context to dictionary for logging or serialization"""
â”‚   â”‚           return {
â”‚   â”‚               "event_id": self.event_id,
â”‚   â”‚               "trace_id": self.trace_id,
â”‚   â”‚               "subject": self.subject,
â”‚   â”‚               "correlation_id": self.correlation_id,
â”‚   â”‚               "timestamp": self.timestamp.isoformat(),
â”‚   â”‚               "source_service": self.source_service,
â”‚   â”‚               "idempotency_key": self.idempotency_key,
â”‚   â”‚               "metadata": self.metadata,  # keep nested
â”‚   â”‚           }
â”‚   â”‚   
â”‚   â”‚       def apply_correlation(self):
â”‚   â”‚           """Apply correlation and trace context to async context"""
â”‚   â”‚           if self.correlation_id:
â”‚   â”‚               set_correlation_context(self.correlation_id)
â”‚   â”‚           if self.trace_id:
â”‚   â”‚               set_trace_context(self.trace_id)
â”‚   â”‚   
â”‚   â”‚       def create_response_context(
â”‚   â”‚           self,
â”‚   â”‚           response_subject: str,
â”‚   â”‚           response_service: str,
â”‚   â”‚           idempotency_key: Optional[str] = None,
â”‚   â”‚           additional_metadata: Optional[Dict[str, Any]] = None,
â”‚   â”‚       ) -> "EventContext":
â”‚   â”‚           """Create context for response events, preserving correlation chain"""
â”‚   â”‚           metadata = {
â”‚   â”‚               "triggered_by": self.event_id,
â”‚   â”‚               "original_source": self.source_service,
â”‚   â”‚               **(additional_metadata or {}),
â”‚   â”‚           }
â”‚   â”‚   
â”‚   â”‚           return EventContext.create(
â”‚   â”‚               subject=response_subject,
â”‚   â”‚               source_service=response_service,
â”‚   â”‚               correlation_id=self.correlation_id,
â”‚   â”‚               trace_id=self.trace_id,
â”‚   â”‚               idempotency_key=idempotency_key,
â”‚   â”‚               metadata=metadata,
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   @dataclass
â”‚   â”‚   class EventPayload(Generic[T]):
â”‚   â”‚       """Wrapper for typed event payloads with context"""
â”‚   â”‚   
â”‚   â”‚       context: EventContext
â”‚   â”‚       data: T
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def correlation_id(self) -> Optional[str]:
â”‚   â”‚           return self.context.correlation_id
â”‚   â”‚   
â”‚   â”‚       def to_event_dict(self) -> Dict[str, Any]:
â”‚   â”‚           """Convert to event dictionary for publishing"""
â”‚   â”‚           return {
â”‚   â”‚               "event_id": self.context.event_id,
â”‚   â”‚               "subject": self.context.subject,
â”‚   â”‚               "correlation_id": self.context.correlation_id,
â”‚   â”‚               "idempotency_key": self.context.idempotency_key,
â”‚   â”‚               "timestamp": self.context.timestamp.isoformat(),
â”‚   â”‚               "metadata": {
â”‚   â”‚                   "source_service": self.context.source_service,
â”‚   â”‚                   **(self.context.metadata or {}),
â”‚   â”‚               },
â”‚   â”‚               "payload": self.data if isinstance(self.data, dict) else {},
â”‚   â”‚           }
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class EventContextManager:
â”‚   â”‚       """
â”‚   â”‚       Manages event context throughout processing lifecycle.
â”‚   â”‚       This can be used by any service that processes events.
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       def __init__(self, logger=None):
â”‚   â”‚           self.logger = logger
â”‚   â”‚   
â”‚   â”‚       def extract_context(self, event: Dict[str, Any]) -> EventContext:
â”‚   â”‚           """Extract and validate event context"""
â”‚   â”‚           context = EventContext.from_event(event)
â”‚   â”‚   
â”‚   â”‚           # Validate required fields
â”‚   â”‚           if not context.event_id and self.logger:
â”‚   â”‚               self.logger.warning("Event missing event_id", extra={"event": event})
â”‚   â”‚   
â”‚   â”‚           if not context.subject:
â”‚   â”‚               raise ValueError("Event missing required subject")
â”‚   â”‚   
â”‚   â”‚           # Apply correlation context
â”‚   â”‚           context.apply_correlation()
â”‚   â”‚   
â”‚   â”‚           # Log event reception
â”‚   â”‚           if self.logger:
â”‚   â”‚               self.logger.info(
â”‚   â”‚                   f"Processing {context.subject} event", extra=context.to_dict()
â”‚   â”‚               )
â”‚   â”‚   
â”‚   â”‚           return context
â”‚   â”‚   
â”‚   â”‚       def log_event_completion(
â”‚   â”‚           self,
â”‚   â”‚           context: EventContext,
â”‚   â”‚           success: bool,
â”‚   â”‚           duration_ms: float,
â”‚   â”‚           error: Optional[Exception] = None,
â”‚   â”‚           additional_data: Optional[Dict[str, Any]] = None,
â”‚   â”‚       ):
â”‚   â”‚           """Log event processing completion"""
â”‚   â”‚           if not self.logger:
â”‚   â”‚               return
â”‚   â”‚   
â”‚   â”‚           log_data = {
â”‚   â”‚               **context.to_dict(),
â”‚   â”‚               "success": success,
â”‚   â”‚               "duration_ms": duration_ms,
â”‚   â”‚               **(additional_data or {}),
â”‚   â”‚           }
â”‚   â”‚   
â”‚   â”‚           if success:
â”‚   â”‚               self.logger.info(f"Completed processing {context.subject}", extra=log_data)
â”‚   â”‚           else:
â”‚   â”‚               self.logger.error(
â”‚   â”‚                   f"Failed to process {context.subject}: {error}",
â”‚   â”‚                   extra={
â”‚   â”‚                       **log_data,
â”‚   â”‚                       "error_type": type(error).__name__ if error else "Unknown",
â”‚   â”‚                   },
â”‚   â”‚                   exc_info=error,
â”‚   â”‚               )
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ mappers.py
â”‚       
â”‚       ```py
â”‚       # shared/events/mappers.py
â”‚       from typing import List
â”‚       from .base import Streams
â”‚       
â”‚       # Simple service to stream mapping
â”‚       SERVICE_STREAM_MAP = {
â”‚           "analytics-service": Streams.ANALYTICS,
â”‚           "billing-service": Streams.BILLING,
â”‚           "catalog-ai-service": Streams.AI_PROCESSING,
â”‚           "catalog-connector": Streams.CATALOG,
â”‚           "catalog-service": Streams.CATALOG,
â”‚           "credit-service": Streams.CREDIT,
â”‚           "merchant-service": Streams.MERCHANT,
â”‚           "notification-service": Streams.NOTIFICATION,
â”‚           "profile-ai-selfie": Streams.AI_PROCESSING,
â”‚           "profile-service": Streams.PROFILE,
â”‚           "scheduler-service": Streams.SCHEDULER,
â”‚           "webhook-service": Streams.WEBHOOKS,
â”‚       }
â”‚       
â”‚       
â”‚       def get_stream_subjects(stream: Streams) -> List[str]:
â”‚           """Get all subjects for a stream"""
â”‚           stream_prefix = stream.value.lower()
â”‚           return [f"cmd.{stream_prefix}.*", f"evt.{stream_prefix}.*"]
â”‚       
â”‚       
â”‚       def get_stream_for_service(service_name: str) -> Streams:
â”‚           """Get the stream for a service"""
â”‚           if service_name not in SERVICE_STREAM_MAP:
â”‚               raise ValueError(f"Unknown service: {service_name}")
â”‚           return SERVICE_STREAM_MAP[service_name]
â”‚       
â”‚       
â”‚       def get_stream_from_subject(subject: str) -> Streams:
â”‚           """
â”‚           Infer stream from event type.
â”‚           Event types follow pattern: cmd.domain.* or evt.domain.*
â”‚           """
â”‚           parts = subject.split(".")
â”‚           if len(parts) >= 2 and parts[0] in ["cmd", "evt"]:
â”‚               domain = parts[1].upper()
â”‚               if hasattr(Streams, domain):
â”‚                   return Streams[domain]
â”‚       
â”‚           raise ValueError(f"Cannot infer stream from event type: {subject}")
â”‚       ```
â”‚       
â”œâ”€â”€ mappers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/mappers/__init__.py
â”‚   â”‚   
â”‚   â”‚   """Shared mapper infrastructure for all services."""
â”‚   â”‚   
â”‚   â”‚   from .base import (
â”‚   â”‚       BaseMapper,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   __all__ = [
â”‚   â”‚       "BaseMapper",
â”‚   â”‚   ]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # File: shared/shared/mappers/base.py
â”‚   â”‚   from __future__ import annotations
â”‚   â”‚   
â”‚   â”‚   from typing import TypeVar, Generic, List, Dict, Any, Optional
â”‚   â”‚   from abc import ABC, abstractmethod
â”‚   â”‚   from pydantic import BaseModel
â”‚   â”‚   
â”‚   â”‚   # Type variables
â”‚   â”‚   ModelT = TypeVar("ModelT")
â”‚   â”‚   CreateT = TypeVar("CreateT", bound=BaseModel)
â”‚   â”‚   UpdateT = TypeVar("UpdateT", bound=BaseModel)
â”‚   â”‚   ResponseT = TypeVar("ResponseT", bound=BaseModel)
â”‚   â”‚   
â”‚   â”‚   class BaseMapper(Generic[ModelT, CreateT, UpdateT, ResponseT], ABC):
â”‚   â”‚       """
â”‚   â”‚       Universal mapper for all entities with optional update support.
â”‚   â”‚       
â”‚   â”‚       Required methods (always implement):
â”‚   â”‚       - create_to_model: Convert create schema to model
â”‚   â”‚       - model_to_response: Convert model to basic response
â”‚   â”‚       
â”‚   â”‚       Optional methods (implement only if your entity needs them):
â”‚   â”‚       - update_to_dict: For updatable entities  
â”‚   â”‚       - model_to_detail_response: For entities with detailed views
â”‚   â”‚       """
â”‚   â”‚       __slots__ = ()  # Memory optimization
â”‚   â”‚       
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def create_to_model(self, create_schema: CreateT, **kwargs) -> ModelT:
â”‚   â”‚           """Convert create schema to model instance."""
â”‚   â”‚           pass
â”‚   â”‚       
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def model_to_response(self, model: ModelT) -> ResponseT:
â”‚   â”‚           """Convert model instance to basic response schema."""
â”‚   â”‚           pass
â”‚   â”‚       
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def models_to_responses(self, models: List[ModelT]) -> List[ResponseT]:
â”‚   â”‚           """Convert list of models to list of response schemas."""
â”‚   â”‚           return [self.model_to_response(model) for model in models]
â”‚   â”‚       
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def update_to_dict(self, update_schema: UpdateT) -> Dict[str, Any]:
â”‚   â”‚           """
â”‚   â”‚           Optional: Convert update schema to dict for partial updates.
â”‚   â”‚           Only implement this method if your entity supports updates.
â”‚   â”‚           """
â”‚   â”‚           return {
â”‚   â”‚               k: v for k, v in update_schema.model_dump(exclude_none=True).items()
â”‚   â”‚           }
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ crud_mapper.py
â”‚       
â”‚       ```py
â”‚       # mappers/generic.py
â”‚       from __future__ import annotations
â”‚       from typing import TypeVar, Generic, List
â”‚       from pydantic import BaseModel, TypeAdapter
â”‚       from sqlalchemy.orm import DeclarativeBase
â”‚       from sqlalchemy import inspect
â”‚       
â”‚       ModelT = TypeVar('ModelT', bound=DeclarativeBase)
â”‚       InT    = TypeVar('InT',    bound=BaseModel)
â”‚       PatchT = TypeVar('PatchT', bound=BaseModel | None)
â”‚       OutT   = TypeVar('OutT',   bound=BaseModel)
â”‚       
â”‚       class CRUDMapper(Generic[ModelT, InT, PatchT, OutT]):
â”‚           """Bidirectional bridge between SQLAlchemy models and Pydantic DTOs."""
â”‚       
â”‚           model_cls: type[ModelT]
â”‚           out_schema: type[OutT]
â”‚       
â”‚           # ---------- CREATE ---------- #
â”‚           def to_model(self, dto: InT, **extra) -> ModelT:
â”‚               return self.model_cls(**dto.model_dump(), **extra)
â”‚       
â”‚           # ---------- PATCH ---------- #
â”‚           def patch_model(self, obj: ModelT, patch: PatchT) -> None:
â”‚               if patch is None:
â”‚                   return
â”‚               for field, value in patch.model_dump(exclude_unset=True).items():
â”‚                   setattr(obj, field, value)
â”‚               
â”‚       
â”‚           # ---------- READ ---------- #
â”‚           def to_out(self, obj: ModelT) -> OutT:
â”‚               # from_attributes=True must be set on OutT
â”‚               return self.out_schema.model_validate(obj)
â”‚       
â”‚           def list_to_out(self, objs: List[ModelT]) -> List[OutT]:
â”‚               # faster validation for big lists
â”‚               ta = TypeAdapter(List[self.out_schema])  # type: ignore[arg-type]
â”‚               return ta.validate_python(objs)
â”‚       
â”‚           # ---------- HELPER ---------- #
â”‚           @staticmethod
â”‚           def is_dirty(obj: ModelT) -> bool:
â”‚               return bool(inspect(obj).attrs.modified)
â”‚       ```
â”‚       
â”œâ”€â”€ messaging/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ dependencies.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/messaging/dependencies.py
â”‚   â”‚   from typing import Any, Dict, Literal, get_args
â”‚   â”‚   
â”‚   â”‚   # Define all valid dependency keys across the platform
â”‚   â”‚   DepKeys = Literal[
â”‚   â”‚       "credit_service",
â”‚   â”‚       "credit_transaction_service", 
â”‚   â”‚       "notification_service",
â”‚   â”‚       "logger",
â”‚   â”‚       # Test-only keys
â”‚   â”‚       "test_service",
â”‚   â”‚   ]
â”‚   â”‚   
â”‚   â”‚   class ServiceDependencies:
â”‚   â”‚       """Service-scoped dependency container with typed key constraints"""
â”‚   â”‚       
â”‚   â”‚       def __init__(self):
â”‚   â”‚           self._deps: Dict[str, Any] = {}
â”‚   â”‚       
â”‚   â”‚       def register(self, key: DepKeys, instance: Any) -> None:
â”‚   â”‚           """Register a dependency - prevents accidental shadowing"""
â”‚   â”‚           if key in self._deps:
â”‚   â”‚               raise RuntimeError(f"Dependency '{key}' already registered")
â”‚   â”‚           self._deps[key] = instance
â”‚   â”‚       
â”‚   â”‚       def get(self, key: DepKeys) -> Any:
â”‚   â”‚           """Get a dependency with type-constrained keys"""
â”‚   â”‚           if key not in self._deps:
â”‚   â”‚               available = list(self._deps.keys())
â”‚   â”‚               raise KeyError(
â”‚   â”‚                   f"Dependency '{key}' not registered. Available: {available}"
â”‚   â”‚               )
â”‚   â”‚           return self._deps[key]
â”‚   â”‚       
â”‚   â”‚       def has(self, key: DepKeys) -> bool:
â”‚   â”‚           """Check if dependency is registered"""
â”‚   â”‚           return key in self._deps
â”‚   â”‚       
â”‚   â”‚       def clear(self) -> None:
â”‚   â”‚           """Clear all dependencies (for testing)"""
â”‚   â”‚           self._deps.clear()
â”‚   â”‚           
â”‚   â”‚       def register_many(self, **kwargs) -> None:
â”‚   â”‚           """Bulk register dependencies for cleaner lifecycle code"""
â”‚   â”‚           for key, instance in kwargs.items():
â”‚   â”‚               if key not in get_args(DepKeys):
â”‚   â”‚                   raise ValueError(f"Invalid dependency key: {key}")
â”‚   â”‚               self.register(key, instance)
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ jetstream_wrapper.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/messaging/jetstream_wrapper.py
â”‚   â”‚   from typing import List, Optional, Dict, Type, Any, TypeVar, cast
â”‚   â”‚   import os
â”‚   â”‚   import asyncio
â”‚   â”‚   
â”‚   â”‚   import nats
â”‚   â”‚   from nats.aio.client import Client
â”‚   â”‚   from nats.js import JetStreamContext
â”‚   â”‚   
â”‚   â”‚   from shared.messaging.publisher import JetStreamEventPublisher
â”‚   â”‚   from shared.messaging.subscriber import JetStreamEventSubscriber
â”‚   â”‚   from .dependencies import ServiceDependencies, DepKeys
â”‚   â”‚   
â”‚   â”‚   T = TypeVar('T', bound=JetStreamEventPublisher)
â”‚   â”‚   
â”‚   â”‚   class JetStreamWrapper:
â”‚   â”‚       """JetStream wrapper with service-scoped dependency injection"""
â”‚   â”‚       
â”‚   â”‚       def __init__(self, logger: Optional[Any] = None):
â”‚   â”‚           self._client: Optional[Client] = None
â”‚   â”‚           self._js: Optional[JetStreamContext] = None
â”‚   â”‚           self._publishers: Dict[str, JetStreamEventPublisher] = {}
â”‚   â”‚           self._subscribers: List[JetStreamEventSubscriber] = []
â”‚   â”‚           self._tasks: List[asyncio.Task] = []
â”‚   â”‚           self.logger = logger
â”‚   â”‚           self.dependencies = ServiceDependencies()
â”‚   â”‚       
â”‚   â”‚       async def __aenter__(self):
â”‚   â”‚           """Async context manager entry"""
â”‚   â”‚           return self
â”‚   â”‚       
â”‚   â”‚       async def __aexit__(self, exc_type, exc_val, exc_tb):
â”‚   â”‚           """Guaranteed cleanup even if caller forgets close()"""
â”‚   â”‚           await self.close()
â”‚   â”‚       
â”‚   â”‚       @property
â”‚   â”‚       def client(self) -> Client:
â”‚   â”‚           """Get the NATS client (for backward compatibility)"""
â”‚   â”‚           if not self._client:
â”‚   â”‚               raise Exception("NATS client not connected")
â”‚   â”‚           return self._client
â”‚   â”‚       
â”‚   â”‚       @property
â”‚   â”‚       def js(self) -> JetStreamContext:
â”‚   â”‚           """Get the JetStream context"""
â”‚   â”‚           if not self._js:
â”‚   â”‚               raise Exception("JetStream not initialized")
â”‚   â”‚           return self._js
â”‚   â”‚       
â”‚   â”‚       @property
â”‚   â”‚       def publishers(self) -> Dict[str, JetStreamEventPublisher]:
â”‚   â”‚           """Get all registered publishers"""
â”‚   â”‚           return self._publishers
â”‚   â”‚       
â”‚   â”‚       async def connect(self, servers: List[str]):
â”‚   â”‚           """Connect to NATS and initialize JetStream"""
â”‚   â”‚           try:
â”‚   â”‚               # Connection options
â”‚   â”‚               options = {
â”‚   â”‚                   "servers": servers,
â”‚   â”‚                   "max_reconnect_attempts": -1,
â”‚   â”‚                   "reconnect_time_wait": 2,
â”‚   â”‚               }
â”‚   â”‚               
â”‚   â”‚               # Add authentication if provided
â”‚   â”‚               if user := os.getenv("NATS_USER"):
â”‚   â”‚                   options["user"] = user
â”‚   â”‚                   options["password"] = os.getenv("NATS_PASSWORD", "")
â”‚   â”‚               
â”‚   â”‚               self._client = await nats.connect(**options)
â”‚   â”‚               self._js = self._client.jetstream()
â”‚   â”‚               
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.info(f"Connected to NATS with JetStream at {servers}")
â”‚   â”‚               
â”‚   â”‚           except Exception as e:
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.error(f"Failed to connect to NATS: {e}")
â”‚   â”‚               raise
â”‚   â”‚       
â”‚   â”‚       async def close(self):
â”‚   â”‚           """Enhanced cleanup with task cancellation"""
â”‚   â”‚           # Cancel all subscriber tasks
â”‚   â”‚           for task in self._tasks:
â”‚   â”‚               task.cancel()
â”‚   â”‚           
â”‚   â”‚           # Wait for graceful shutdown
â”‚   â”‚           if self._tasks:
â”‚   â”‚               await asyncio.gather(*self._tasks, return_exceptions=True)
â”‚   â”‚           
â”‚   â”‚           # Stop subscribers
â”‚   â”‚           for subscriber in self._subscribers:
â”‚   â”‚               try:
â”‚   â”‚                   await subscriber.stop()
â”‚   â”‚               except Exception as e:
â”‚   â”‚                   if self.logger:
â”‚   â”‚                       self.logger.error(f"Error stopping subscriber: {e}")
â”‚   â”‚           
â”‚   â”‚           # Close NATS connection
â”‚   â”‚           if self._client and not self._client.is_closed:
â”‚   â”‚               await self._client.close()
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.info("NATS connection closed")
â”‚   â”‚       
â”‚   â”‚       def is_connected(self) -> bool:
â”‚   â”‚           """Health check helper for /healthz endpoints"""
â”‚   â”‚           return bool(self._client and self._client.is_connected)
â”‚   â”‚       
â”‚   â”‚       def register_dependency(self, key: DepKeys, instance: Any) -> None:
â”‚   â”‚           """
â”‚   â”‚           Register a dependency for this wrapper's subscribers.
â”‚   â”‚           Typical keys: see shared/messaging/dependencies.DepKeys.
â”‚   â”‚           """
â”‚   â”‚           self.dependencies.register(key, instance)
â”‚   â”‚           if self.logger:
â”‚   â”‚               self.logger.debug(f"Registered dependency: {key}")
â”‚   â”‚       
â”‚   â”‚       def create_publisher(self, publisher_class: Type[T]) -> T:
â”‚   â”‚           """Create and cache a publisher instance"""
â”‚   â”‚           class_name = publisher_class.__name__
â”‚   â”‚           
â”‚   â”‚           if class_name not in self._publishers:
â”‚   â”‚               if not self._client or not self._js:
â”‚   â”‚                   raise Exception("Must connect to NATS before creating publishers")
â”‚   â”‚               
â”‚   â”‚               self._publishers[class_name] = publisher_class(self._client, self._js, self.logger)
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.info(f"Created publisher: {class_name}")
â”‚   â”‚           
â”‚   â”‚           return cast(T, self._publishers[class_name])
â”‚   â”‚       
â”‚   â”‚       def get_publisher(self, publisher_class: Type[T]) -> Optional[T]:
â”‚   â”‚           """Get a publisher by class type"""
â”‚   â”‚           publisher = self._publishers.get(publisher_class.__name__)
â”‚   â”‚           return cast(T, publisher) if publisher else None
â”‚   â”‚       
â”‚   â”‚       def create_subscriber(self, subscriber_class: Type[JetStreamEventSubscriber]) -> JetStreamEventSubscriber:
â”‚   â”‚           """Create subscriber with wrapper access for dependencies"""
â”‚   â”‚           if not self._client or not self._js:
â”‚   â”‚               raise Exception("Must connect to NATS before creating subscribers")
â”‚   â”‚           
â”‚   â”‚           # Pass wrapper reference so subscriber can access dependencies
â”‚   â”‚           subscriber = subscriber_class(self._client, self._js, self.logger, self)
â”‚   â”‚           self._subscribers.append(subscriber)
â”‚   â”‚           if self.logger:
â”‚   â”‚               self.logger.info(f"Created subscriber: {subscriber_class.__name__}")
â”‚   â”‚           
â”‚   â”‚           return subscriber
â”‚   â”‚       
â”‚   â”‚       async def start_subscriber(self, subscriber_class: Type[JetStreamEventSubscriber]):
â”‚   â”‚           """Create and start a subscriber in the background"""
â”‚   â”‚           subscriber = self.create_subscriber(subscriber_class)
â”‚   â”‚           task = asyncio.create_task(subscriber.listen())
â”‚   â”‚           self._tasks.append(task)  # Track for proper cleanup
â”‚   â”‚           
â”‚   â”‚           if self.logger:
â”‚   â”‚               self.logger.info(f"Started subscriber: {subscriber_class.__name__}")
â”‚   â”‚           
â”‚   â”‚           return task
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ publisher.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # File: shared/shared/messaging/publisher.py
â”‚   â”‚   import json
â”‚   â”‚   import uuid
â”‚   â”‚   from abc import ABC, abstractmethod
â”‚   â”‚   from typing import Dict, Any, Optional
â”‚   â”‚   from datetime import datetime, timezone
â”‚   â”‚   
â”‚   â”‚   from nats.aio.client import Client
â”‚   â”‚   from nats.js import JetStreamContext
â”‚   â”‚   from nats.js.api import StreamConfig, RetentionPolicy, StorageType
â”‚   â”‚   
â”‚   â”‚   from shared.api.tracing import get_trace_context
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class JetStreamEventPublisher(ABC):
â”‚   â”‚       """
â”‚   â”‚       JetStream publisher specifically for structured events.
â”‚   â”‚       Combines base functionality with event structure in one class.
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def stream_name(self) -> str:
â”‚   â”‚           """The JetStream stream name to publish to."""
â”‚   â”‚           pass
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def subjects(self) -> list[str]:
â”‚   â”‚           """List of subjects this stream should handle."""
â”‚   â”‚           pass
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       @abstractmethod
â”‚   â”‚       def service_name(self) -> str:
â”‚   â”‚           """The name of the service publishing events."""
â”‚   â”‚           pass
â”‚   â”‚   
â”‚   â”‚       @property
â”‚   â”‚       def service_version(self) -> str:
â”‚   â”‚           """The version of the service."""
â”‚   â”‚           return "1.0.0"
â”‚   â”‚   
â”‚   â”‚       def __init__(
â”‚   â”‚           self, client: Client, js: JetStreamContext, logger: Optional[Any] = None
â”‚   â”‚       ):
â”‚   â”‚           self.client = client
â”‚   â”‚           self.js = js
â”‚   â”‚           self._stream_created = False
â”‚   â”‚           self.logger = logger or self._get_default_logger()
â”‚   â”‚   
â”‚   â”‚       def _get_default_logger(self):
â”‚   â”‚           """Get a default logger if none provided"""
â”‚   â”‚           import logging
â”‚   â”‚   
â”‚   â”‚           return logging.getLogger(self.__class__.__name__)
â”‚   â”‚   
â”‚   â”‚       async def ensure_stream(self) -> None:
â”‚   â”‚           """Ensure the stream exists with default configuration."""
â”‚   â”‚           if self._stream_created:
â”‚   â”‚               return
â”‚   â”‚   
â”‚   â”‚           stream_config = StreamConfig(
â”‚   â”‚               name=self.stream_name,
â”‚   â”‚               subjects=self.subjects,
â”‚   â”‚               retention=RetentionPolicy.LIMITS,
â”‚   â”‚               max_age=7 * 24 * 60 * 60,  # 7 days
â”‚   â”‚               max_msgs_per_subject=100000,
â”‚   â”‚               storage=StorageType.FILE,
â”‚   â”‚               duplicate_window=60,
â”‚   â”‚               allow_rollup_hdrs=True,
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚           try:
â”‚   â”‚               await self.js.stream_info(self.stream_name)
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.info(f"Using existing stream: {self.stream_name}")
â”‚   â”‚           except:
â”‚   â”‚               await self.js.add_stream(stream_config)
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.info(f"Created new stream: {self.stream_name}")
â”‚   â”‚   
â”‚   â”‚           self._stream_created = True
â”‚   â”‚   
â”‚   â”‚       async def publish_event(
â”‚   â”‚           self,
â”‚   â”‚           subject: str,
â”‚   â”‚           payload: Dict[str, Any],
â”‚   â”‚           subject: Optional[str] = None,
â”‚   â”‚           correlation_id: Optional[str] = None,
â”‚   â”‚           trace_id: Optional[str] = None,
â”‚   â”‚           idempotency_key: Optional[str] = None,
â”‚   â”‚           metadata: Optional[Dict[str, Any]] = None,
â”‚   â”‚       ) -> str:
â”‚   â”‚           """Publish a structured event."""
â”‚   â”‚           await self.ensure_stream()
â”‚   â”‚   
â”‚   â”‚           # Generate IDs
â”‚   â”‚           event_id = str(uuid.uuid4())
â”‚   â”‚           if not correlation_id:
â”‚   â”‚               correlation_id = str(uuid.uuid4())
â”‚   â”‚           if not idempotency_key:
â”‚   â”‚               idempotency_key = event_id
â”‚   â”‚   
â”‚   â”‚           trace_id = trace_id or (get_trace_context() or correlation_id)
â”‚   â”‚   
â”‚   â”‚           # Build event
â”‚   â”‚           event = {
â”‚   â”‚               "event_id": event_id,
â”‚   â”‚               "subject": subject,
â”‚   â”‚               "correlation_id": correlation_id,
â”‚   â”‚               "idempotency_key": idempotency_key,
â”‚   â”‚               "timestamp": datetime.now(timezone.utc).isoformat(),
â”‚   â”‚               "metadata": {
â”‚   â”‚                   "source_service": self.service_name,
â”‚   â”‚                   "version": self.service_version,
â”‚   â”‚                   **(metadata or {}),
â”‚   â”‚               },
â”‚   â”‚               "payload": payload,
â”‚   â”‚           }
â”‚   â”‚   
â”‚   â”‚           # Publish
â”‚   â”‚           subject = subject or subject
â”‚   â”‚           headers = {"Nats-Msg-Id": idempotency_key}
â”‚   â”‚   
â”‚   â”‚           try:
â”‚   â”‚               ack = await self.js.publish(
â”‚   â”‚                   subject, json.dumps(event).encode("utf-8"), headers=headers
â”‚   â”‚               )
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.debug(f"Published {subject} to {subject} (seq: {ack.seq})")
â”‚   â”‚   
â”‚   â”‚               if ack.duplicate:
â”‚   â”‚                   self.logger.info(
â”‚   â”‚                       f"Duplicate message detected and ignored",
â”‚   â”‚                       extra={"idempotency_key": idempotency_key},
â”‚   â”‚                   )
â”‚   â”‚               return event_id
â”‚   â”‚   
â”‚   â”‚           except Exception as e:
â”‚   â”‚               if self.logger:
â”‚   â”‚                   self.logger.critical(
â”‚   â”‚                       f"Failed to publish to {subject}: {e}", exc_info=True
â”‚   â”‚                   )
â”‚   â”‚               raise
â”‚   â”‚   
â”‚   â”‚       async def publish_command(
â”‚   â”‚           self, command_type: str, payload: Dict[str, Any], **kwargs
â”‚   â”‚       ) -> str:
â”‚   â”‚           """Publish a command event."""
â”‚   â”‚           if not command_type.startswith("cmd."):
â”‚   â”‚               command_type = f"cmd.{command_type}"
â”‚   â”‚   
â”‚   â”‚           idempotency_key = kwargs.pop("idempotency_key", None)
â”‚   â”‚   
â”‚   â”‚           return await self.publish_event(
â”‚   â”‚               subject=command_type,
â”‚   â”‚               payload=payload,
â”‚   â”‚               idempotency_key=idempotency_key,
â”‚   â”‚               **kwargs,
â”‚   â”‚           )
â”‚   â”‚   
â”‚   â”‚       async def publish_event_response(
â”‚   â”‚           self, subject: str, payload: Dict[str, Any], **kwargs
â”‚   â”‚       ) -> str:
â”‚   â”‚           """Publish an event response."""
â”‚   â”‚           if not subject.startswith("evt."):
â”‚   â”‚               subject = f"evt.{subject}"
â”‚   â”‚   
â”‚   â”‚           # Ensure idempotency key is set
â”‚   â”‚           idempotency_key = kwargs.pop("idempotency_key", None)
â”‚   â”‚   
â”‚   â”‚           return await self.publish_event(
â”‚   â”‚               subject=subject, payload=payload, idempotency_key=idempotency_key, **kwargs
â”‚   â”‚           )
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ subscriber.py
â”‚       
â”‚       ```py
â”‚       # shared/messaging/subscriber.py
â”‚       import json
â”‚       from abc import ABC, abstractmethod
â”‚       from typing import Dict, Any, Optional, TYPE_CHECKING
â”‚       import asyncio
â”‚       
â”‚       from nats.aio.client import Client
â”‚       from nats.js import JetStreamContext
â”‚       from nats.js.api import ConsumerConfig, DeliverPolicy, AckPolicy
â”‚       from .dependencies import DepKeys
â”‚       
â”‚       if TYPE_CHECKING:
â”‚           from .jetstream_wrapper import JetStreamWrapper
â”‚       
â”‚       
â”‚       class JetStreamEventSubscriber(ABC):
â”‚           """
â”‚           JetStream subscriber specifically for structured events.
â”‚           Combines base functionality with event handling in one class.
â”‚           """
â”‚       
â”‚           @property
â”‚           @abstractmethod
â”‚           def stream_name(self) -> str:
â”‚               """The JetStream stream name to subscribe to."""
â”‚               pass
â”‚       
â”‚           @property
â”‚           @abstractmethod
â”‚           def subject(self) -> str:
â”‚               """The subject pattern to subscribe to."""
â”‚               pass
â”‚       
â”‚           @property
â”‚           @abstractmethod
â”‚           def durable_name(self) -> str:
â”‚               """The durable consumer name."""
â”‚               pass
â”‚       
â”‚           @property
â”‚           @abstractmethod
â”‚           def subject(self) -> str:
â”‚               """The expected subject for validation."""
â”‚               pass
â”‚       
â”‚           def __init__(
â”‚               self,
â”‚               client: Client,
â”‚               js: JetStreamContext,
â”‚               logger: Optional[Any] = None,
â”‚               wrapper: Optional["JetStreamWrapper"] = None,
â”‚           ):
â”‚               """Constructor with optional wrapper for dependency access"""
â”‚               self.client = client
â”‚               self.js = js
â”‚               self.logger = logger or self._get_default_logger()
â”‚               self._subscription = None
â”‚       
â”‚               # Access to service dependencies via wrapper
â”‚               self._wrapper = wrapper
â”‚       
â”‚               # Debug initialization
â”‚               self.logger.debug(f"Initialized {self.__class__.__name__}")
â”‚               self.logger.debug(f"JetStream context: {self.js is not None}")
â”‚               self.logger.debug(
â”‚                   f"NATS client connected: {self.client.is_connected if self.client else False}"
â”‚               )
â”‚       
â”‚           def _get_default_logger(self):
â”‚               """Get a default logger if none provided"""
â”‚               import logging
â”‚       
â”‚               return logging.getLogger(self.__class__.__name__)
â”‚       
â”‚           def get_dependency(self, key: DepKeys) -> Any:
â”‚               """Get a service dependency with type-constrained keys"""
â”‚               if not self._wrapper:
â”‚                   raise RuntimeError(
â”‚                       f"Cannot access dependency '{key}' - wrapper not provided. "
â”‚                       "This usually means the subscriber was created manually instead of via JetStreamWrapper."
â”‚                   )
â”‚               return self._wrapper.dependencies.get(key)
â”‚       
â”‚           def dep(self, key: DepKeys) -> Any:
â”‚               """Shorter alias for get_dependency"""
â”‚               return self.get_dependency(key)
â”‚       
â”‚           @abstractmethod
â”‚           async def on_event(
â”‚               self, event: Dict[str, Any], headers: Optional[Dict[str, str]] = None
â”‚           ) -> None:
â”‚               """Process the validated event - access dependencies via self.get_dependency()"""
â”‚               pass
â”‚       
â”‚           async def on_error(self, error: Exception, event: Dict[str, Any]) -> bool:
â”‚               """Handle processing errors with safety net for dependency access"""
â”‚               try:
â”‚                   self.logger.error(f"Error processing {self.subject}: {error}")
â”‚               except Exception as log_error:
â”‚                   # Fallback if even logging fails - avoid print() in production
â”‚                   try:
â”‚                       import sys
â”‚       
â”‚                       sys.stderr.write(
â”‚                           f"Critical error in subscriber {self.__class__.__name__}: {error}\n"
â”‚                       )
â”‚                       sys.stderr.write(f"Additionally, logging failed: {log_error}\n")
â”‚                       sys.stderr.flush()
â”‚                   except Exception:
â”‚                       # Last resort - this should never happen but protects against closed stderr
â”‚                       pass
â”‚               return False  # Default: retry
â”‚       
â”‚           async def listen(self) -> None:
â”‚               """Subscribe and process messages with exponential backoff on failures"""
â”‚       
â”‚               # Consumer config
â”‚               consumer_config = ConsumerConfig(
â”‚                   durable_name=self.durable_name,
â”‚                   deliver_policy=DeliverPolicy.ALL,
â”‚                   ack_policy=AckPolicy.EXPLICIT,
â”‚                   max_deliver=3,
â”‚                   ack_wait=30,
â”‚                   filter_subject=self.subject,
â”‚               )
â”‚       
â”‚               # Create or bind consumer
â”‚               try:
â”‚                   await self.js.consumer_info(self.stream_name, self.durable_name)
â”‚                   self.logger.info(f"Using existing consumer: {self.durable_name}")
â”‚               except:
â”‚                   await self.js.add_consumer(self.stream_name, config=consumer_config)
â”‚                   self.logger.info(f"Created new consumer: {self.durable_name}")
â”‚       
â”‚               # Subscribe
â”‚               try:
â”‚                   self._subscription = await self.js.pull_subscribe(
â”‚                       self.subject, durable=self.durable_name, stream=self.stream_name
â”‚                   )
â”‚       
â”‚                   if self._subscription is None:
â”‚                       raise Exception("Failed to create subscription")
â”‚       
â”‚                   self.logger.info(f"Listening on {self.stream_name}/{self.subject}")
â”‚       
â”‚                   error_count = 0
â”‚                   max_errors = 5
â”‚       
â”‚                   # Process messages with exponential backoff
â”‚                   while True:
â”‚                       try:
â”‚                           messages = await self._subscription.fetch(batch=10, timeout=1)
â”‚                           error_count = 0  # Reset on success
â”‚       
â”‚                           for msg in messages:
â”‚                               await self._process_message(msg)
â”‚       
â”‚                       except asyncio.TimeoutError:
â”‚                           continue  # Normal - no messages
â”‚                       except Exception as e:
â”‚                           error_count += 1
â”‚       
â”‚                           if error_count > max_errors:
â”‚                               self.logger.error("Too many errors, stopping subscriber")
â”‚                               break
â”‚       
â”‚                           # Exponential backoff with jitter
â”‚                           backoff = min(60, 2**error_count)
â”‚                           self.logger.warning(
â”‚                               f"Error #{error_count}, backing off {backoff}s: {e}"
â”‚                           )
â”‚                           await asyncio.sleep(backoff)
â”‚       
â”‚               except Exception as e:
â”‚                   self.logger.error(f"Failed to create subscription: {e}")
â”‚                   raise
â”‚       
â”‚           async def _process_message(self, msg) -> None:
â”‚               """Process a single message with error handling"""
â”‚               try:
â”‚                   # Parse message
â”‚                   try:
â”‚                       data = json.loads(msg.data.decode("utf-8"))
â”‚                   except json.JSONDecodeError as e:
â”‚                       self.logger.error(f"Invalid JSON: {e}")
â”‚                       await msg.ack()
â”‚                       return
â”‚       
â”‚                   # Validate structure
â”‚                   required = ["event_id", "subject", "timestamp", "payload"]
â”‚                   if missing := [f for f in required if f not in data]:
â”‚                       self.logger.error(f"Missing fields: {missing}")
â”‚                       await msg.ack()
â”‚                       return
â”‚       
â”‚                   # Validate event type
â”‚                   if self.subject and data.get("subject") != self.subject:
â”‚                       self.logger.warning(
â”‚                           f"Wrong event type: expected {self.subject}, got {data.get('subject')}"
â”‚                       )
â”‚                       await msg.ack()
â”‚                       return
â”‚       
â”‚                   # Extract headers
â”‚                   headers = {}
â”‚                   if msg.headers:
â”‚                       headers = {
â”‚                           k: v[0] if isinstance(v, list) else v
â”‚                           for k, v in msg.headers.items()
â”‚                       }
â”‚       
â”‚                   # Process event
â”‚                   try:
â”‚                       await self.on_event(data, headers)
â”‚                       await msg.ack()
â”‚                   except Exception as e:
â”‚                       should_ack = await self.on_error(e, data)
â”‚                       if should_ack:
â”‚                           await msg.ack()
â”‚       
â”‚               except Exception as e:
â”‚                   self.logger.critical(f"Fatal error processing message: {e}", exc_info=True)
â”‚                   try:
â”‚                       await msg.ack()  # Prevent poison messages
â”‚                   except:
â”‚                       pass
â”‚       
â”‚           async def stop(self) -> None:
â”‚               """Stop listening"""
â”‚               if self._subscription:
â”‚                   try:
â”‚                       await self._subscription.unsubscribe()
â”‚                   except Exception as e:
â”‚                       self.logger.error(f"Error unsubscribing: {e}")
â”‚                   finally:
â”‚                       self._subscription = None
â”‚       ```
â”‚       
â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   
â”‚   â”‚   # -------------------------------
â”‚   â”‚   # shared/metrics/__init__.py
â”‚   â”‚   # -------------------------------
â”‚   â”‚   
â”‚   â”‚   """Prometheus metrics utilities for microservices."""
â”‚   â”‚   
â”‚   â”‚   from .middleware import (
â”‚   â”‚       PrometheusMiddleware,
â”‚   â”‚       metrics_endpoint,
â”‚   â”‚       http_requests_total,
â”‚   â”‚       http_request_duration_seconds,
â”‚   â”‚       http_requests_in_progress,
â”‚   â”‚   )
â”‚   â”‚   
â”‚   â”‚   __all__ = [
â”‚   â”‚       "PrometheusMiddleware",
â”‚   â”‚       "metrics_endpoint",
â”‚   â”‚       "http_requests_total",
â”‚   â”‚       "http_request_duration_seconds",
â”‚   â”‚       "http_requests_in_progress",
â”‚   â”‚   ]
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ middleware.py
â”‚       
â”‚       ```py
â”‚       # -------------------------------
â”‚       # shared/metrics/middleware.py
â”‚       # -------------------------------
â”‚       
â”‚       """
â”‚       Prometheus metrics middleware for all services.
â”‚       
â”‚       Provides standard HTTP metrics and allows services to register
â”‚       their own domain-specific metrics.
â”‚       """
â”‚       
â”‚       import time
â”‚       import re
â”‚       from typing import Dict, Any, Optional, Callable
â”‚       from fastapi import Request
â”‚       from starlette.middleware.base import BaseHTTPMiddleware
â”‚       from starlette.responses import Response
â”‚       from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
â”‚       
â”‚       # Standard HTTP metrics for all services
â”‚       http_requests_total = Counter(
â”‚           'http_requests_total',
â”‚           'Total HTTP requests',
â”‚           ['service', 'method', 'endpoint', 'status']
â”‚       )
â”‚       
â”‚       http_request_duration_seconds = Histogram(
â”‚           'http_request_duration_seconds',
â”‚           'HTTP request duration in seconds',
â”‚           ['service', 'method', 'endpoint']
â”‚       )
â”‚       
â”‚       http_requests_in_progress = Gauge(
â”‚           'http_requests_in_progress',
â”‚           'HTTP requests in progress',
â”‚           ['service']
â”‚       )
â”‚       
â”‚       
â”‚       class PrometheusMiddleware(BaseHTTPMiddleware):
â”‚           """Prometheus metrics collection middleware."""
â”‚           
â”‚           def __init__(self, app, service_name: str):
â”‚               super().__init__(app)
â”‚               self.service_name = service_name
â”‚           
â”‚           async def dispatch(self, request: Request, call_next):
â”‚               # Skip metrics endpoint to avoid recursion
â”‚               if request.url.path == "/metrics":
â”‚                   return await call_next(request)
â”‚               
â”‚               # Get method and normalize path
â”‚               method = request.method
â”‚               path = self._normalize_path(request.url.path)
â”‚               
â”‚               # Track in-progress requests
â”‚               http_requests_in_progress.labels(service=self.service_name).inc()
â”‚               
â”‚               # Time the request
â”‚               start_time = time.time()
â”‚               
â”‚               try:
â”‚                   response = await call_next(request)
â”‚                   status_code = response.status_code
â”‚                   
â”‚                   # Record success metrics
â”‚                   self._record_metrics(method, path, status_code, start_time)
â”‚                   
â”‚                   return response
â”‚                   
â”‚               except Exception as e:
â”‚                   # Record failure metrics
â”‚                   self._record_metrics(method, path, 500, start_time)
â”‚                   raise
â”‚               finally:
â”‚                   http_requests_in_progress.labels(service=self.service_name).dec()
â”‚           
â”‚           def _record_metrics(self, method: str, path: str, status: int, start_time: float):
â”‚               """Record HTTP metrics."""
â”‚               http_requests_total.labels(
â”‚                   service=self.service_name,
â”‚                   method=method,
â”‚                   endpoint=path,
â”‚                   status=status
â”‚               ).inc()
â”‚               
â”‚               http_request_duration_seconds.labels(
â”‚                   service=self.service_name,
â”‚                   method=method,
â”‚                   endpoint=path
â”‚               ).observe(time.time() - start_time)
â”‚           
â”‚           def _normalize_path(self, path: str) -> str:
â”‚               """Normalize paths to prevent high cardinality."""
â”‚               # Replace UUIDs
â”‚               path = re.sub(
â”‚                   r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}',
â”‚                   '{id}',
â”‚                   path
â”‚               )
â”‚               # Replace numeric IDs
â”‚               path = re.sub(r'/\d+', '/{id}', path)
â”‚               return path
â”‚       
â”‚       
â”‚       async def metrics_endpoint(request: Request) -> Response:
â”‚           """Endpoint to expose Prometheus metrics."""
â”‚           return Response(
â”‚               content=generate_latest(),
â”‚               media_type=CONTENT_TYPE_LATEST
â”‚           )
â”‚       
â”‚       ```
â”‚       
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ idempotency_key_generator.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/utils/idempotency.py
â”‚   â”‚   """Simple idempotency key generator."""
â”‚   â”‚   
â”‚   â”‚   from typing import Union, Optional
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   def generate_idempotency_key(
â”‚   â”‚       system: str,
â”‚   â”‚       operation_type: str, 
â”‚   â”‚       identifier: Union[str, int, UUID],
â”‚   â”‚       extra: Optional[str] = None
â”‚   â”‚   ) -> str:
â”‚   â”‚       """
â”‚   â”‚       Generate idempotency key: SYSTEM_OPERATION_ID[_EXTRA]
â”‚   â”‚       
â”‚   â”‚       Examples:
â”‚   â”‚           generate_idempotency_key("SHOPIFY", "ORDER", "123456") 
â”‚   â”‚           â†’ "SHOPIFY_ORDER_123456"
â”‚   â”‚           
â”‚   â”‚           generate_idempotency_key("STRIPE", "PAYMENT", "pi_abc123")
â”‚   â”‚           â†’ "STRIPE_PAYMENT_pi_abc123"
â”‚   â”‚           
â”‚   â”‚           generate_idempotency_key("SHOPIFY", "ORDER", "123", "TESTSTORE")
â”‚   â”‚           â†’ "SHOPIFY_ORDER_123_TESTSTORE"
â”‚   â”‚       """
â”‚   â”‚       # Normalize inputs
â”‚   â”‚       system = str(system).upper().replace('-', '_').replace('.', '_')
â”‚   â”‚       operation_type = str(operation_type).upper().replace('-', '_').replace('.', '_')
â”‚   â”‚       identifier = str(identifier)
â”‚   â”‚       
â”‚   â”‚       # Build key
â”‚   â”‚       parts = [system, operation_type, identifier]
â”‚   â”‚       
â”‚   â”‚       if extra:
â”‚   â”‚           parts.append(str(extra).upper().replace('-', '_').replace('.', '_'))
â”‚   â”‚       
â”‚   â”‚       return '_'.join(parts)
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â””â”€â”€ logger.py
â”‚       
â”‚       ```py
â”‚       # shared/utils/logger.py
â”‚       import logging
â”‚       import logging.handlers
â”‚       import os
â”‚       import json
â”‚       from datetime import datetime
â”‚       from typing import Dict, Any
â”‚       from pathlib import Path
â”‚       from contextvars import ContextVar
â”‚       
â”‚       
â”‚       # Context variable for request-scoped data
â”‚       request_context: ContextVar[Dict[str, Any]] = ContextVar('request_context', default={})
â”‚       
â”‚       
â”‚       class ServiceLogger:
â”‚           """
â”‚           Service-specific logger that automatically includes service name and request context.
â”‚           """
â”‚           
â”‚           def __init__(self, service_name: str):
â”‚               self.service_name = service_name
â”‚               self._setup_logging()
â”‚               self._logger = logging.getLogger(service_name)
â”‚           
â”‚           def _setup_logging(self):
â”‚               """Configure logging for this service"""
â”‚               env = os.getenv("APP_ENV", "dev").lower()
â”‚               log_level = os.getenv("LOG_LEVEL", "INFO").upper()
â”‚               print(f"Setting up logger for {self.service_name} in {env} environment with level {log_level}")
â”‚               
â”‚               # Create logs directory
â”‚               Path("logs").mkdir(exist_ok=True)
â”‚               
â”‚               # Configure formatters based on environment
â”‚               if env == "prod":
â”‚                   formatter = JsonFormatter(self.service_name)
â”‚               else:
â”‚                   formatter = ConsoleFormatter(self.service_name)
â”‚               
â”‚               # Set up handlers
â”‚               console_handler = logging.StreamHandler()
â”‚               console_handler.setFormatter(formatter)
â”‚               console_handler.setLevel(log_level)
â”‚               
â”‚               # Configure the service logger
â”‚               logger = logging.getLogger(self.service_name)
â”‚               logger.setLevel(log_level)
â”‚               logger.addHandler(console_handler)
â”‚               
â”‚               # Add file handler for production
â”‚               if env == "prod":
â”‚                   file_handler = logging.handlers.RotatingFileHandler(
â”‚                       f"logs/{self.service_name}.log",
â”‚                       maxBytes=10485760,  # 10MB
â”‚                       backupCount=5,
â”‚                       encoding='utf8'
â”‚                   )
â”‚                   file_handler.setFormatter(formatter)
â”‚                   file_handler.setLevel(logging.INFO)
â”‚                   logger.addHandler(file_handler)
â”‚               
â”‚               # Prevent propagation to avoid duplicate logs
â”‚               logger.propagate = False
â”‚           
â”‚           def set_request_context(self, **kwargs):
â”‚               """Set request-scoped context (e.g., request_id, user_id)"""
â”‚               ctx = request_context.get()
â”‚               ctx.update(kwargs)
â”‚               request_context.set(ctx)
â”‚           
â”‚           def clear_request_context(self):
â”‚               """Clear request context"""
â”‚               request_context.set({})
â”‚           
â”‚           def _log(self, level: int, msg: str, *args, **kwargs):
â”‚               """Internal log method that adds context"""
â”‚               # Get request context
â”‚               ctx = request_context.get()
â”‚               
â”‚               # Add context to extra
â”‚               extra = kwargs.get('extra', {})
â”‚               extra.update(ctx)
â”‚               kwargs['extra'] = extra
â”‚               
â”‚               self._logger.log(level, msg, *args, **kwargs)
â”‚           
â”‚           def debug(self, msg: str, *args, **kwargs):
â”‚               self._log(logging.DEBUG, msg, *args, **kwargs)
â”‚           
â”‚           def info(self, msg: str, *args, **kwargs):
â”‚               self._log(logging.INFO, msg, *args, **kwargs)
â”‚           
â”‚           def warning(self, msg: str, *args, **kwargs):
â”‚               self._log(logging.WARNING, msg, *args, **kwargs)
â”‚           
â”‚           def error(self, msg: str, *args, **kwargs):
â”‚               self._log(logging.ERROR, msg, *args, **kwargs)
â”‚           
â”‚           def critical(self, msg: str, *args, **kwargs):
â”‚               self._log(logging.CRITICAL, msg, *args, **kwargs)
â”‚       
â”‚       
â”‚       class ConsoleFormatter(logging.Formatter):
â”‚           """Console formatter that includes service name and request context"""
â”‚           
â”‚           def __init__(self, service_name: str):
â”‚               self.service_name = service_name
â”‚               super().__init__()
â”‚           
â”‚           def format(self, record):
â”‚               # Build context string from extra fields
â”‚               context_parts = []
â”‚               request_id = getattr(record, 'request_id', None)
â”‚               if request_id is not None:
â”‚                   context_parts.append(f"request_id={request_id}")
â”‚               user_id = getattr(record, 'user_id', None)
â”‚               if user_id is not None:
â”‚                   context_parts.append(f"user_id={user_id}")
â”‚               
â”‚               # Add any other extra fields
â”‚               for key in record.__dict__:
â”‚                   if key not in ['name', 'msg', 'args', 'created', 'filename', 'funcName',
â”‚                                 'levelname', 'levelno', 'lineno', 'module', 'msecs',
â”‚                                 'pathname', 'process', 'processName', 'relativeCreated',
â”‚                                 'thread', 'threadName', 'exc_info', 'exc_text', 'stack_info',
â”‚                                 'message', 'getMessage', 'request_id', 'user_id']:
â”‚                       context_parts.append(f"{key}={getattr(record, key)}")
â”‚               
â”‚               # Format: 2024-01-15 10:30:45 - funding-service - INFO - [request_id=123] Processing order
â”‚               timestamp = datetime.fromtimestamp(record.created).strftime('%Y-%m-%d %H:%M:%S')
â”‚               
â”‚               message = f"{timestamp} - {self.service_name} - {record.levelname}"
â”‚               if context_parts:
â”‚                   message += f" - [{' '.join(context_parts)}]"
â”‚               message += f" - {record.getMessage()}"
â”‚               
â”‚               if record.exc_info:
â”‚                   message += '\n' + self.formatException(record.exc_info)
â”‚               
â”‚               return message
â”‚       
â”‚       
â”‚       class JsonFormatter(logging.Formatter):
â”‚           """JSON formatter for production"""
â”‚           
â”‚           def __init__(self, service_name: str):
â”‚               self.service_name = service_name
â”‚               super().__init__()
â”‚           
â”‚           def format(self, record):
â”‚               log_data = {
â”‚                   "timestamp": datetime.utcnow().isoformat(),
â”‚                   "service": self.service_name,
â”‚                   "level": record.levelname,
â”‚                   "message": record.getMessage(),
â”‚                   "environment": os.getenv("APP_ENV", "dev"),
â”‚               }
â”‚               
â”‚               # Add request context from extra
â”‚               request_id = getattr(record, 'request_id', None)
â”‚               if request_id is not None:
â”‚                   log_data['request_id'] = request_id
â”‚               user_id = getattr(record, 'user_id', None)
â”‚               if user_id is not None:
â”‚                   log_data['user_id'] = user_id
â”‚               
â”‚               # Add any other extra fields
â”‚               for key in record.__dict__:
â”‚                   if key not in ['name', 'msg', 'args', 'created', 'filename', 'funcName',
â”‚                                 'levelname', 'levelno', 'lineno', 'module', 'msecs',
â”‚                                 'pathname', 'process', 'processName', 'relativeCreated',
â”‚                                 'thread', 'threadName', 'exc_info', 'exc_text', 'stack_info',
â”‚                                 'message', 'getMessage', 'request_id', 'user_id']:
â”‚                       log_data[key] = getattr(record, key)
â”‚               
â”‚               # Add exception if present
â”‚               if record.exc_info:
â”‚                   log_data['exception'] = self.formatException(record.exc_info)
â”‚               
â”‚               return json.dumps(log_data)
â”‚       
â”‚       
â”‚       # Factory function to create service logger
â”‚       def create_logger(service_name: str) -> ServiceLogger:
â”‚           """
â”‚           Create a logger for a specific service.
â”‚           
â”‚           Args:
â”‚               service_name: Name of the service
â”‚               
â”‚           Returns:
â”‚               ServiceLogger instance
â”‚           """
â”‚           return ServiceLogger(service_name)
â”‚       
â”‚       
â”‚       # ============ USAGE ============
â”‚       
â”‚       """
â”‚       USAGE:
â”‚       
â”‚       1. In your service initialization (main.py or app.py):
â”‚       ```python
â”‚       from shared.utils.logger import create_logger
â”‚       
â”‚       # Create service-specific logger
â”‚       logger = create_logger("funding-service")
â”‚       ```
â”‚       
â”‚       2. Basic logging:
â”‚       ```python
â”‚       logger.info("Service started")
â”‚       logger.error("Connection failed", extra={"host": "localhost", "port": 5432})
â”‚       ```
â”‚       
â”‚       3. In FastAPI middleware or request handler:
â”‚       ```python
â”‚       @app.middleware("http")
â”‚       async def add_request_context(request: Request, call_next):
â”‚           # Set request context for all logs in this request
â”‚           logger.set_request_context(
â”‚               request_id=request.headers.get("X-Request-ID", str(uuid.uuid4())),
â”‚               method=request.method,
â”‚               path=request.url.path
â”‚           )
â”‚           
â”‚           logger.info("Request started")
â”‚           response = await call_next(request)
â”‚           logger.info("Request completed", extra={"status_code": response.status_code})
â”‚           
â”‚           # Clear context after request
â”‚           logger.clear_request_context()
â”‚           return response
â”‚       ```
â”‚       
â”‚       4. In any route or service method:
â”‚       ```python
â”‚       @app.post("/api/orders")
â”‚       async def create_order(order: Order, user_id: str = Depends(get_current_user)):
â”‚           # Add user context
â”‚           logger.set_request_context(user_id=user_id)
â”‚           
â”‚           logger.info("Creating order", extra={"order_id": order.id})
â”‚           # ... business logic ...
â”‚           logger.info("Order created successfully")
â”‚       ```
â”‚       
â”‚       5. Output examples:
â”‚       
â”‚       Development:
â”‚       2024-01-15 10:30:45 - funding-service - INFO - [request_id=abc123 user_id=456] - Creating order
â”‚       
â”‚       Production (JSON):
â”‚       {"timestamp": "2024-01-15T10:30:45.123Z", "service": "funding-service", "level": "INFO", "message": "Creating order", "request_id": "abc123", "user_id": "456", "order_id": "789"}
â”‚       """
â”‚       ```
â”‚       
â””â”€â”€ __init__.py
tests/
â””â”€â”€ __init__.py
.python-version
poetry.lock
pyproject.toml

```toml
# shared/pyproject.toml
[tool.poetry]
name = "shared"
version = "0.1.0"
description = "Shared utilities for GLAM system services"
authors = ["GLAM Team <team@glam.com>"]

[tool.poetry.dependencies]
python = "^3.11"
nats-py = "^2.6.0"
pydantic = "^2.5.0"
python-json-logger = "^2.0.7"
redis = "^5.0.1"
tenacity = "^8.2.3"
alembic = "^1.16.2"
pydantic-settings = "^2.10.1"
asyncio = "^3.4.3"
python-dotenv = "^1.1.1"
uuid7 = "^0.1.0"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
```

README.md

```md
# GLAM Shared Package

Shared utilities and infrastructure components for GLAM microservices platform.

## Features

- **Standardized API Responses**: Consistent response format across all services
- **Database Integration**: SQLAlchemy models, repository pattern, and session management  
- **Event-Driven Architecture**: Publishers, subscribers, and event context management
- **Error Handling**: Comprehensive error hierarchy with automatic mapping
- **Distributed Tracing**: Correlation IDs and trace context propagation
- **Metrics & Monitoring**: Prometheus metrics with automatic HTTP tracking
- **Structured Logging**: Service-aware logging with request context
- **Configuration Management**: YAML configuration with environment overrides
- **NATS Messaging**: JetStream integration with dependency injection

## Quick Start

### Installation

```bash
# Add to your service
cd your-service/
poetry add ../shared

# Or if published to registry
poetry add glam-shared
```

### Basic Service Setup

```python
# src/main.py
from fastapi import FastAPI
from shared.api import setup_middleware, create_health_router
from shared.utils.logger import create_logger

# Create logger and app
logger = create_logger("your-service")
app = FastAPI(title="Your Service")

# Setup essential middleware
setup_middleware(app, service_name="your-service")

# Add health endpoint
app.include_router(create_health_router("your-service"), prefix="/api/v1")
```

### Configuration

```yaml
# config/services/your-service.yml
database:
  host: "localhost"
  port: 5432
  name: "your_service_db"
  user: "postgres"
  password: "password"

nats:
  servers: ["nats://localhost:4222"]
```

## Core Components

### API Module
- **Middleware**: Automatic request/response handling, tracing, metrics
- **Dependencies**: Pagination, request context, correlation IDs
- **Responses**: Standardized success, error, and paginated responses
- **Health Checks**: Built-in health endpoints

### Database Module
- **Base Models**: Async SQLAlchemy with automatic mixins
- **Repository Pattern**: Generic CRUD operations with extensibility
- **Session Management**: Async session handling with proper cleanup
- **Migrations**: Alembic integration utilities

### Event System
- **Publishers**: Domain-specific event publishing with validation
- **Subscribers**: Event processing with dependency injection
- **Context Management**: Correlation and trace propagation
- **Pre-built Events**: Common event types (notifications, billing, etc.)

### Error Handling
- **Error Hierarchy**: Structured domain and infrastructure errors
- **Automatic Mapping**: Convert external exceptions to domain errors
- **Service-Specific**: Ready-to-use errors for common domains
- **API Integration**: Automatic error response formatting

### Messaging (NATS)
- **JetStream Wrapper**: Simplified publisher/subscriber setup
- **Dependency Injection**: Service dependencies for event handlers
- **Stream Management**: Automatic stream creation and configuration
- **Health Monitoring**: Connection health checks

## Available Mixins & Base Classes

### Database Mixins
```python
# Automatic timestamps
class TimestampedMixin:
    created_at: Mapped[datetime]  # Auto-set
    updated_at: Mapped[datetime]  # Auto-updated

# Multi-tenant support  
class MerchantMixin:
    merchant_id: Mapped[UUID]      # Indexed
    merchant_domain: Mapped[str]   # Indexed

# Soft delete support
class SoftDeleteMixin:
    deleted_at: Mapped[datetime | None]
    is_deleted: Mapped[bool]       # Indexed
```

### Repository Base
```python
class Repository(Generic[T]):
    # Available methods (all async)
    async def save(self, instance: T) -> T
    async def find_by_id(self, id: UUID) -> T | None  
    async def find_all(self, **filters) -> list[T]
    async def delete_by_id(self, id: UUID) -> None
    # Override for custom queries
```

### Event Base Classes
```python
class DomainEventPublisher:
    # Set these properties
    domain_stream: Streams = Streams.YOUR_DOMAIN
    service_name_override: str = "your-service"
    
    # Available methods
    async def publish_event(subject: str, payload: dict) -> str
    async def publish_command(command_type: str, payload: dict) -> str

class DomainEventSubscriber:
    # Must implement
    async def on_event(self, event: dict, headers: dict) -> None
    
    # Available methods  
    def get_dependency(self, key: str) -> Any
```

## Error Types

### Common Domain Errors (Ready to Use)
- `NotFoundError` - Resource not found (404)
- `ValidationError` - Invalid input (422)
- `ConflictError` - Resource conflicts (409)
- `UnauthorizedError` - Authentication required (401)
- `ForbiddenError` - Insufficient permissions (403)

### Infrastructure Errors (Ready to Use)
- `DatabaseError` - Database operation failed
- `UpstreamServiceError` - External service failure
- `MessageBusError` - NATS/messaging failure
- `S3Error` - Storage operation failed

### Service-Specific Collections
```python
# Import pre-built error collections
from shared.errors import (
    # Catalog errors
    SyncInProgressError, ItemNotFoundError,
    
    # Profile errors  
    ProfileNotFoundError, ProfileAlreadyExistsError,
    
    # Notification errors
    TemplateNotFoundError, EmailProviderError
)
```

## Event Streams

Each service publishes to designated streams:

```python
# Available streams
Streams.CATALOG      # catalog-service, catalog-connector
Streams.MERCHANT     # merchant-service
Streams.BILLING      # billing-service  
Streams.CREDIT       # credit-service
Streams.PROFILE      # profile-service
Streams.NOTIFICATION # notification-service
Streams.AI_PROCESSING # AI services
Streams.WEBHOOKS     # webhook-service
Streams.SCHEDULER    # scheduler-service
Streams.ANALYTICS    # analytics-service
```

## Configuration

### Environment Variables

All services support these patterns:

```bash
# Database
{SERVICE}_DB_HOST=localhost
{SERVICE}_DB_PORT=5432
{SERVICE}_DB_NAME=service_db
{SERVICE}_DB_USER=postgres
{SERVICE}_DB_PASSWORD=password

# Messaging  
{SERVICE}_NATS_SERVERS=nats://localhost:4222

# Logging
{SERVICE}_LOG_LEVEL=INFO
APP_ENV=dev  # dev, staging, prod
```

### YAML Configuration
```yaml
# config/services/your-service.yml
service:
  name: "your-service"
  port: 8080

database:
  host: "localhost"
  port: 5432
  name: "your_service_db"

nats:
  servers: ["nats://localhost:4222"]
```

## Development

### Testing
```bash
# Run tests
poetry run pytest

# With coverage
poetry run pytest --cov=shared
```

### Code Quality
```bash
# Format code
poetry run black .
poetry run isort .

# Type checking  
poetry run mypy shared/

# Linting
poetry run ruff check shared/
```

### Documentation
```bash
# Generate API docs
poetry run pdoc shared --html
```

## Monitoring & Observability

### Built-in Metrics (Automatic)
- `http_requests_total` - Request counts by service/endpoint/status
- `http_request_duration_seconds` - Request timing histograms  
- `http_requests_in_progress` - Active request gauge

### Health Checks (Automatic)
- `GET /api/v1/health` - Service health with timestamp
- `GET /metrics` - Prometheus metrics endpoint

### Logging Features
- **Structured Logging**: JSON in production, console in development
- **Request Context**: Automatic request_id, correlation_id, trace_id
- **File Rotation**: Automatic log rotation in production
- **Environment-Aware**: Different formats per environment

## Architecture Patterns

The shared package enforces consistent patterns across services:

- **Event-Driven Design**: All inter-service communication through events
- **Repository Pattern**: Standardized data access with extensibility
- **Dependency Injection**: Clean service dependencies via messaging wrapper
- **Domain Errors**: Business logic errors separate from infrastructure
- **Request Tracing**: End-to-end request tracking with correlation IDs
- **Multi-Tenancy**: Built-in merchant isolation and indexing

## Usage Examples

### Complete Service Setup
```python
from shared.api import setup_middleware
from shared.database import create_database_config, DatabaseSessionManager
from shared.messaging import JetStreamWrapper

# Database setup
db_config = create_database_config("YOUR_SERVICE_")
db_manager = DatabaseSessionManager(db_config.database_url)
await db_manager.init()

# Messaging setup  
messaging = JetStreamWrapper(logger)
await messaging.connect(["nats://localhost:4222"])
publisher = messaging.create_publisher(YourPublisher)

# Middleware setup
setup_middleware(app, service_name="your-service")
```

### Event Publishing
```python
# Publish with automatic correlation
await publisher.publish_event(
    subject="evt.item.created",
    payload={"item_id": str(item.id)},
    correlation_id=get_correlation_context(),
    idempotency_key=generate_idempotency_key("INTERNAL", "ITEM_CREATED", item.id)
)
```

### Error Handling
```python
from shared.errors import NotFoundError, ValidationError

# Use specific error types
if not item:
    raise NotFoundError(
        f"Item {item_id} not found",
        resource="item",
        resource_id=str(item_id)
    )
```

## Dependencies

- **FastAPI** - Web framework integration
- **SQLAlchemy** - Async database ORM
- **Pydantic** - Data validation and serialization
- **NATS.py** - JetStream messaging
- **Prometheus Client** - Metrics collection
- **Alembic** - Database migrations
- **PyYAML** - Configuration management

## License

Copyright Â© 2025 GlamYouUp. All rights reserved.
```


================================================================================
Output includes file contents
================================================================================