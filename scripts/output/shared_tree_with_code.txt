================================================================================
Directory Structure: /home/bellabe/glam-app/shared
================================================================================

shared/
shared/
├── api/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/api/__init__.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Unified API response models and utilities for glam-app microservices.
│   │   
│   │   This module provides a single, consistent approach to API responses
│   │   across all services.
│   │   """
│   │   
│   │   from .models import (
│   │       # Core models
│   │       ApiResponse,
│   │       Meta,
│   │       Pagination,
│   │       Links,
│   │       ErrorDetail,
│   │       T,  # Generic type
│   │   )
│   │   
│   │   from .responses import (
│   │       # Response helpers
│   │       create_response,
│   │       success_response,
│   │       error_response,
│   │       paginated_response,
│   │   )
│   │   
│   │   from .dependencies import (
│   │       # FastAPI dependencies
│   │       PaginationDep,
│   │       RequestContextDep,
│   │       CorrelationIdDep,  # Re-exported from correlation
│   │   )
│   │   
│   │   from .middleware import (
│   │       # Middleware
│   │       APIMiddleware,
│   │       setup_middleware,
│   │   )
│   │   
│   │   from .correlation import (
│   │       # Correlation utilities
│   │       get_correlation_id,
│   │       set_correlation_context,
│   │       get_correlation_context,
│   │       add_correlation_header,
│   │       add_correlation_to_event,
│   │       extract_correlation_from_event,
│   │   )
│   │   
│   │   __all__ = [
│   │       # Models
│   │       "ApiResponse",
│   │       "Meta",
│   │       "Pagination",
│   │       "Links",
│   │       "ErrorDetail",
│   │       "T",
│   │       
│   │       # Response helpers
│   │       "create_response",
│   │       "success_response",
│   │       "error_response",
│   │       "paginated_response",
│   │       
│   │       # Dependencies
│   │       "PaginationDep",
│   │       "RequestContextDep",
│   │       "CorrelationIdDep",
│   │       
│   │       # Correlation
│   │       "get_correlation_id",
│   │       "set_correlation_context",
│   │       "get_correlation_context",
│   │       "add_correlation_header",
│   │       "add_correlation_to_event",
│   │       "extract_correlation_from_event",
│   │       
│   │       # Middleware
│   │       "APIMiddleware",
│   │       "setup_middleware",
│   │   ]
│   │   ```
│   │   
│   ├── correlation.py
│   │   
│   │   ```py
│   │   # File: shared/api/correlation.py
│   │   
│   │   """
│   │   Simplified correlation ID support for distributed tracing.
│   │   
│   │   Focuses on the essential functionality needed for request tracing
│   │   across services without over-engineering.
│   │   """
│   │   
│   │   from typing import Optional, Annotated
│   │   from contextvars import ContextVar
│   │   from fastapi import Request, Depends
│   │   import uuid
│   │   
│   │   # Context variable for async operations
│   │   _correlation_context: ContextVar[Optional[str]] = ContextVar(
│   │       "correlation_id",
│   │       default=None
│   │   )
│   │   
│   │   
│   │   def get_correlation_id(request: Request) -> str:
│   │       """
│   │       Get or generate correlation ID for the current request.
│   │       
│   │       Priority:
│   │       1. Request state (set by middleware)
│   │       2. X-Correlation-ID header (from upstream service)  
│   │       3. Generate new one (originating request)
│   │       """
│   │       # Check request state first
│   │       if hasattr(request.state, "correlation_id"):
│   │           return request.state.correlation_id
│   │       
│   │       # Check headers from upstream service
│   │       correlation_id = request.headers.get("X-Correlation-ID")
│   │       if correlation_id:
│   │           return correlation_id
│   │       
│   │       # Generate new one
│   │       return f"corr_{uuid.uuid4().hex[:12]}"
│   │   
│   │   
│   │   # FastAPI dependency
│   │   CorrelationIdDep = Annotated[str, Depends(get_correlation_id)]
│   │   
│   │   
│   │   def set_correlation_context(correlation_id: str) -> None:
│   │       """Set correlation ID in async context."""
│   │       _correlation_context.set(correlation_id)
│   │   
│   │   
│   │   def get_correlation_context() -> Optional[str]:
│   │       """Get correlation ID from async context."""
│   │       return _correlation_context.get()
│   │   
│   │   
│   │   # Essential integrations only
│   │   
│   │   def add_correlation_header(headers: dict) -> dict:
│   │       """
│   │       Add correlation ID to outgoing HTTP headers.
│   │       
│   │       Usage:
│   │           headers = add_correlation_header({"Content-Type": "application/json"})
│   │           response = await client.get(url, headers=headers)
│   │       """
│   │       correlation_id = get_correlation_context()
│   │       if correlation_id:
│   │           headers["X-Correlation-ID"] = correlation_id
│   │       return headers
│   │   
│   │   
│   │   def add_correlation_to_event(event_data: dict) -> dict:
│   │       """
│   │       Add correlation ID to message bus events.
│   │       
│   │       Usage:
│   │           event_data = {"event_type": "ORDER_CREATED", "data": {...}}
│   │           event_with_correlation = add_correlation_to_event(event_data)
│   │       """
│   │       correlation_id = get_correlation_context()
│   │       if correlation_id:
│   │           if "metadata" not in event_data:
│   │               event_data["metadata"] = {}
│   │           event_data["metadata"]["correlation_id"] = correlation_id
│   │       return event_data
│   │   
│   │   
│   │   def extract_correlation_from_event(event_data: dict) -> Optional[str]:
│   │       """Extract correlation ID from event data."""
│   │       return event_data.get("metadata", {}).get("correlation_id")
│   │   ```
│   │   
│   ├── dependencies.py
│   │   
│   │   ```py
│   │   # File: shared/api/dependencies.py
│   │   
│   │   """
│   │   FastAPI dependencies for standardized API behavior.
│   │   
│   │   Simplified to focus on commonly used dependencies.
│   │   """
│   │   
│   │   from typing import Annotated
│   │   from fastapi import Query, Request, Depends
│   │   from pydantic import BaseModel, Field
│   │   from .correlation import get_correlation_id
│   │   
│   │   
│   │   class PaginationParams(BaseModel):
│   │       """Standard pagination parameters."""
│   │       
│   │       page: int = Field(default=1, ge=1)
│   │       limit: int = Field(default=50, ge=1, le=1000)
│   │       
│   │       @property
│   │       def offset(self) -> int:
│   │           """Calculate offset for database queries."""
│   │           return (self.page - 1) * self.limit
│   │   
│   │   
│   │   def get_pagination_params(
│   │       page: int = Query(1, ge=1, description="Page number"),
│   │       limit: int = Query(50, ge=1, le=1000, description="Items per page")
│   │   ) -> PaginationParams:
│   │       """
│   │       FastAPI dependency for pagination parameters.
│   │       
│   │       Usage:
│   │           @app.get("/items")
│   │           async def list_items(pagination: PaginationDep):
│   │               items = await db.query(offset=pagination.offset, limit=pagination.limit)
│   │       """
│   │       return PaginationParams(page=page, limit=limit)
│   │   
│   │   
│   │   def get_request_id(request: Request) -> str:
│   │       """
│   │       Get request ID from middleware-set state.
│   │       
│   │       Raises error if middleware hasn't run, ensuring proper initialization.
│   │       """
│   │       if not hasattr(request.state, "request_id"):
│   │           raise RuntimeError(
│   │               "Request ID not found. Ensure APIMiddleware is properly configured."
│   │           )
│   │       return request.state.request_id
│   │   
│   │   
│   │   # Type aliases for clean dependency injection
│   │   RequestIdDep = Annotated[str, Depends(get_request_id)]
│   │   PaginationDep = Annotated[PaginationParams, Depends(get_pagination_params)]
│   │   CorrelationIdDep = Annotated[str, Depends(get_correlation_id)]  # Re-export for convenience
│   │   
│   │   
│   │   # Optional: Simplified request context for logging
│   │   class RequestContext(BaseModel):
│   │       """Essential request context for logging/auditing."""
│   │       
│   │       request_id: str
│   │       correlation_id: str
│   │       method: str
│   │       path: str
│   │       
│   │       @classmethod
│   │       def from_request(cls, request: Request) -> "RequestContext":
│   │           """Create context from FastAPI request."""
│   │           return cls(
│   │               request_id=get_request_id(request),
│   │               correlation_id=get_correlation_id(request),
│   │               method=request.method,
│   │               path=str(request.url.path)
│   │           )
│   │   
│   │   
│   │   def get_request_context(request: Request) -> RequestContext:
│   │       """Get essential request context."""
│   │       return RequestContext.from_request(request)
│   │   
│   │   
│   │   RequestContextDep = Annotated[RequestContext, Depends(get_request_context)]
│   │   
│   │   def get_client_ip(request: Request) -> str:
│   │       """
│   │       Extract client IP address.
│   │       Only add if needed for rate limiting or security.
│   │       """
│   │       forwarded_for = request.headers.get("X-Forwarded-For")
│   │       if forwarded_for:
│   │           return forwarded_for.split(",")[0].strip()
│   │       return request.client.host if request.client else "unknown"
│   │   
│   │   
│   │   ClientIpDep = Annotated[str, Depends(get_client_ip)]
│   │   ```
│   │   
│   ├── middleware.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/api/middleware.py
│   │   # -------------------------------
│   │   
│   │   """Simplified API middleware."""
│   │   
│   │   import time
│   │   import uuid
│   │   import logging
│   │   from typing import Callable
│   │   
│   │   from fastapi import Request, Response
│   │   from fastapi import FastAPI
│   │   from fastapi.responses import JSONResponse
│   │   from starlette.middleware.base import BaseHTTPMiddleware
│   │   from fastapi.exceptions import RequestValidationError, HTTPException
│   │   
│   │   from ..errors import GlamBaseError
│   │   from ..metrics import PrometheusMiddleware, metrics_endpoint
│   │   
│   │   from .models import ErrorDetail
│   │   from .responses import error_response
│   │   from .correlation import get_correlation_id, set_correlation_context
│   │   
│   │   logger = logging.getLogger(__name__)
│   │   
│   │   
│   │   class APIMiddleware(BaseHTTPMiddleware):
│   │       """Unified middleware for request/response handling."""
│   │       
│   │       def __init__(self, app, *, service_name: str = "glam-service"):
│   │           super().__init__(app)
│   │           self.service_name = service_name
│   │       
│   │       async def dispatch(self, request: Request, call_next: Callable) -> Response:
│   │           # Generate IDs
│   │           request_id = request.headers.get("X-Request-ID", f"req_{uuid.uuid4().hex[:12]}")
│   │           
│   │           # Get correlation ID (this will check headers and generate if needed)
│   │           correlation_id = get_correlation_id(request)
│   │           
│   │           # Store in request state for easy access in the request
│   │           request.state.request_id = request_id
│   │           request.state.correlation_id = correlation_id
│   │           
│   │           # IMPORTANT: Set correlation context for async operations
│   │           # This makes correlation_id available throughout the request lifecycle
│   │           set_correlation_context(correlation_id)
│   │           
│   │           # Track timing
│   │           start_time = time.perf_counter()
│   │           
│   │           try:
│   │               response = await call_next(request)
│   │               
│   │               # Add standard headers
│   │               response.headers["X-Request-ID"] = request_id
│   │               response.headers["X-Correlation-ID"] = correlation_id
│   │               response.headers["X-Service-Name"] = self.service_name
│   │               
│   │               return response
│   │               
│   │           except Exception as exc:
│   │               # Convert to standard error response
│   │               error_resp = self._handle_exception(exc, request_id, correlation_id)
│   │               
│   │               # Determine status code
│   │               status_code = 500
│   │               if isinstance(exc, GlamBaseError):
│   │                   status_code = exc.status
│   │               elif isinstance(exc, HTTPException):
│   │                   status_code = exc.status_code
│   │               elif isinstance(exc, RequestValidationError):
│   │                   status_code = 422
│   │               
│   │               # Log error
│   │               duration_ms = (time.perf_counter() - start_time) * 1000
│   │               logger.error(
│   │                   "Request failed",
│   │                   extra={
│   │                       "request_id": request_id,
│   │                       "correlation_id": correlation_id,
│   │                       "method": request.method,
│   │                       "path": request.url.path,
│   │                       "status": status_code,
│   │                       "duration_ms": round(duration_ms, 2),
│   │                       "error_code": error_resp.error.code if error_resp.error else "UNKNOWN",
│   │                       "service": self.service_name
│   │                   }
│   │               )
│   │               
│   │               response = JSONResponse(
│   │                   content=error_resp.model_dump(mode="json", exclude_none=True),
│   │                   status_code=status_code
│   │               )
│   │               
│   │               # Add standard headers
│   │               response.headers["X-Request-ID"] = request_id
│   │               response.headers["X-Correlation-ID"] = correlation_id
│   │               response.headers["X-Service-Name"] = self.service_name
│   │               
│   │               return response
│   │       
│   │       def _handle_exception(self, exc: Exception, request_id: str, correlation_id: str):
│   │           """Convert exception to error response."""
│   │           
│   │           if isinstance(exc, GlamBaseError):
│   │               return error_response(
│   │                   code=exc.code,
│   │                   message=exc.message,
│   │                   details=exc.details,
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │           
│   │           elif isinstance(exc, RequestValidationError):
│   │               validation_errors = []
│   │               for error in exc.errors():
│   │                   field_path = ".".join(str(loc) for loc in error["loc"])
│   │                   validation_errors.append({
│   │                       "field": field_path,
│   │                       "message": error["msg"],
│   │                       "type": error["type"]
│   │                   })
│   │               
│   │               return error_response(
│   │                   code="VALIDATION_ERROR",
│   │                   message="Request validation failed",
│   │                   details={"validation_errors": validation_errors},
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │           
│   │           elif isinstance(exc, HTTPException):
│   │               return error_response(
│   │                   code=f"HTTP_{exc.status_code}",
│   │                   message=exc.detail,
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │           
│   │           else:
│   │               logger.exception(
│   │                   "Unhandled exception",
│   │                   extra={
│   │                       "request_id": request_id,
│   │                       "correlation_id": correlation_id,
│   │                       "error_type": type(exc).__name__
│   │                   }
│   │               )
│   │               
│   │               return error_response(
│   │                   code="INTERNAL_ERROR",
│   │                   message="An unexpected error occurred",
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id
│   │               )
│   │   
│   │   
│   │   def setup_middleware(
│   │       app: FastAPI,
│   │       *,
│   │       service_name: str,
│   │       enable_metrics: bool = True,
│   │       metrics_path: str = "/metrics",
│   │   ):
│   │       """
│   │       Set up all standard middleware for a service.
│   │       
│   │       This sets up middleware in the correct order:
│   │       1. Prometheus metrics (if enabled) - captures all requests
│   │       2. API middleware - handles responses and errors
│   │       
│   │       Args:
│   │           app: FastAPI application
│   │           service_name: Name of the service
│   │           enable_metrics: Whether to enable Prometheus metrics
│   │           metrics_path: Path for metrics endpoint
│   │           debug: Whether to include error details in responses
│   │       """
│   │       # Add Prometheus middleware FIRST (captures all requests)
│   │       if enable_metrics:
│   │           app.add_middleware(PrometheusMiddleware, service_name=service_name)
│   │           
│   │           # Add metrics endpoint
│   │           app.add_api_route(
│   │               metrics_path,
│   │               metrics_endpoint,
│   │               methods=["GET"],
│   │               include_in_schema=False,
│   │               tags=["monitoring"]
│   │           )
│   │       
│   │       # Add API middleware for standardized responses
│   │       app.add_middleware(APIMiddleware, service_name=service_name)
│   │   ```
│   │   
│   ├── models.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/api/models.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Unified API response models for glam-app services.
│   │   Consolidates all response structures into a single, consistent pattern.
│   │   """
│   │   
│   │   from typing import TypeVar, Generic, Optional, Any, Dict, List
│   │   from datetime import datetime, timezone
│   │   from pydantic import BaseModel, Field, ConfigDict
│   │   import uuid
│   │   
│   │   # Generic type for response data
│   │   T = TypeVar("T")
│   │   
│   │   
│   │   class Meta(BaseModel):
│   │       """Metadata included in all responses."""
│   │       request_id: str = Field(description="Unique request identifier")
│   │       correlation_id: Optional[str] = Field(None, description="Distributed tracing ID")
│   │       timestamp: datetime = Field(
│   │           default_factory=lambda: datetime.now(timezone.utc),
│   │           description="Response timestamp in UTC"
│   │       )
│   │       
│   │       model_config = ConfigDict(
│   │           json_encoders={datetime: lambda v: v.isoformat()}
│   │       )
│   │   
│   │   
│   │   class Pagination(BaseModel):
│   │       """Pagination metadata for list responses."""
│   │       page: int = Field(ge=1)
│   │       limit: int = Field(ge=1, le=1000)
│   │       total: int = Field(ge=0)
│   │       pages: int = Field(ge=0)
│   │       has_next: bool
│   │       has_previous: bool
│   │       
│   │       @classmethod
│   │       def create(cls, page: int, limit: int, total: int) -> "Pagination":
│   │           """Create pagination from parameters."""
│   │           pages = (total + limit - 1) // limit if total > 0 else 0
│   │           return cls(
│   │               page=page,
│   │               limit=limit,
│   │               total=total,
│   │               pages=pages,
│   │               has_next=page < pages,
│   │               has_previous=page > 1
│   │           )
│   │   
│   │   
│   │   class Links(BaseModel):
│   │       """HATEOAS links for resource navigation."""
│   │       self: str
│   │       next: Optional[str] = None
│   │       previous: Optional[str] = None
│   │       first: Optional[str] = None
│   │       last: Optional[str] = None
│   │       
│   │       @classmethod
│   │       def create_paginated(
│   │           cls, 
│   │           base_url: str, 
│   │           page: int, 
│   │           limit: int, 
│   │           pages: int,
│   │           **query_params
│   │       ) -> "Links":
│   │           """Create pagination links."""
│   │           def build_url(page_num: int) -> str:
│   │               params = {**query_params, "page": page_num, "limit": limit}
│   │               query = "&".join(f"{k}={v}" for k, v in params.items())
│   │               return f"{base_url}?{query}"
│   │           
│   │           return cls(
│   │               self=build_url(page),
│   │               next=build_url(page + 1) if page < pages else None,
│   │               previous=build_url(page - 1) if page > 1 else None,
│   │               first=build_url(1) if pages > 0 else None,
│   │               last=build_url(pages) if pages > 0 else None
│   │           )
│   │   
│   │   
│   │   class ErrorDetail(BaseModel):
│   │       """Error information."""
│   │       code: str
│   │       message: str
│   │       details: Optional[Dict[str, Any]] = None
│   │   
│   │   
│   │   class ApiResponse(BaseModel, Generic[T]):
│   │       """
│   │       Unified API response structure.
│   │       Used for both success and error responses.
│   │       """
│   │       # For success responses
│   │       data: Optional[T] = None
│   │       
│   │       # For error responses
│   │       error: Optional[ErrorDetail] = None
│   │       
│   │       # Always present
│   │       meta: Meta
│   │       
│   │       # Optional for paginated responses
│   │       pagination: Optional[Pagination] = None
│   │       links: Optional[Links] = None
│   │       
│   │       model_config = ConfigDict(
│   │           json_encoders={datetime: lambda v: v.isoformat()}
│   │       )
│   │   ```
│   │   
│   └── responses.py
│       
│       ```py
│       # -------------------------------
│       # shared/api/responses.py
│       # -------------------------------
│       
│       """Response helper functions."""
│       
│       from typing import Optional, Dict, Any, List, Tuple
│       import uuid
│       from .models import ApiResponse, Meta, ErrorDetail, Pagination, Links, T
│       
│       
│       def create_response(
│           data: Optional[T] = None,
│           error: Optional[ErrorDetail] = None,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None,
│           pagination: Optional[Pagination] = None,
│           links: Optional[Links] = None
│       ) -> ApiResponse[T]:
│           """Create a unified API response."""
│           if request_id is None:
│               request_id = f"req_{uuid.uuid4().hex[:12]}"
│           
│           meta = Meta(request_id=request_id, correlation_id=correlation_id)
│           
│           return ApiResponse(
│               data=data,
│               error=error,
│               meta=meta,
│               pagination=pagination,
│               links=links
│           )
│       
│       
│       def success_response(
│           data: T,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None,
│           links: Optional[Links] = None
│       ) -> ApiResponse[T]:
│           """Create a success response."""
│           return create_response(
│               data=data,
│               request_id=request_id,
│               correlation_id=correlation_id,
│               links=links
│           )
│       
│       
│       def error_response(
│           code: str,
│           message: str,
│           details: Optional[Dict[str, Any]] = None,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None
│       ) -> ApiResponse[None]:
│           """Create an error response."""
│           error = ErrorDetail(code=code, message=message, details=details)
│           return create_response(
│               error=error,
│               request_id=request_id,
│               correlation_id=correlation_id
│           )
│       
│       
│       def paginated_response(
│           data: List[T],
│           page: int,
│           limit: int,
│           total: int,
│           base_url: str,
│           request_id: Optional[str] = None,
│           correlation_id: Optional[str] = None,
│           **query_params
│       ) -> ApiResponse[List[T]]:
│           """Create a paginated response."""
│           pagination = Pagination.create(page, limit, total)
│           links = Links.create_paginated(base_url, page, limit, pagination.pages, **query_params)
│           
│           return create_response(
│               data=data,
│               request_id=request_id,
│               correlation_id=correlation_id,
│               pagination=pagination,
│               links=links
│           )
│       ```
│       
├── database/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   # glam-app/shared/database/__init__.py
│   │   """
│   │   Shared database utilities for GLAM microservices.
│   │   
│   │   This package provides:
│   │   - Base SQLAlchemy models and mixins
│   │   - Async session management
│   │   - Generic repository pattern
│   │   - FastAPI dependencies
│   │   - Alembic migration utilities
│   │   - Database configuration
│   │   """
│   │   
│   │   from .base import Base, TimestampedMixin, SoftDeleteMixin
│   │   from .session import DatabaseSessionManager
│   │   from .repository import Repository
│   │   from .dependencies import (
│   │       DBSessionDep,
│   │       get_db_session,
│   │       set_database_manager,
│   │       get_database_manager,
│   │       get_database_health,
│   │   )
│   │   from .config import DatabaseConfig, TestDatabaseConfig, create_database_config
│   │   from .migrations import MigrationManager, create_alembic_env_template
│   │   
│   │   __all__ = [
│   │       # Base classes
│   │       "Base",
│   │       "TimestampedMixin",
│   │       "SoftDeleteMixin",
│   │       
│   │       # Session management
│   │       "DatabaseSessionManager",
│   │       
│   │       # Repository pattern
│   │       "Repository",
│   │       
│   │       # FastAPI dependencies
│   │       "DBSessionDep",
│   │       "get_db_session",
│   │       "set_database_manager",
│   │       "get_database_manager",
│   │       "get_database_health",
│   │       
│   │       # Configuration
│   │       "DatabaseConfig",
│   │       "TestDatabaseConfig",
│   │       "create_database_config",
│   │       
│   │       # Migrations
│   │       "MigrationManager",
│   │       "create_alembic_env_template",
│   │   ]
│   │   ```
│   │   
│   ├── base.py
│   │   
│   │   ```py
│   │   
│   │   # glam-app/shared/database/base.py
│   │   from sqlalchemy.orm import DeclarativeBase, Mapped, mapped_column
│   │   from sqlalchemy.ext.asyncio import AsyncAttrs
│   │   from sqlalchemy import DateTime
│   │   from datetime import datetime, timezone
│   │   
│   │   
│   │   
│   │   class Base(AsyncAttrs, DeclarativeBase):
│   │       """Base class for all database models across microservices"""
│   │       pass
│   │   
│   │   
│   │   class TimestampedMixin:
│   │       """Mixin to add created_at and updated_at to any model"""
│   │       created_at: Mapped[datetime] = mapped_column(
│   │           DateTime(timezone=True),
│   │           default=lambda: datetime.now(timezone.utc),
│   │           nullable=False
│   │       )
│   │       updated_at: Mapped[datetime] = mapped_column(
│   │           DateTime(timezone=True),
│   │           default=lambda: datetime.now(timezone.utc),
│   │           onupdate=lambda: datetime.now(timezone.utc),
│   │           nullable=False
│   │       )
│   │   
│   │   
│   │   class SoftDeleteMixin:
│   │       """Mixin to add soft delete functionality"""
│   │       deleted_at: Mapped[datetime | None] = mapped_column(
│   │           DateTime(timezone=True),
│   │           default=None)
│   │       is_deleted: Mapped[bool] = mapped_column(default=False, index=True)
│   │   ```
│   │   
│   ├── config.py
│   │   
│   │   ```py
│   │   # glam-app/shared/database/config.py
│   │   from pydantic_settings import BaseSettings, SettingsConfigDict
│   │   from pydantic import Field
│   │   from typing import Optional, Dict, Any
│   │   import os
│   │   
│   │   
│   │   class DatabaseConfig(BaseSettings):
│   │       """
│   │       Base database configuration for microservices.
│   │       Automatically handles Docker port mapping.
│   │       
│   │       When running locally against Docker:
│   │       - DB_PORT_EXTERNAL is used if DB_HOST is localhost
│   │       - DB_PORT is used when running inside Docker
│   │       """
│   │       
│   │       # Connection parameters
│   │       DB_HOST: str = Field(..., description="Database host")
│   │       DB_PORT: Optional[int] = Field(default=None, description="Database port")
│   │       DB_PORT_EXTERNAL: Optional[int] = Field(default=None, description="External port for Docker")
│   │       DB_NAME: str = Field(..., description="Database name")
│   │       DB_USER: str = Field(..., description="Database user")
│   │       DB_PASSWORD: str = Field(..., description="Database password")
│   │       
│   │       # Optional schema for logical separation
│   │       DB_SCHEMA: Optional[str] = Field(default=None, description="Database schema")
│   │       
│   │       # Connection pool settings
│   │       DB_POOL_SIZE: int = Field(default=5, description="Connection pool size")
│   │       DB_MAX_OVERFLOW: int = Field(default=10, description="Max overflow connections")
│   │       DB_POOL_PRE_PING: bool = Field(default=True, description="Pre-ping connections")
│   │       DB_POOL_RECYCLE: int = Field(default=3600, description="Recycle connections after seconds")
│   │       
│   │       # SQLAlchemy settings
│   │       DB_ECHO: bool = Field(default=False, description="Echo SQL statements")
│   │       
│   │       # Async driver
│   │       DB_ASYNC_DRIVER: str = Field(default="asyncpg", description="Async database driver")
│   │       
│   │       model_config = SettingsConfigDict(
│   │           env_file=".env",
│   │           env_file_encoding="utf-8",
│   │           case_sensitive=True,
│   │       )
│   │       
│   │       def model_post_init(self, __context):
│   │           """Post-initialization to set the correct port"""
│   │           # If DB_PORT is not explicitly set, determine it intelligently
│   │           if self.DB_PORT is None:
│   │               if self.DB_HOST in ['localhost', '127.0.0.1', 'host.docker.internal']:
│   │                   # Connecting from host to Docker container
│   │                   self.DB_PORT = self.DB_PORT_EXTERNAL or 5432
│   │               else:
│   │                   # Connecting within Docker network or to remote host
│   │                   self.DB_PORT = 5432
│   │       
│   │       @property
│   │       def database_url(self) -> str:
│   │           """Construct the async database URL"""
│   │           return (
│   │               f"postgresql+{self.DB_ASYNC_DRIVER}://"
│   │               f"{self.DB_USER}:{self.DB_PASSWORD}@"
│   │               f"{self.DB_HOST}:{self.DB_PORT}/{self.DB_NAME}"
│   │           )
│   │       
│   │       @property
│   │       def sync_database_url(self) -> str:
│   │           """Construct sync database URL (for Alembic)"""
│   │           return (
│   │               f"postgresql://"
│   │               f"{self.DB_USER}:{self.DB_PASSWORD}@"
│   │               f"{self.DB_HOST}:{self.DB_PORT}/{self.DB_NAME}"
│   │           )
│   │       
│   │       @property
│   │       def display_url(self) -> str:
│   │           """Get a display-safe URL (password hidden)"""
│   │           return (
│   │               f"postgresql+{self.DB_ASYNC_DRIVER}://"
│   │               f"{self.DB_USER}:***@"
│   │               f"{self.DB_HOST}:{self.DB_PORT}/{self.DB_NAME}"
│   │           )
│   │       
│   │       def get_engine_kwargs(self) -> Dict[str, Any]:
│   │           """Get kwargs for create_async_engine"""
│   │           return {
│   │               "echo": self.DB_ECHO,
│   │               "pool_size": self.DB_POOL_SIZE,
│   │               "max_overflow": self.DB_MAX_OVERFLOW,
│   │               "pool_pre_ping": self.DB_POOL_PRE_PING,
│   │               "pool_recycle": self.DB_POOL_RECYCLE,
│   │           }
│   │   
│   │   
│   │   def create_database_config(prefix: str = "") -> DatabaseConfig:
│   │       """
│   │       Factory function to create DatabaseConfig with custom prefix.
│   │       
│   │       Args:
│   │           prefix: Environment variable prefix (e.g., "NOTIFICATION_")
│   │       
│   │       Returns:
│   │           DatabaseConfig instance with prefixed env vars
│   │       """
│   │       class PrefixedDatabaseConfig(DatabaseConfig):
│   │           model_config = SettingsConfigDict(
│   │               env_file=".env",
│   │               env_file_encoding="utf-8",
│   │               case_sensitive=True,
│   │               env_prefix=prefix,
│   │           )
│   │       
│   │       return PrefixedDatabaseConfig() # type: ignore
│   │   
│   │   
│   │   class TestDatabaseConfig(DatabaseConfig):
│   │       """Test database configuration"""
│   │       
│   │       DB_ECHO: bool = True
│   │       
│   │       class Config:
│   │           env_file = ".env.test"
│   │   ```
│   │   
│   ├── dependencies.py
│   │   
│   │   ```py
│   │   # glam-app/shared/database/dependencies.py
│   │   from typing import Annotated, AsyncGenerator
│   │   from fastapi import Depends
│   │   from sqlalchemy.ext.asyncio import AsyncSession
│   │   from .session import DatabaseSessionManager
│   │   
│   │   # Global database manager instance - each service will set this
│   │   from typing import Optional
│   │   
│   │   _db_manager: Optional[DatabaseSessionManager] = None
│   │   
│   │   
│   │   def set_database_manager(manager: DatabaseSessionManager):
│   │       """Set the global database manager for the service"""
│   │       global _db_manager
│   │       _db_manager = manager
│   │   
│   │   
│   │   def get_database_manager() -> DatabaseSessionManager:
│   │       """Get the current database manager"""
│   │       if _db_manager is None:
│   │           raise RuntimeError(
│   │               "Database manager not initialized. "
│   │               "Call set_database_manager() during app startup."
│   │           )
│   │       return _db_manager
│   │   
│   │   
│   │   async def get_db_session() -> AsyncGenerator[AsyncSession, None]:
│   │       """FastAPI dependency to get a database session"""
│   │       manager = get_database_manager()
│   │       async with manager.session() as session:
│   │           yield session
│   │           
│   │   async def get_database_health() -> bool:
│   │       """Check if the database is healthy"""
│   │       manager = get_database_manager()
│   │       try:
│   │           async with manager.session() as session:
│   │               # Perform a simple query to check connectivity
│   │               from sqlalchemy.sql import text
│   │               await session.execute(text("SELECT 1"))
│   │           return True
│   │       except Exception as e:
│   │           # Log the error or handle it as needed
│   │           print(f"Database health check failed: {e}")
│   │           return False
│   │   
│   │   
│   │   # Type alias for dependency injection
│   │   DBSessionDep = Annotated[AsyncSession, Depends(get_db_session)]
│   │   ```
│   │   
│   ├── migrations.py
│   │   
│   │   ```py
│   │   # glam-app/shared/database/migrations.py
│   │   import os
│   │   from pathlib import Path
│   │   from alembic import command
│   │   from alembic.config import Config
│   │   from sqlalchemy import text
│   │   from sqlalchemy.ext.asyncio import AsyncEngine
│   │   import logging
│   │   
│   │   logger = logging.getLogger(__name__)
│   │   
│   │   
│   │   class MigrationManager:
│   │       """Manages Alembic migrations for a microservice"""
│   │       
│   │       def __init__(
│   │           self,
│   │           service_name: str,
│   │           alembic_ini_path: str,
│   │           migrations_path: str,
│   │           database_url: str
│   │       ):
│   │           self.service_name = service_name
│   │           self.alembic_ini_path = Path(alembic_ini_path)
│   │           self.migrations_path = Path(migrations_path)
│   │           self.database_url = database_url
│   │           
│   │           # Verify paths exist
│   │           if not self.alembic_ini_path.exists():
│   │               raise FileNotFoundError(f"Alembic config not found: {alembic_ini_path}")
│   │           
│   │           # Create migrations directory if it doesn't exist
│   │           self.migrations_path.mkdir(parents=True, exist_ok=True)
│   │       
│   │       def get_alembic_config(self) -> Config:
│   │           """Get Alembic configuration"""
│   │           config = Config(str(self.alembic_ini_path))
│   │           config.set_main_option("sqlalchemy.url", self.database_url)
│   │           config.set_main_option("script_location", str(self.migrations_path))
│   │           return config
│   │       
│   │       def init_alembic(self):
│   │           """Initialize Alembic for the service (run once)"""
│   │           config = self.get_alembic_config()
│   │           command.init(config, str(self.migrations_path))
│   │           logger.info(f"Initialized Alembic for {self.service_name}")
│   │       
│   │       def create_migration(self, message: str):
│   │           """Create a new migration"""
│   │           config = self.get_alembic_config()
│   │           command.revision(config, message=message, autogenerate=True)
│   │           logger.info(f"Created migration: {message}")
│   │       
│   │       def upgrade(self, revision: str = "head"):
│   │           """Apply migrations up to a specific revision"""
│   │           config = self.get_alembic_config()
│   │           command.upgrade(config, revision)
│   │           logger.info(f"Upgraded database to {revision}")
│   │       
│   │       def downgrade(self, revision: str):
│   │           """Downgrade to a specific revision"""
│   │           config = self.get_alembic_config()
│   │           command.downgrade(config, revision)
│   │           logger.info(f"Downgraded database to {revision}")
│   │       
│   │       def get_current_revision(self) -> str:
│   │           """Get the current migration revision"""
│   │           config = self.get_alembic_config()
│   │           # This would require more implementation
│   │           return "Not implemented"
│   │       
│   │       async def ensure_schema_exists(self, engine: AsyncEngine, schema_name: str):
│   │           """Ensure a database schema exists (PostgreSQL specific)"""
│   │           async with engine.connect() as conn:
│   │               await conn.execute(
│   │                   text(f"CREATE SCHEMA IF NOT EXISTS {schema_name}")
│   │               )
│   │               await conn.commit()
│   │           logger.info(f"Ensured schema exists: {schema_name}")
│   │   
│   │   
│   │   def create_alembic_env_template(service_name: str, base_module: str) -> str:
│   │       """Generate env.py template for a service"""
│   │       return f'''"""Alembic environment script for {service_name}"""
│   │   from logging.config import fileConfig
│   │   from sqlalchemy import engine_from_config, pool
│   │   from alembic import context
│   │   
│   │   # Import your service's Base metadata
│   │   from {base_module} import Base
│   │   
│   │   config = context.config
│   │   
│   │   if config.config_file_name is not None:
│   │       fileConfig(config.config_file_name)
│   │   
│   │   target_metadata = Base.metadata
│   │   
│   │   
│   │   def run_migrations_offline() -> None:
│   │       """Run migrations in 'offline' mode."""
│   │       url = config.get_main_option("sqlalchemy.url")
│   │       context.configure(
│   │           url=url,
│   │           target_metadata=target_metadata,
│   │           literal_binds=True,
│   │           dialect_opts={{"paramstyle": "named"}},
│   │       )
│   │   
│   │       with context.begin_transaction():
│   │           context.run_migrations()
│   │   
│   │   
│   │   def run_migrations_online() -> None:
│   │       """Run migrations in 'online' mode."""
│   │       connectable = engine_from_config(
│   │           config.get_section(config.config_ini_section),
│   │           prefix="sqlalchemy.",
│   │           poolclass=pool.NullPool,
│   │       )
│   │   
│   │       with connectable.connect() as connection:
│   │           context.configure(
│   │               connection=connection,
│   │               target_metadata=target_metadata
│   │           )
│   │   
│   │           with context.begin_transaction():
│   │               context.run_migrations()
│   │   
│   │   
│   │   if context.is_offline_mode():
│   │       run_migrations_offline()
│   │   else:
│   │       run_migrations_online()
│   │   '''
│   │   ```
│   │   
│   ├── repository.py
│   │   
│   │   ```py
│   │   # glam-app/shared/database/repository.py
│   │   from typing import TypeVar, Generic, Type, AsyncIterator
│   │   from sqlalchemy.ext.asyncio import async_sessionmaker
│   │   from sqlalchemy.ext.asyncio import AsyncSession
│   │   from .base import Base
│   │   
│   │   T = TypeVar("T", bound=Base)
│   │   
│   │   
│   │   class Repository(Generic[T]):
│   │       """
│   │       Generic repository providing basic CRUD operations.
│   │       Services can extend this for specific domain needs.
│   │       """
│   │       
│   │       def __init__(self, model: Type[T], session_factory: async_sessionmaker[AsyncSession]):
│   │           self.model = model
│   │           self.session_factory = session_factory
│   │   
│   │       # helper used by child methods
│   │       async def _session(self) -> AsyncIterator[AsyncSession]:
│   │           async with self.session_factory() as session:
│   │               yield session
│   │   ```
│   │   
│   └── session.py
│       
│       ```py
│       # glam-app/shared/database/session.py
│       from sqlalchemy.ext.asyncio import (
│           create_async_engine,
│           AsyncSession,
│           async_sessionmaker,
│           AsyncEngine
│       )
│       from contextlib import asynccontextmanager
│       from typing import AsyncGenerator, Optional
│       import logging
│       
│       logger = logging.getLogger(__name__)
│       
│       
│       class DatabaseSessionManager:
│           """
│           Manages database connections and sessions for a microservice.
│           Each service creates its own instance with its specific configuration.
│           """
│           
│           def __init__(
│               self,
│               database_url: str,
│               echo: bool = False,
│               pool_size: int = 5,
│               max_overflow: int = 10,
│               pool_pre_ping: bool = True,
│               pool_recycle: int = 3600
│           ):
│               self.database_url = database_url
│               self._engine: Optional[AsyncEngine] = None
│               self._session_factory: Optional[async_sessionmaker[AsyncSession]] = None
│               
│               # Engine configuration
│               self.engine_config = {
│                   "echo": echo,
│                   "pool_size": pool_size,
│                   "max_overflow": max_overflow,
│                   "pool_pre_ping": pool_pre_ping,
│                   "pool_recycle": pool_recycle,
│               }
│           
│           async def init(self):
│               """Initialize the database engine and session factory"""
│               if self._engine is not None:
│                   raise RuntimeError("Database session manager already initialized")
│               
│               self._engine = create_async_engine(
│                   self.database_url,
│                   **self.engine_config
│               )
│               
│               self._session_factory = async_sessionmaker(
│                   bind=self._engine,
│                   class_=AsyncSession,
│                   autocommit=False,
│                   autoflush=False,
│                   expire_on_commit=False
│               )
│               
│               logger.info(f"Database engine initialized with URL: {self.database_url}")
│           
│           async def close(self):
│               """Close the database engine"""
│               if self._engine is None:
│                   raise RuntimeError("Database session manager not initialized")
│               
│               await self._engine.dispose()
│               self._engine = None
│               self._session_factory = None
│               logger.info("Database engine closed")
│           
│           @asynccontextmanager
│           async def session(self) -> AsyncGenerator[AsyncSession, None]:
│               """
│               Provide a transactional scope around a series of operations.
│               Automatically commits on success and rolls back on error.
│               """
│               if self._session_factory is None:
│                   raise RuntimeError("Database session manager not initialized")
│               
│               async with self._session_factory() as session:
│                   try:
│                       yield session
│                       await session.commit()
│                   except Exception:
│                       await session.rollback()
│                       raise
│                   finally:
│                       await session.close()
│           
│           async def get_session(self) -> AsyncGenerator[AsyncSession, None]:
│               """
│               Dependency injection function for FastAPI.
│               Yields a database session and handles cleanup.
│               """
│               async with self.session() as session:
│                   yield session
│           
│           @property
│           def engine(self) -> AsyncEngine:
│               """Get the underlying SQLAlchemy engine"""
│               if self._engine is None:
│                   raise RuntimeError("Database session manager not initialized")
│               return self._engine
│           
│           @property
│           def session_factory(self) -> async_sessionmaker[AsyncSession]:
│               """Get the session factory"""
│               if self._session_factory is None:
│                   raise RuntimeError("Database session manager not initialized")
│               return self._session_factory
│       ```
│       
├── errors/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/__init__.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Shared error handling module for glam-app microservices.
│   │   
│   │   This module provides a consistent error hierarchy and handling patterns
│   │   across all services, following the three-tier model:
│   │   - BaseError (root)
│   │   - InfrastructureError (external failures)
│   │   - DomainError (business logic failures)
│   │   """
│   │   
│   │   from .base import (
│   │       GlamBaseError,
│   │       InfrastructureError,
│   │       DomainError,
│   │       ValidationError,
│   │       NotFoundError,
│   │       ConflictError,
│   │       UnauthorizedError,
│   │       ForbiddenError,
│   │       RateLimitedError,
│   │       ServiceUnavailableError,
│   │       RequestTimeoutError,
│   │       InternalError,
│   │   )
│   │   
│   │   from .catalog import (
│   │       SyncInProgressError,
│   │       SyncNotFoundError,
│   │       SyncNotResumableError,
│   │       SyncNotCancellableError,
│   │       ItemNotFoundError,
│   │       ParentSyncNotFoundError,
│   │   )
│   │   
│   │   from .profile import (
│   │       ProfileNotFoundError,
│   │       ProfileAlreadyExistsError,
│   │       ProfileCreationFailedError,
│   │   )
│   │   
│   │   from .analysis import (
│   │       AnalysisInProgressError,
│   │       AnalysisNotFoundError,
│   │       AnalysisNotCancellableError,
│   │       NoCurrentAnalysisError,
│   │   )
│   │   
│   │   from .selfie import (
│   │       SelfieNotFoundError,
│   │       InvalidImageFormatError,
│   │       ImageTooLargeError,
│   │       ImageTooSmallError,
│   │       NoFaceDetectedError,
│   │       MultipleFacesDetectedError,
│   │       PoorImageQualityError,
│   │   )
│   │   
│   │   from .notification import (
│   │       NotificationNotFoundError,
│   │       TemplateNotFoundError,
│   │       TemplateRenderError,
│   │       InvalidRecipientError,
│   │       PreferencesNotFoundError,
│   │       EmailProviderError,
│   │       UnsubscribedError,
│   │   )
│   │   
│   │   from .infrastructure import (
│   │       DatabaseError,
│   │       RedisError,
│   │       S3Error,
│   │       UpstreamServiceError,
│   │       CircuitOpenError,
│   │       MessageBusError,
│   │   )
│   │   
│   │   
│   │   from .utils import (
│   │       wrap_external_error,
│   │       classify_http_error,
│   │       is_retryable_error,
│   │   )
│   │   
│   │   __all__ = [
│   │       # Base errors
│   │       "GlamBaseError",
│   │       "InfrastructureError",
│   │       "DomainError",
│   │       # Common domain errors
│   │       "ValidationError",
│   │       "NotFoundError",
│   │       "ConflictError",
│   │       "UnauthorizedError",
│   │       "ForbiddenError",
│   │       "RateLimitedError",
│   │       "ServiceUnavailableError",
│   │       "InternalError",
│   │       # Catalog errors
│   │       "SyncInProgressError",
│   │       "SyncNotFoundError",
│   │       "SyncNotResumableError",
│   │       "SyncNotCancellableError",
│   │       "ItemNotFoundError",
│   │       "ParentSyncNotFoundError",
│   │       # Profile errors
│   │       "ProfileNotFoundError",
│   │       "ProfileAlreadyExistsError",
│   │       "ProfileCreationFailedError",
│   │       # Analysis errors
│   │       "AnalysisInProgressError",
│   │       "AnalysisNotFoundError",
│   │       "AnalysisNotCancellableError",
│   │       "NoCurrentAnalysisError",
│   │       # Selfie errors
│   │       "SelfieNotFoundError",
│   │       "InvalidImageFormatError",
│   │       "ImageTooLargeError",
│   │       "ImageTooSmallError",
│   │       "NoFaceDetectedError",
│   │       "MultipleFacesDetectedError",
│   │       "PoorImageQualityError",
│   │       # Notification errors
│   │       "NotificationNotFoundError",
│   │       "TemplateNotFoundError",
│   │       "TemplateRenderError",
│   │       "InvalidRecipientError",
│   │       "PreferencesNotFoundError",
│   │       "EmailProviderError",
│   │       "UnsubscribedError",
│   │       # Infrastructure errors
│   │       "DatabaseError",
│   │       "RedisError",
│   │       "S3Error",
│   │       "UpstreamServiceError",
│   │       "CircuitOpenError",
│   │       "MessageBusError",
│   │       # Handlers and utilities
│   │       "wrap_external_error",
│   │       "classify_http_error",
│   │       "is_retryable_error",
│   │   ]
│   │   ```
│   │   
│   ├── analysis.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/analysis.py
│   │   # -------------------------------
│   │   
│   │   """Analysis service specific errors."""
│   │   
│   │   from typing import Optional
│   │   from .base import ConflictError, NotFoundError
│   │   
│   │   
│   │   class AnalysisInProgressError(ConflictError):
│   │       """Another analysis is already in progress."""
│   │       
│   │       code = "ANALYSIS_IN_PROGRESS"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "Another analysis is already in progress",
│   │           *,
│   │           current_analysis_id: Optional[str] = None,
│   │           user_id: Optional[str] = None,
│   │           started_at: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if current_analysis_id:
│   │               self.details["current_analysis_id"] = current_analysis_id
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │           if started_at:
│   │               self.details["started_at"] = started_at
│   │   
│   │   
│   │   class AnalysisNotFoundError(NotFoundError):
│   │       """Analysis not found."""
│   │       
│   │       code = "ANALYSIS_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           analysis_id: Optional[str] = None,
│   │           user_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, resource="analysis", resource_id=analysis_id, **kwargs)
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │   
│   │   
│   │   class AnalysisNotCancellableError(ConflictError):
│   │       """Analysis cannot be cancelled in its current state."""
│   │       
│   │       code = "ANALYSIS_NOT_CANCELLABLE"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           analysis_id: Optional[str] = None,
│   │           current_status: Optional[str] = None,
│   │           reason: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if analysis_id:
│   │               self.details["analysis_id"] = analysis_id
│   │           if current_status:
│   │               self.details["current_status"] = current_status
│   │           if reason:
│   │               self.details["reason"] = reason
│   │   
│   │   
│   │   class NoCurrentAnalysisError(NotFoundError):
│   │       """No completed analysis available."""
│   │       
│   │       code = "NO_CURRENT_ANALYSIS"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "No completed analysis available",
│   │           *,
│   │           user_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, resource="current_analysis", **kwargs)
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │   ```
│   │   
│   ├── base.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/base.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   Base error classes for the glam-app error hierarchy.
│   │   
│   │   This module defines the fundamental error types that all other
│   │   errors inherit from, following a three-tier model:
│   │   1. GlamBaseError - Root of all application errors
│   │   2. InfrastructureError - External system failures
│   │   3. DomainError - Business logic violations
│   │   """
│   │   
│   │   from typing import Any, Dict, Optional
│   │   
│   │   
│   │   class GlamBaseError(Exception):
│   │       """
│   │       Base class for all glam-app errors.
│   │   
│   │       Attributes:
│   │           code: Stable error code for clients (e.g., "VALIDATION_ERROR")
│   │           status: HTTP status code (default 500)
│   │           message: Human-readable error message
│   │           details: Additional error context
│   │           __cause__: Original exception if wrapped
│   │       """
│   │   
│   │       code: str = "INTERNAL_ERROR"
│   │       status: int = 500
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           code: Optional[str] = None,
│   │           status: Optional[int] = None,
│   │           details: Optional[Dict[str, Any]] = None,
│   │           cause: Optional[Exception] = None
│   │       ):
│   │           super().__init__(message)
│   │   
│   │           if code is not None:
│   │               self.code = code
│   │           if status is not None:
│   │               self.status = status
│   │   
│   │           self.message = message
│   │           self.details = details or {}
│   │   
│   │           # Preserve the original exception chain
│   │           if cause is not None:
│   │               self.__cause__ = cause
│   │   
│   │       def to_dict(self) -> Dict[str, Any]:
│   │           """Convert error to dictionary for JSON serialization."""
│   │           result: Dict[str, Any] = {
│   │               "code": self.code,
│   │               "message": self.message,
│   │           }
│   │   
│   │           if self.details:
│   │               result["details"] = self.details
│   │   
│   │           return result
│   │   
│   │   
│   │   class InfrastructureError(GlamBaseError):
│   │       """
│   │       Infrastructure/external system errors.
│   │   
│   │       These are failures in external dependencies like databases,
│   │       APIs, message queues, etc. They may be retryable.
│   │       """
│   │   
│   │       code = "INFRASTRUCTURE_ERROR"
│   │       status = 503  # Service Unavailable
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           service: Optional[str] = None,
│   │           retryable: bool = True,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if service:
│   │               self.details["service"] = service
│   │   
│   │           self.details["retryable"] = retryable
│   │           self.retryable = retryable
│   │   
│   │   
│   │   class DomainError(GlamBaseError):
│   │       """
│   │       Domain/business logic errors.
│   │   
│   │       These represent violations of business rules or invalid
│   │       operations within the application domain.
│   │       """
│   │   
│   │       code = "DOMAIN_ERROR"
│   │       status = 400  # Bad Request
│   │   
│   │   
│   │   # Common domain errors used across services
│   │   
│   │   
│   │   class ValidationError(DomainError):
│   │       """Invalid request data or parameters."""
│   │   
│   │       code = "VALIDATION_ERROR"
│   │       status = 422  # Unprocessable Entity
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           field: Optional[str] = None,
│   │           value: Optional[Any] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if field:
│   │               self.details["field"] = field
│   │           if value is not None:
│   │               self.details["value"] = str(value)
│   │   
│   │   
│   │   class NotFoundError(DomainError):
│   │       """Requested resource not found."""
│   │   
│   │       code = "NOT_FOUND"
│   │       status = 404
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           resource: Optional[str] = None,
│   │           resource_id: Optional[Any] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if resource:
│   │               self.details["resource"] = resource
│   │           if resource_id is not None:
│   │               self.details["resource_id"] = str(resource_id)
│   │   
│   │   
│   │   class ConflictError(DomainError):
│   │       """Operation conflicts with current state."""
│   │   
│   │       code = "CONFLICT"
│   │       status = 409
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           conflicting_resource: Optional[str] = None,
│   │           current_state: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if conflicting_resource:
│   │               self.details["conflicting_resource"] = conflicting_resource
│   │           if current_state:
│   │               self.details["current_state"] = current_state
│   │   
│   │   
│   │   class UnauthorizedError(DomainError):
│   │       """Authentication required or failed."""
│   │   
│   │       code = "UNAUTHORIZED"
│   │       status = 401
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "Authentication required",
│   │           *,
│   │           auth_type: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if auth_type:
│   │               self.details["auth_type"] = auth_type
│   │   
│   │   
│   │   class ForbiddenError(DomainError):
│   │       """Authenticated but insufficient permissions."""
│   │   
│   │       code = "FORBIDDEN"
│   │       status = 403
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "Insufficient permissions",
│   │           *,
│   │           required_permission: Optional[str] = None,
│   │           resource: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if required_permission:
│   │               self.details["required_permission"] = required_permission
│   │           if resource:
│   │               self.details["resource"] = resource
│   │   
│   │   
│   │   class RateLimitedError(DomainError):
│   │       """Too many requests."""
│   │   
│   │       code = "RATE_LIMITED"
│   │       status = 429
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "Rate limit exceeded",
│   │           *,
│   │           limit: Optional[int] = None,
│   │           window: Optional[str] = None,
│   │           retry_after: Optional[int] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if limit:
│   │               self.details["limit"] = limit
│   │           if window:
│   │               self.details["window"] = window
│   │           if retry_after:
│   │               self.details["retry_after"] = retry_after
│   │   
│   │   
│   │   class ServiceUnavailableError(InfrastructureError):
│   │       """Service temporarily unavailable."""
│   │   
│   │       code = "SERVICE_UNAVAILABLE"
│   │       status = 503
│   │   
│   │   
│   │   class RequestTimeoutError(InfrastructureError):
│   │       """Operation timed out."""
│   │   
│   │       code = "TIMEOUT"
│   │       status = 504
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           timeout_seconds: Optional[float] = None,
│   │           operation: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if timeout_seconds:
│   │               self.details["timeout_seconds"] = timeout_seconds
│   │           if operation:
│   │               self.details["operation"] = operation
│   │   
│   │   
│   │   class InternalError(GlamBaseError):
│   │       """Unexpected internal server error."""
│   │   
│   │       code = "INTERNAL_ERROR"
│   │       status = 500
│   │   
│   │       def __init__(
│   │           self,
│   │           message: str = "An unexpected error occurred",
│   │           *,
│   │           error_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           # Never expose internal details in production
│   │           super().__init__(message, **kwargs)
│   │   
│   │           if error_id:
│   │               self.details["error_id"] = error_id
│   │   ```
│   │   
│   ├── catalog.py
│   │   
│   │   ```py
│   │   
│   │   # -------------------------------
│   │   # shared/errors/catalog.py
│   │   # -------------------------------
│   │   
│   │   """Catalog service specific errors."""
│   │   
│   │   from typing import Optional
│   │   from .base import ConflictError, NotFoundError
│   │   
│   │   
│   │   class SyncInProgressError(ConflictError):
│   │       """Another sync operation is already running."""
│   │       
│   │       code = "SYNC_IN_PROGRESS"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "Another sync is already in progress",
│   │           *,
│   │           current_sync_id: Optional[str] = None,
│   │           merchant_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if current_sync_id:
│   │               self.details["current_sync_id"] = current_sync_id
│   │           if merchant_id:
│   │               self.details["merchant_id"] = merchant_id
│   │   
│   │   
│   │   class SyncNotFoundError(NotFoundError):
│   │       """Sync operation not found."""
│   │       
│   │       code = "SYNC_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           sync_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, resource="sync", resource_id=sync_id, **kwargs)
│   │   
│   │   
│   │   class SyncNotResumableError(ConflictError):
│   │       """Sync cannot be resumed in its current state."""
│   │       
│   │       code = "SYNC_NOT_RESUMABLE"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           sync_id: Optional[str] = None,
│   │           sync_status: Optional[str] = None,
│   │           reason: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if sync_id:
│   │               self.details["sync_id"] = sync_id
│   │           if sync_status:
│   │               self.details["sync_status"] = sync_status
│   │           if reason:
│   │               self.details["reason"] = reason
│   │   
│   │   
│   │   class SyncNotCancellableError(ConflictError):
│   │       """Sync cannot be cancelled in its current state."""
│   │       
│   │       code = "SYNC_NOT_CANCELLABLE"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           sync_id: Optional[str] = None,
│   │           sync_status: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if sync_id:
│   │               self.details["sync_id"] = sync_id
│   │           if sync_status:
│   │               self.details["sync_status"] = sync_status
│   │   
│   │   
│   │   class ItemNotFoundError(NotFoundError):
│   │       """Item not found in catalog."""
│   │       
│   │       code = "ITEM_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           item_id: Optional[str] = None,
│   │           merchant_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, resource="item", resource_id=item_id, **kwargs)
│   │           
│   │           if merchant_id:
│   │               self.details["merchant_id"] = merchant_id
│   │   
│   │   
│   │   class ParentSyncNotFoundError(NotFoundError):
│   │       """Parent sync operation not found for resume."""
│   │       
│   │       code = "PARENT_SYNC_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           parent_sync_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(
│   │               message,
│   │               resource="parent_sync",
│   │               resource_id=parent_sync_id,
│   │               **kwargs
│   │           )
│   │   ```
│   │   
│   ├── infrastructure.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/infrastructure.py
│   │   # -------------------------------
│   │   
│   │   """Infrastructure-specific error classes."""
│   │   
│   │   from typing import Optional
│   │   from .base import InfrastructureError
│   │   
│   │   
│   │   class DatabaseError(InfrastructureError):
│   │       """Database operation failed."""
│   │       
│   │       code = "DATABASE_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           operation: Optional[str] = None,
│   │           table: Optional[str] = None,
│   │           error_code: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, service="database", **kwargs)
│   │           
│   │           if operation:
│   │               self.details["operation"] = operation
│   │           if table:
│   │               self.details["table"] = table
│   │           if error_code:
│   │               self.details["error_code"] = error_code
│   │   
│   │   
│   │   class RedisError(InfrastructureError):
│   │       """Redis operation failed."""
│   │       
│   │       code = "REDIS_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           operation: Optional[str] = None,
│   │           key: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, service="redis", **kwargs)
│   │           
│   │           if operation:
│   │               self.details["operation"] = operation
│   │           if key:
│   │               self.details["key"] = key
│   │   
│   │   
│   │   class S3Error(InfrastructureError):
│   │       """S3 operation failed."""
│   │       
│   │       code = "S3_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           operation: Optional[str] = None,
│   │           bucket: Optional[str] = None,
│   │           key: Optional[str] = None,
│   │           error_code: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, service="s3", **kwargs)
│   │           
│   │           if operation:
│   │               self.details["operation"] = operation
│   │           if bucket:
│   │               self.details["bucket"] = bucket
│   │           if key:
│   │               self.details["key"] = key
│   │           if error_code:
│   │               self.details["error_code"] = error_code
│   │   
│   │   
│   │   class UpstreamServiceError(InfrastructureError):
│   │       """Upstream service call failed."""
│   │       
│   │       code = "UPSTREAM_SERVICE_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           upstream_service: Optional[str] = None,
│   │           upstream_status: Optional[int] = None,
│   │           upstream_error: Optional[str] = None,
│   │           endpoint: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, service=upstream_service, **kwargs)
│   │           
│   │           if upstream_status:
│   │               self.details["upstream_status"] = upstream_status
│   │           if upstream_error:
│   │               self.details["upstream_error"] = upstream_error
│   │           if endpoint:
│   │               self.details["endpoint"] = endpoint
│   │   
│   │   
│   │   class CircuitOpenError(InfrastructureError):
│   │       """Circuit breaker is open."""
│   │       
│   │       code = "CIRCUIT_OPEN"
│   │       status = 503
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           service_name: Optional[str] = None,
│   │           failure_count: Optional[int] = None,
│   │           open_until: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(
│   │               message,
│   │               service=service_name,
│   │               retryable=False,  # Don't retry when circuit is open
│   │               **kwargs
│   │           )
│   │           
│   │           if failure_count:
│   │               self.details["failure_count"] = failure_count
│   │           if open_until:
│   │               self.details["open_until"] = open_until
│   │   
│   │   
│   │   class MessageBusError(InfrastructureError):
│   │       """Message bus operation failed."""
│   │       
│   │       code = "MESSAGE_BUS_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           operation: Optional[str] = None,
│   │           stream: Optional[str] = None,
│   │           subject: Optional[str] = None,
│   │           event_type: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, service="nats", **kwargs)
│   │           
│   │           if operation:
│   │               self.details["operation"] = operation
│   │           if stream:
│   │               self.details["stream"] = stream
│   │           if subject:
│   │               self.details["subject"] = subject
│   │           if event_type:
│   │               self.details["event_type"] = event_type
│   │   ```
│   │   
│   ├── middleware.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/middleware.py
│   │   # -------------------------------
│   │   
│   │   """
│   │   FastAPI middleware and exception handlers for consistent error handling.
│   │   
│   │   This module provides middleware and handlers that can be used by all
│   │   services to ensure consistent error responses.
│   │   """
│   │   
│   │   import time
│   │   import uuid
│   │   import logging
│   │   from typing import Callable, Optional
│   │   from contextlib import asynccontextmanager
│   │   
│   │   from fastapi import FastAPI, Request, Response, HTTPException
│   │   from fastapi.responses import JSONResponse
│   │   from fastapi.exceptions import RequestValidationError
│   │   from shared.api.responses import exception_to_error_response
│   │   from starlette.middleware.base import BaseHTTPMiddleware
│   │   from starlette.types import ASGIApp
│   │   
│   │   from .base import GlamBaseError, ValidationError
│   │   
│   │   
│   │   logger = logging.getLogger(__name__)
│   │   
│   │   
│   │   class ErrorHandlingMiddleware(BaseHTTPMiddleware):
│   │       """
│   │       Middleware that ensures all errors are converted to standard format.
│   │       
│   │       This middleware:
│   │       - Catches all exceptions and converts to standard error responses
│   │       - Logs request metrics and errors
│   │       """
│   │       
│   │       def __init__(
│   │           self,
│   │           app: ASGIApp,
│   │           *,
│   │           include_details: bool = True,
│   │           log_errors: bool = True
│   │       ):
│   │           super().__init__(app)
│   │           self.include_details = include_details
│   │           self.log_errors = log_errors
│   │       
│   │       async def dispatch(self, request: Request, call_next: Callable) -> Response:
│   │           # Track request timing
│   │           start_time = time.perf_counter()
│   │           
│   │           try:
│   │               response = await call_next(request)
│   │               return response
│   │               
│   │           except Exception as exc:
│   │               # Get request_id and correlation_id from request state if available
│   │               request_id = getattr(request.state, "request_id", None)
│   │               correlation_id = getattr(request.state, "correlation_id", None)
│   │               
│   │               # Convert exception to standard error response
│   │               error_response, status_code = exception_to_error_response(
│   │                   exc,
│   │                   request_id=request_id,
│   │                   correlation_id=correlation_id,
│   │                   include_details=self.include_details,
│   │                   log_traceback=self.log_errors
│   │               )
│   │               
│   │               # Log error with context
│   │               if self.log_errors:
│   │                   duration_ms = (time.perf_counter() - start_time) * 1000
│   │                   logger.error(
│   │                       "Request failed",
│   │                       extra={
│   │                           "request_id": request_id,
│   │                           "method": request.method,
│   │                           "path": request.url.path,
│   │                           "status": status_code,
│   │                           "duration_ms": round(duration_ms, 2),
│   │                           "error_code": error_response.error.code,
│   │                       }
│   │                   )
│   │               
│   │               return JSONResponse(
│   │                   content=error_response.model_dump(),
│   │                   status_code=status_code
│   │               )
│   │           
│   │           finally:
│   │               # Always log request completion
│   │               duration_ms = (time.perf_counter() - start_time) * 1000
│   │               logger.info(
│   │                   "Request completed",
│   │                   extra={
│   │                       "method": request.method,
│   │                       "path": request.url.path,
│   │                       "duration_ms": round(duration_ms, 2),
│   │                   }
│   │               )
│   │   
│   │   
│   │   def setup_exception_handlers(
│   │       app: FastAPI,
│   │       *,
│   │       include_details: bool = True
│   │   ):
│   │       """
│   │       Set up standard exception handlers for a FastAPI app.
│   │       
│   │       This adds handlers for:
│   │       - GlamBaseError (our custom errors)
│   │       - RequestValidationError (Pydantic validation)
│   │       - HTTPException (FastAPI HTTP errors)
│   │       - Generic Exception (unexpected errors)
│   │       
│   │       Args:
│   │           app: FastAPI application instance
│   │           include_details: Whether to include error details in responses
│   │       """
│   │       
│   │       @app.exception_handler(GlamBaseError)
│   │       async def glam_error_handler(request: Request, exc: GlamBaseError):
│   │           """Handle our custom domain/infrastructure errors."""
│   │           request_id = getattr(request.state, "request_id", None)
│   │           correlation_id = getattr(request.state, "correlation_id", None)
│   │           
│   │           error_response, status_code = exception_to_error_response(
│   │               exc,
│   │               request_id=request_id,
│   │               correlation_id=correlation_id,
│   │               include_details=include_details,
│   │               log_traceback=False  # Don't log expected errors
│   │           )
│   │           
│   │           return JSONResponse(
│   │               content=error_response.model_dump(),
│   │               status_code=status_code
│   │           )
│   │       
│   │       @app.exception_handler(RequestValidationError)
│   │       async def validation_error_handler(request: Request, exc: RequestValidationError):
│   │           """Handle Pydantic validation errors."""
│   │           request_id = getattr(request.state, "request_id", None)
│   │           correlation_id = getattr(request.state, "correlation_id", None)
│   │           
│   │           # Convert Pydantic errors to our format
│   │           validation_errors = []
│   │           for error in exc.errors():
│   │               field_path = ".".join(str(loc) for loc in error["loc"])
│   │               validation_errors.append({
│   │                   "field": field_path,
│   │                   "message": error["msg"],
│   │                   "type": error["type"]
│   │               })
│   │           
│   │           # Create a ValidationError with details
│   │           validation_exc = ValidationError(
│   │               "Request validation failed",
│   │               details={"validation_errors": validation_errors}
│   │           )
│   │           
│   │           error_response, status_code = exception_to_error_response(
│   │               validation_exc,
│   │               request_id=request_id,
│   │               correlation_id=correlation_id,
│   │               include_details=include_details
│   │           )
│   │           
│   │           return JSONResponse(
│   │               content=error_response.model_dump(),
│   │               status_code=status_code
│   │           )
│   │       
│   │       @app.exception_handler(HTTPException)
│   │       async def http_exception_handler(request: Request, exc: HTTPException):
│   │           """Handle FastAPI HTTP exceptions."""
│   │           request_id = getattr(request.state, "request_id", None)
│   │           correlation_id = getattr(request.state, "correlation_id", None)
│   │           
│   │           # Map common HTTP exceptions to our error types
│   │           if exc.status_code == 401:
│   │               from .base import UnauthorizedError
│   │               domain_exc = UnauthorizedError(exc.detail)
│   │           elif exc.status_code == 403:
│   │               from .base import ForbiddenError
│   │               domain_exc = ForbiddenError(exc.detail)
│   │           elif exc.status_code == 404:
│   │               from .base import NotFoundError
│   │               domain_exc = NotFoundError(exc.detail)
│   │           else:
│   │               # Generic error
│   │               domain_exc = GlamBaseError(
│   │                   exc.detail,
│   │                   code="HTTP_ERROR",
│   │                   status=exc.status_code
│   │               )
│   │           
│   │           error_response, status_code = exception_to_error_response(
│   │               domain_exc,
│   │               request_id=request_id,
│   │               correlation_id=correlation_id,
│   │               include_details=include_details
│   │           )
│   │           
│   │           return JSONResponse(
│   │               content=error_response.model_dump(),
│   │               status_code=status_code
│   │           )
│   │       
│   │       @app.exception_handler(Exception)
│   │       async def generic_exception_handler(request: Request, exc: Exception):
│   │           """Handle unexpected errors."""
│   │           request_id = getattr(request.state, "request_id", None)
│   │           correlation_id = getattr(request.state, "correlation_id", None)
│   │           
│   │           error_response, status_code = exception_to_error_response(
│   │               exc,
│   │               request_id=request_id,
│   │               correlation_id=correlation_id,
│   │               include_details=include_details,
│   │               log_traceback=True
│   │           )
│   │           
│   │           return JSONResponse(
│   │               content=error_response.model_dump(),
│   │               status_code=status_code
│   │           )
│   │   
│   │   
│   │   @asynccontextmanager
│   │   async def get_request_id(request: Request):
│   │       """
│   │       Context manager to access the current request's ID.
│   │       
│   │       Usage:
│   │           async with get_request_id(request) as request_id:
│   │               # Use request_id in your code
│   │       """
│   │       request_id = getattr(request.state, "request_id", None)
│   │       if not request_id:
│   │           request_id = f"req_{uuid.uuid4().hex[:12]}"
│   │           request.state.request_id = request_id
│   │       
│   │       yield request_id
│   │   ```
│   │   
│   ├── notification.py
│   │   
│   │   ```py
│   │   # -------------------------------
│   │   # shared/errors/notification.py
│   │   # -------------------------------
│   │   
│   │   from uuid import UUID
│   │   
│   │   """Notification service specific errors."""
│   │   
│   │   from typing import Optional
│   │   from .base import NotFoundError, ValidationError, InfrastructureError, ConflictError
│   │   
│   │   
│   │   class NotificationNotFoundError(NotFoundError):
│   │       """Notification not found."""
│   │       
│   │       code = "NOTIFICATION_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           notification_id: Optional[UUID] = None,
│   │           shop_id: Optional[UUID] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(
│   │               message,
│   │               resource="notification",
│   │               resource_id=notification_id,
│   │               **kwargs
│   │           )
│   │           
│   │           if shop_id:
│   │               self.details["shop_id"] = shop_id
│   │   
│   │   
│   │   class TemplateNotFoundError(NotFoundError):
│   │       """Email template not found."""
│   │       
│   │       code = "TEMPLATE_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           template_name: Optional[str] = None,
│   │           template_type: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(
│   │               message,
│   │               resource="template",
│   │               resource_id=template_name,
│   │               **kwargs
│   │           )
│   │           
│   │           if template_type:
│   │               self.details["template_type"] = template_type
│   │   
│   │   
│   │   class TemplateRenderError(ValidationError):
│   │       """Failed to render email template."""
│   │       
│   │       code = "TEMPLATE_RENDER_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           template_name: Optional[str] = None,
│   │           missing_variables: Optional[list] = None,
│   │           render_error: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if template_name:
│   │               self.details["template_name"] = template_name
│   │           if missing_variables:
│   │               self.details["missing_variables"] = missing_variables
│   │           if render_error:
│   │               self.details["render_error"] = render_error
│   │   
│   │   
│   │   class InvalidRecipientError(ValidationError):
│   │       """Invalid recipient email address."""
│   │       
│   │       code = "INVALID_RECIPIENT"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           recipient: Optional[str] = None,
│   │           reason: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, field="recipient", value=recipient, **kwargs)
│   │           
│   │           if reason:
│   │               self.details["reason"] = reason
│   │   
│   │   
│   │   class PreferencesNotFoundError(NotFoundError):
│   │       """Notification preferences not found."""
│   │       
│   │       code = "PREFERENCES_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           user_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(
│   │               message,
│   │               resource="notification_preferences",
│   │               resource_id=user_id,
│   │               **kwargs
│   │           )
│   │   
│   │   
│   │   class EmailProviderError(InfrastructureError):
│   │       """Email provider API error."""
│   │       
│   │       code = "EMAIL_PROVIDER_ERROR"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           provider: Optional[str] = None,
│   │           provider_error_code: Optional[str] = None,
│   │           provider_message: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, service=provider, **kwargs)
│   │           
│   │           if provider_error_code:
│   │               self.details["provider_error_code"] = provider_error_code
│   │           if provider_message:
│   │               self.details["provider_message"] = provider_message
│   │   
│   │   
│   │   class UnsubscribedError(ConflictError):
│   │       """Recipient has unsubscribed."""
│   │       
│   │       code = "UNSUBSCRIBED"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "Recipient has unsubscribed from notifications",
│   │           *,
│   │           user_id: Optional[str] = None,
│   │           notification_type: Optional[str] = None,
│   │           unsubscribed_at: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │           if notification_type:
│   │               self.details["notification_type"] = notification_type
│   │           if unsubscribed_at:
│   │               self.details["unsubscribed_at"] = unsubscribed_at
│   │   ```
│   │   
│   ├── profile.py
│   │   
│   │   ```py
│   │   
│   │   # -------------------------------
│   │   # shared/errors/profile.py
│   │   # -------------------------------
│   │   
│   │   """Profile service specific errors."""
│   │   
│   │   from typing import Optional
│   │   from .base import NotFoundError, ConflictError, DomainError
│   │   
│   │   
│   │   class ProfileNotFoundError(NotFoundError):
│   │       """User profile not found."""
│   │       
│   │       code = "PROFILE_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           user_id: Optional[str] = None,
│   │           profile_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, resource="profile", **kwargs)
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │           if profile_id:
│   │               self.details["profile_id"] = profile_id
│   │   
│   │   
│   │   class ProfileAlreadyExistsError(ConflictError):
│   │       """Profile already exists for this user."""
│   │       
│   │       code = "PROFILE_ALREADY_EXISTS"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           user_id: Optional[str] = None,
│   │           existing_profile_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(
│   │               message,
│   │               conflicting_resource="profile",
│   │               **kwargs
│   │           )
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │           if existing_profile_id:
│   │               self.details["existing_profile_id"] = existing_profile_id
│   │   
│   │   
│   │   class ProfileCreationFailedError(DomainError):
│   │       """Failed to create profile."""
│   │       
│   │       code = "PROFILE_CREATION_FAILED"
│   │       status = 422
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           user_id: Optional[str] = None,
│   │           reason: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │           if reason:
│   │               self.details["reason"] = reason
│   │   ```
│   │   
│   ├── selfie.py
│   │   
│   │   ```py
│   │   
│   │   # -------------------------------
│   │   # shared/errors/selfie.py
│   │   # -------------------------------
│   │   
│   │   """Selfie service specific errors."""
│   │   
│   │   from typing import Optional, List
│   │   from .base import NotFoundError, ValidationError
│   │   
│   │   
│   │   class SelfieNotFoundError(NotFoundError):
│   │       """Selfie not found."""
│   │       
│   │       code = "SELFIE_NOT_FOUND"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           selfie_id: Optional[str] = None,
│   │           user_id: Optional[str] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, resource="selfie", resource_id=selfie_id, **kwargs)
│   │           
│   │           if user_id:
│   │               self.details["user_id"] = user_id
│   │   
│   │   
│   │   class InvalidImageFormatError(ValidationError):
│   │       """Image format not supported."""
│   │       
│   │       code = "INVALID_IMAGE_FORMAT"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           provided_format: Optional[str] = None,
│   │           supported_formats: Optional[List[str]] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if provided_format:
│   │               self.details["provided_format"] = provided_format
│   │           if supported_formats:
│   │               self.details["supported_formats"] = supported_formats
│   │   
│   │   
│   │   class ImageTooLargeError(ValidationError):
│   │       """Image exceeds size limit."""
│   │       
│   │       code = "IMAGE_TOO_LARGE"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           size_bytes: Optional[int] = None,
│   │           max_size_bytes: Optional[int] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if size_bytes:
│   │               self.details["size_bytes"] = size_bytes
│   │           if max_size_bytes:
│   │               self.details["max_size_bytes"] = max_size_bytes
│   │   
│   │   
│   │   class ImageTooSmallError(ValidationError):
│   │       """Image below minimum dimensions."""
│   │       
│   │       code = "IMAGE_TOO_SMALL"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str,
│   │           *,
│   │           width: Optional[int] = None,
│   │           height: Optional[int] = None,
│   │           min_width: Optional[int] = None,
│   │           min_height: Optional[int] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if width:
│   │               self.details["width"] = width
│   │           if height:
│   │               self.details["height"] = height
│   │           if min_width:
│   │               self.details["min_width"] = min_width
│   │           if min_height:
│   │               self.details["min_height"] = min_height
│   │   
│   │   
│   │   class NoFaceDetectedError(ValidationError):
│   │       """No face detected in image."""
│   │       
│   │       code = "NO_FACE_DETECTED"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "No face detected in the image",
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │   
│   │   
│   │   class MultipleFacesDetectedError(ValidationError):
│   │       """Multiple faces detected."""
│   │       
│   │       code = "MULTIPLE_FACES_DETECTED"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "Multiple faces detected in the image",
│   │           *,
│   │           face_count: Optional[int] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if face_count:
│   │               self.details["face_count"] = face_count
│   │   
│   │   
│   │   class PoorImageQualityError(ValidationError):
│   │       """Image quality too low for analysis."""
│   │       
│   │       code = "POOR_IMAGE_QUALITY"
│   │       
│   │       def __init__(
│   │           self,
│   │           message: str = "Image quality too low for analysis",
│   │           *,
│   │           quality_score: Optional[float] = None,
│   │           min_quality_score: Optional[float] = None,
│   │           quality_issues: Optional[List[str]] = None,
│   │           **kwargs
│   │       ):
│   │           super().__init__(message, **kwargs)
│   │           
│   │           if quality_score is not None:
│   │               self.details["quality_score"] = quality_score
│   │           if min_quality_score is not None:
│   │               self.details["min_quality_score"] = min_quality_score
│   │           if quality_issues:
│   │               self.details["quality_issues"] = quality_issues
│   │   ```
│   │   
│   └── utils.py
│       
│       ```py
│       # -------------------------------
│       # shared/errors/utils.py
│       # -------------------------------
│       
│       """
│       Utility functions for error handling and classification.
│       
│       This module provides helpers for wrapping external errors,
│       classifying HTTP errors, and determining retry behavior.
│       """
│       
│       from typing import Type, Callable, TypeVar
│       import httpx
│       import asyncio
│       from functools import wraps
│       
│       from .base import (
│           GlamBaseError,
│           InfrastructureError,
│           RequestTimeoutError,
│           ServiceUnavailableError,
│           RateLimitedError,
│       )
│       from .infrastructure import UpstreamServiceError
│       
│       T = TypeVar("T")
│       
│       
│       def wrap_external_error(
│           error_class: Type[GlamBaseError], message: str, *, cause: Exception, **kwargs
│       ) -> GlamBaseError:
│           """
│           Wrap an external exception in a domain-specific error.
│       
│           This preserves the original exception chain while providing
│           a clean domain error for upper layers.
│       
│           Args:
│               error_class: The error class to wrap with
│               message: Human-readable error message
│               cause: The original exception
│               **kwargs: Additional arguments for the error class
│       
│           Returns:
│               Instance of error_class with proper cause chain
│           """
│           return error_class(message, cause=cause, **kwargs)
│       
│       
│       def classify_http_error(
│           exc: httpx.HTTPError, *, service_name: str = "upstream"
│       ) -> InfrastructureError | RateLimitedError:
│           """
│           Classify HTTP errors into appropriate infrastructure errors.
│       
│           Args:
│               exc: The HTTP exception to classify
│               service_name: Name of the upstream service
│       
│           Returns:
│               Appropriate InfrastructureError subclass
│           """
│           if isinstance(exc, httpx.TimeoutException):
│               return RequestTimeoutError(
│                   f"Request to {service_name} timed out", cause=exc, operation="http_request"
│               )
│       
│           if isinstance(exc, httpx.HTTPStatusError):
│               status = exc.response.status_code
│       
│               if status == 429:
│                   # Extract retry-after if available
│                   retry_after = exc.response.headers.get("Retry-After")
│                   return RateLimitedError(
│                       f"Rate limited by {service_name}",
│                       cause=exc,
│                       retry_after=int(retry_after) if retry_after else None,
│                   )
│       
│               if status == 503:
│                   return ServiceUnavailableError(
│                       f"{service_name} is temporarily unavailable", cause=exc
│                   )
│       
│               if 500 <= status < 600:
│                   return UpstreamServiceError(
│                       f"{service_name} returned {status}",
│                       cause=exc,
│                       upstream_service=service_name,
│                       upstream_status=status,
│                       endpoint=str(exc.request.url),
│                   )
│       
│               # 4xx errors - usually client errors, not retryable
│               return UpstreamServiceError(
│                   f"{service_name} rejected request: {status}",
│                   cause=exc,
│                   upstream_service=service_name,
│                   upstream_status=status,
│                   endpoint=str(exc.request.url),
│                   retryable=False,
│               )
│       
│           # Generic connection errors
│           return InfrastructureError(
│               f"Failed to connect to {service_name}", cause=exc, service=service_name
│           )
│       
│       
│       def is_retryable_error(exc: Exception) -> bool:
│           """
│           Determine if an error should be retried.
│       
│           Args:
│               exc: The exception to check
│       
│           Returns:
│               True if the error is retryable
│           """
│           if isinstance(exc, InfrastructureError):
│               return exc.retryable
│       
│           # Specific exceptions that are retryable
│           retryable_types = (
│               asyncio.TimeoutError,
│               ConnectionError,
│               RequestTimeoutError,
│           )
│       
│           return isinstance(exc, retryable_types)
│       
│       
│       def with_error_mapping(
│           mappings: dict[Type[Exception], Type[GlamBaseError]],
│           *,
│           default_error: Type[GlamBaseError] = InfrastructureError,
│           default_message: str = "Operation failed",
│       ):
│           """
│           Decorator to automatically map exceptions to domain errors.
│       
│           Example:
│               @with_error_mapping({
│                   FileNotFoundError: NotFoundError,
│                   PermissionError: ForbiddenError,
│               })
│               async def read_file(path: str):
│                   ...
│       
│           Args:
│               mappings: Dict mapping exception types to error classes
│               default_error: Error class for unmapped exceptions
│               default_message: Default message for unmapped errors
│           """
│       
│           def decorator(func: Callable[..., T]) -> Callable[..., T]:
│               @wraps(func)
│               async def async_wrapper(*args, **kwargs):
│                   try:
│                       result = func(*args, **kwargs)
│                       if asyncio.iscoroutine(result):
│                           return await result
│                       return result
│                   except Exception as exc:
│                       # Check if we have a mapping for this exception
│                       for exc_type, error_class in mappings.items():
│                           if isinstance(exc, exc_type):
│                               raise error_class(
│                                   str(exc) or default_message, cause=exc
│                               ) from exc
│       
│                       # No mapping found - use default
│                       if isinstance(exc, GlamBaseError):
│                           # Already our error type - let it bubble
│                           raise
│       
│                       raise default_error(str(exc) or default_message, cause=exc) from exc
│       
│               @wraps(func)
│               def sync_wrapper(*args, **kwargs):
│                   try:
│                       return func(*args, **kwargs)
│                   except Exception as exc:
│                       # Same logic as async version
│                       for exc_type, error_class in mappings.items():
│                           if isinstance(exc, exc_type):
│                               raise error_class(
│                                   str(exc) or default_message, cause=exc
│                               ) from exc
│       
│                       if isinstance(exc, GlamBaseError):
│                           raise
│       
│                       raise default_error(str(exc) or default_message, cause=exc) from exc
│       
│               # Return appropriate wrapper based on function type
│               if asyncio.iscoroutinefunction(func):
│                   return async_wrapper  # type: ignore
│               else:
│                   return sync_wrapper
│       
│           return decorator
│       ```
│       
├── events/
│   ├── catalog/
│   │   ├── __init__.py
│   │   └── types.py
│   │       
│   │       ```py
│   │       from pydantic import BaseModel, Field
│   │       from typing import Dict, Optional, List, Any
│   │       
│   │       from uuid import UUID
│   │       
│   │       
│   │       from ..base import EventWrapper
│   │       
│   │       class CatalogCommands:
│   │           """Catalog command types"""
│   │           CATALOG_SYNC_INITIAL = "cmd.catalog.sync_initial"
│   │           CATALOG_SYNC_UPDATE = "cmd.catalog.sync_update"
│   │           CATALOG_PROCESS_IMAGES = "cmd.catalog.process_images"
│   │           CATALOG_ANALYZE_ITEMS = "cmd.catalog.analyze_items"
│   │           CATALOG_ENRICH_WITH_AI = "cmd.catalog.enrich_with_ai"
│   │           
│   │       class CatalogEvents:
│   │           """Catalog event types"""
│   │           CATALOG_SYNC_STARTED = "evt.catalog.sync_started"
│   │           CATALOG_SYNC_COMPLETED = "evt.catalog.sync_completed"
│   │           CATALOG_SYNC_FAILED = "evt.catalog.sync_failed"
│   │           CATALOG_IMAGES_PROCESSED = "evt.catalog.images_processed"
│   │           CATALOG_ITEMS_ANALYZED = "evt.catalog.items_analyzed"
│   │           CATALOG_AI_ENRICHED = "evt.catalog.ai_enriched"
│   │           
│   │       class CatalogSyncInitialPayload(BaseModel):
│   │           """Payload for initial catalog sync command"""
│   │           merchant_id: UUID
│   │           source: str  # e.g. "shopify", "woocommerce"
│   │           sync_type: str  # e.g. "full", "incremental"
│   │           webhook_url: Optional[str] = None  # Optional webhook for updates
│   │           
│   │       class CatalogSyncUpdatePayload(BaseModel):
│   │           """Payload for catalog sync update command"""
│   │           merchant_id: UUID
│   │           items: List[Dict[str, Any]]  # List of items to update
│   │           job_id: Optional[str] = None  # Optional job ID for tracking
│   │           
│   │       class CatalogProcessImagesPayload(BaseModel):
│   │           """Payload for processing catalog images"""
│   │           merchant_id: UUID
│   │           items: List[Dict[str, Any]]  # List of items with images to process
│   │           job_id: Optional[str] = None  # Optional job ID for tracking
│   │           
│   │       class CatalogAnalyzeItemsPayload(BaseModel):
│   │           """Payload for analyzing catalog items"""
│   │           merchant_id: UUID
│   │           items: List[Dict[str, Any]]  # List of items to analyze
│   │           job_id: Optional[str] = None  # Optional job ID for tracking
│   │           
│   │       class CatalogEnrichWithAIPayload(BaseModel):
│   │           """Payload for enriching catalog with AI"""
│   │           merchant_id: UUID
│   │           items: List[Dict[str, Any]]  # List of items to enrich
│   │           job_id: Optional[str] = None  # Optional job ID for tracking
│   │           
│   │       class CatalogSyncInitialCommand(EventWrapper):
│   │           """Command to initiate initial catalog sync"""
│   │           subject: str = CatalogCommands.CATALOG_SYNC_INITIAL
│   │           data: CatalogSyncInitialPayload
│   │           
│   │       class CatalogSyncUpdateCommand(EventWrapper):
│   │           """Command to update catalog with new items"""
│   │           subject: str = CatalogCommands.CATALOG_SYNC_UPDATE
│   │           data: CatalogSyncUpdatePayload
│   │           
│   │       class CatalogProcessImagesCommand(EventWrapper):
│   │           """Command to process catalog images"""
│   │           subject: str = CatalogCommands.CATALOG_PROCESS_IMAGES
│   │           data: CatalogProcessImagesPayload
│   │           
│   │       class CatalogAnalyzeItemsCommand(EventWrapper):
│   │           """Command to analyze catalog items"""
│   │           subject: str = CatalogCommands.CATALOG_ANALYZE_ITEMS
│   │           data: CatalogAnalyzeItemsPayload
│   │           
│   │       class CatalogEnrichWithAICommand(EventWrapper):
│   │           """Command to enrich catalog with AI"""
│   │           subject: str = CatalogCommands.CATALOG_ENRICH_WITH_AI
│   │           data: CatalogEnrichWithAIPayload
│   │           
│   │       class CatalogSyncStartedEvent(EventWrapper):
│   │           """Event emitted when catalog sync starts"""
│   │           subject: str = CatalogEvents.CATALOG_SYNC_STARTED
│   │           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
│   │           
│   │       class CatalogSyncCompletedEvent(EventWrapper):
│   │           """Event emitted when catalog sync completes"""
│   │           subject: str = CatalogEvents.CATALOG_SYNC_COMPLETED
│   │           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
│   │           
│   │       class CatalogSyncFailedEvent(EventWrapper):
│   │           """Event emitted when catalog sync fails"""
│   │           subject: str = CatalogEvents.CATALOG_SYNC_FAILED
│   │           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
│   │           error_message: Optional[str] = None  # Optional error message for failure
│   │           
│   │       class CatalogImagesProcessedEvent(EventWrapper):
│   │           """Event emitted when catalog images are processed"""
│   │           subject: str = CatalogEvents.CATALOG_IMAGES_PROCESSED
│   │           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
│   │           
│   │       class CatalogItemsAnalyzedEvent(EventWrapper):
│   │           """Event emitted when catalog items are analyzed"""
│   │           subject: str = CatalogEvents.CATALOG_ITEMS_ANALYZED
│   │           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
│   │           
│   │       class CatalogAIEnrichedEvent(EventWrapper):
│   │           """Event emitted when catalog items are enriched with AI"""
│   │           subject: str = CatalogEvents.CATALOG_AI_ENRICHED
│   │           data: Dict[str, Any] = Field(default_factory=dict)  # Additional metadata if needed
│   │           enrichment_details: Optional[Dict[str, Any]] = None  # Optional details about the enrichment process
│   │           
│   │           
│   │       ```
│   │       
│   ├── notification/
│   │   ├── __init__.py
│   │   ├── helpers.py
│   │   │   
│   │   │   ```py
│   │   │   # shared/events/notification/helpers.py
│   │   │   from datetime import datetime, timezone
│   │   │   import hashlib
│   │   │   from typing import Dict, Optional, List, Any
│   │   │   from uuid import UUID
│   │   │   
│   │   │   from ..context import EventContext
│   │   │   from .types import (
│   │   │       Recipient, 
│   │   │       SendEmailBulkCommand, 
│   │   │       SendEmailCommand,
│   │   │   )
│   │   │   
│   │   │   
│   │   │   def create_send_email_command(
│   │   │       shop_id: UUID,
│   │   │       shop_domain: str,
│   │   │       recipient_email: str,
│   │   │       notification_type: str,
│   │   │       dynamic_content: Dict[str, Any],
│   │   │       unsubscribe_token: str,
│   │   │       idempotency_key: Optional[str] = None,
│   │   │       correlation_id: Optional[str] = None,
│   │   │       metadata: Optional[Dict[str, Any]] = None
│   │   │   ) -> Dict[str, Any]:
│   │   │       """
│   │   │       Create a send email command with idempotency support and context.
│   │   │       
│   │   │       If no idempotency_key provided, generates one based on:
│   │   │       - shop_id + notification_type + recipient_email + timestamp (hourly bucket)
│   │   │       This prevents duplicate emails within the same hour.
│   │   │       """
│   │   │       if not idempotency_key:
│   │   │           # Create deterministic key with hourly bucket to prevent duplicates
│   │   │           hour_bucket = datetime.now(timezone.utc).strftime("%Y%m%d%H")
│   │   │           key_data = f"{shop_id}:{notification_type}:{recipient_email}:{hour_bucket}"
│   │   │           idempotency_key = f"send_{hashlib.sha256(key_data.encode()).hexdigest()[:16]}"
│   │   │       
│   │   │       # Create event context
│   │   │       context = EventContext.create(
│   │   │           event_type="cmd.notification.send_email",
│   │   │           source_service=metadata.get('source_service', 'unknown') if metadata else 'unknown',
│   │   │           correlation_id=correlation_id,
│   │   │           idempotency_key=idempotency_key,
│   │   │           metadata=metadata
│   │   │       )
│   │   │       
│   │   │       recipient = Recipient(
│   │   │           shop_id=shop_id,
│   │   │           shop_domain=shop_domain,
│   │   │           email=recipient_email,
│   │   │           unsubscribe_token=unsubscribe_token,
│   │   │           dynamic_content=dynamic_content
│   │   │       )
│   │   │       
│   │   │       command = SendEmailCommand.create_from_context(
│   │   │           context=context,
│   │   │           notification_type=notification_type,
│   │   │           recipient=recipient
│   │   │       )
│   │   │       
│   │   │       return command.to_event_dict()
│   │   │   
│   │   │   
│   │   │   def create_bulk_email_command(
│   │   │       notification_type: str,
│   │   │       recipients: List[Dict[str, Any]],
│   │   │       idempotency_key: Optional[str] = None,
│   │   │       correlation_id: Optional[str] = None,
│   │   │       metadata: Optional[Dict[str, Any]] = None
│   │   │   ) -> Dict[str, Any]:
│   │   │       """
│   │   │       Create a bulk email command with idempotency support and context.
│   │   │       
│   │   │       If no idempotency_key provided, generates one based on:
│   │   │       - notification_type + recipient_count + timestamp
│   │   │       """
│   │   │       if not idempotency_key:
│   │   │           # Create unique key for this bulk operation
│   │   │           timestamp = datetime.now(timezone.utc).isoformat()
│   │   │           key_data = f"bulk:{notification_type}:{len(recipients)}:{timestamp}"
│   │   │           idempotency_key = f"bulk_{hashlib.sha256(key_data.encode()).hexdigest()[:16]}"
│   │   │       
│   │   │       # Create event context
│   │   │       context = EventContext.create(
│   │   │           event_type="cmd.notification.bulk_send",
│   │   │           source_service=metadata.get('source_service', 'unknown') if metadata else 'unknown',
│   │   │           correlation_id=correlation_id,
│   │   │           idempotency_key=idempotency_key,
│   │   │           metadata=metadata
│   │   │       )
│   │   │       
│   │   │       # Convert recipient dicts to typed objects
│   │   │       typed_recipients = [
│   │   │           Recipient(
│   │   │               shop_id=r["shop_id"],
│   │   │               shop_domain=r["shop_domain"],
│   │   │               email=r["email"],
│   │   │               unsubscribe_token=r["unsubscribe_token"],
│   │   │               dynamic_content=r.get("dynamic_content", {})
│   │   │           )
│   │   │           for r in recipients
│   │   │       ]
│   │   │       
│   │   │       command = SendEmailBulkCommand.create_from_context(
│   │   │           context=context,
│   │   │           notification_type=notification_type,
│   │   │           recipients=typed_recipients
│   │   │       )
│   │   │       
│   │   │       return command.to_event_dict()
│   │   │   ```
│   │   │   
│   │   └── types.py
│   │       
│   │       ```py
│   │       # shared/events/notification/types.py
│   │       from pydantic import BaseModel, Field
│   │       from typing import Dict, List, Any
│   │       from datetime import datetime
│   │       from uuid import UUID
│   │       
│   │       from ..base import EventWrapper  # Now generic
│   │       from ..context import EventContext  # Keep this!
│   │       
│   │       
│   │       class NotificationCommands:
│   │           """Notification command types"""
│   │           NOTIFICATION_SEND_EMAIL = "cmd.notification.send_email"
│   │           NOTIFICATION_SEND_BULK = "cmd.notification.bulk_send"
│   │       
│   │       
│   │       class NotificationEvents:
│   │           """Notification event types"""
│   │           NOTIFICATION_EMAIL_SENT = "evt.notification.email.sent"
│   │           NOTIFICATION_EMAIL_FAILED = "evt.notification.email.failed"
│   │           NOTIFICATION_BULK_SEND_COMPLETED = "evt.notification.bulk_send.completed"
│   │       
│   │       
│   │       class Recipient(BaseModel):
│   │           shop_id: UUID
│   │           shop_domain: str
│   │           email: str
│   │           unsubscribe_token: str
│   │           dynamic_content: Dict[str, Any] = Field(default_factory=dict)
│   │       
│   │       
│   │       class SendEmailCommandPayload(BaseModel):
│   │           """Payload for sending a single email"""
│   │           notification_type: str
│   │           recipient: Recipient
│   │       
│   │       
│   │       class SendEmailBulkCommandPayload(BaseModel):
│   │           """Payload for sending bulk emails by notification type"""
│   │           notification_type: str
│   │           recipients: List[Recipient]
│   │       
│   │       
│   │       # Event payloads remain the same
│   │       class EmailSentEventPayload(BaseModel):
│   │           """Payload for NOTIFICATION_EMAIL_SENT event"""
│   │           notification_id: UUID
│   │           shop_id: UUID
│   │           notification_type: str
│   │           provider: str
│   │           provider_message_id: str
│   │           sent_at: datetime
│   │           metadata: Dict[str, Any] = Field(default_factory=dict)
│   │           
│   │           class Config:
│   │               json_encoders = {
│   │                   UUID: str,
│   │                   datetime: lambda v: v.isoformat()
│   │               }
│   │       
│   │       
│   │       class EmailFailedEventPayload(BaseModel):
│   │           """Payload for NOTIFICATION_EMAIL_FAILED event"""
│   │           notification_id: UUID
│   │           shop_id: UUID
│   │           notification_type: str
│   │           error: str
│   │           error_code: str
│   │           retry_count: int
│   │           will_retry: bool
│   │           failed_at: datetime
│   │       
│   │       
│   │       class BulkCompletedEventPayload(BaseModel):
│   │           """Payload for bulk send completion"""
│   │           bulk_job_id: UUID
│   │           notification_type: str
│   │           total_recipients: int
│   │           total_sent: int
│   │           total_failed: int
│   │           total_skipped: int
│   │           duration_seconds: float
│   │           completed_at: datetime
│   │       
│   │       
│   │       # Enhanced command wrappers that integrate with EventContext
│   │       # The only change is adding the Generic type parameter [PayloadType]
│   │       class SendEmailCommand(EventWrapper[SendEmailCommandPayload]):
│   │           """Command to send a single email"""
│   │           subject: str = NotificationCommands.NOTIFICATION_SEND_EMAIL
│   │           
│   │           @classmethod
│   │           def create_from_context(
│   │               cls,
│   │               context: EventContext,  # Still using context!
│   │               notification_type: str,
│   │               recipient: Recipient
│   │           ) -> "SendEmailCommand":
│   │               """Create command with context"""
│   │               return cls(
│   │                   subject=cls.subject,
│   │                   idempotency_key=context.idempotency_key,
│   │                   event_id=context.event_id,
│   │                   correlation_id=context.correlation_id,
│   │                   timestamp=context.timestamp,
│   │                   metadata=context.metadata,
│   │                   data=SendEmailCommandPayload(
│   │                       notification_type=notification_type,
│   │                       recipient=recipient
│   │                   )
│   │               )
│   │       
│   │       
│   │       class SendEmailBulkCommand(EventWrapper[SendEmailBulkCommandPayload]):
│   │           """Command to send bulk emails with same notification type"""
│   │           subject: str = NotificationCommands.NOTIFICATION_SEND_BULK
│   │           
│   │           @classmethod
│   │           def create_from_context(
│   │               cls,
│   │               context: EventContext,  # Still using context!
│   │               notification_type: str,
│   │               recipients: List[Recipient]
│   │           ) -> "SendEmailBulkCommand":
│   │               """Create bulk command with context"""
│   │               return cls(
│   │                   subject=cls.subject,
│   │                   idempotency_key=context.idempotency_key,
│   │                   event_id=context.event_id,
│   │                   correlation_id=context.correlation_id,
│   │                   timestamp=context.timestamp,
│   │                   metadata=context.metadata,
│   │                   data=SendEmailBulkCommandPayload(
│   │                       notification_type=notification_type,
│   │                       recipients=recipients
│   │                   )
│   │               )
│   │       
│   │       
│   │       # Enhanced event wrappers
│   │       class EmailSentEvent(EventWrapper[EmailSentEventPayload]):
│   │           """Event emitted when an email is successfully sent"""
│   │           subject: str = NotificationEvents.NOTIFICATION_EMAIL_SENT
│   │           
│   │           @classmethod
│   │           def create_from_context(
│   │               cls,
│   │               context: EventContext,  # Still using context!
│   │               payload: EmailSentEventPayload
│   │           ) -> "EmailSentEvent":
│   │               """Create event with context"""
│   │               return cls(
│   │                   subject=cls.subject,
│   │                   idempotency_key=context.idempotency_key,
│   │                   event_id=context.event_id,
│   │                   correlation_id=context.correlation_id,
│   │                   timestamp=context.timestamp,
│   │                   metadata=context.metadata,
│   │                   data=payload
│   │               )
│   │       
│   │       
│   │       class EmailDeliveryFailedEvent(EventWrapper[EmailFailedEventPayload]):
│   │           """Event emitted when email delivery fails"""
│   │           subject: str = NotificationEvents.NOTIFICATION_EMAIL_FAILED
│   │           
│   │           @classmethod
│   │           def create_from_context(
│   │               cls,
│   │               context: EventContext,  # Still using context!
│   │               payload: EmailFailedEventPayload
│   │           ) -> "EmailDeliveryFailedEvent":
│   │               """Create event with context"""
│   │               return cls(
│   │                   subject=cls.subject,
│   │                   idempotency_key=context.idempotency_key,
│   │                   event_id=context.event_id,
│   │                   correlation_id=context.correlation_id,
│   │                   timestamp=context.timestamp,
│   │                   metadata=context.metadata,
│   │                   data=payload
│   │               )
│   │       
│   │       
│   │       class BulkSendCompletedEvent(EventWrapper[BulkCompletedEventPayload]):
│   │           """Event emitted when a bulk email send operation completes"""
│   │           subject: str = NotificationEvents.NOTIFICATION_BULK_SEND_COMPLETED
│   │           
│   │           @classmethod
│   │           def create_from_context(
│   │               cls,
│   │               context: EventContext,  # Still using context!
│   │               payload: BulkCompletedEventPayload
│   │           ) -> "BulkSendCompletedEvent":
│   │               """Create event with context"""
│   │               return cls(
│   │                   subject=cls.subject,
│   │                   idempotency_key=context.idempotency_key,
│   │                   event_id=context.event_id,
│   │                   correlation_id=context.correlation_id,
│   │                   timestamp=context.timestamp,
│   │                   metadata=context.metadata,
│   │                   data=payload
│   │               )
│   │       ```
│   │       
│   ├── __init__.py
│   │   
│   │   ```py
│   │   # shared/events/__init__.py
│   │   """
│   │   Shared event handling module for glam-app microservices.
│   │   
│   │   This module provides:
│   │   - Event type definitions and stream mapping
│   │   - Base publisher/subscriber classes
│   │   - Event context management
│   │   - Stream configuration
│   │   """
│   │   
│   │   from .base import (
│   │       Streams,
│   │       EventWrapper,
│   │       # EventDefinition removed
│   │   )
│   │   
│   │   from .context import (
│   │       EventContext,
│   │       EventPayload,
│   │       EventContextManager,
│   │   )
│   │   
│   │   from .base_publisher import DomainEventPublisher
│   │   from .base_subscriber import DomainEventSubscriber
│   │   
│   │   from .mappers import (
│   │       # EVENT_REGISTRY removed
│   │       SERVICE_STREAM_MAP,
│   │       get_stream_subjects,
│   │       get_stream_for_service,
│   │       get_stream_from_event_type,
│   │   )
│   │   
│   │   __all__ = [
│   │       # Base types
│   │       "Streams",
│   │       "EventWrapper",
│   │       
│   │       # Context management
│   │       "EventContext",
│   │       "EventPayload", 
│   │       "EventContextManager",
│   │       
│   │       # Publishers/Subscribers
│   │       "DomainEventPublisher",
│   │       "DomainEventSubscriber",
│   │       
│   │       # Mappers
│   │       "SERVICE_STREAM_MAP",
│   │       "get_stream_subjects",
│   │       "get_stream_for_service",
│   │       "get_stream_from_event_type",
│   │   ]
│   │   ```
│   │   
│   ├── base.py
│   │   
│   │   ```py
│   │   # shared/events/base.py
│   │   from pydantic import BaseModel, Field
│   │   from typing import Dict, Optional, List, Any, TypeVar, Generic
│   │   from datetime import datetime
│   │   from uuid import UUID
│   │   from enum import Enum
│   │   
│   │   from .context import EventContext
│   │   
│   │   # Generic type for event data
│   │   TData = TypeVar("TData", bound=BaseModel)
│   │   
│   │   
│   │   class Streams(str, Enum):
│   │       """JetStream streams organized by domain"""
│   │       
│   │       # Core Business Domains
│   │       CATALOG = "CATALOG"               # Catalog management
│   │       MERCHANT = "MERCHANT"             # Merchant management
│   │       BILLING = "BILLING"               # Billing management
│   │       CREDIT = "CREDIT"                 # Credit management
│   │       
│   │       # User & Identity
│   │       AUTH = "AUTH"                     # Authentication & authorization
│   │       PROFILE = "PROFILE"               # Merchant users profiles
│   │       
│   │       # Platform Services
│   │       NOTIFICATION = "NOTIFICATION"     # Notification delivery
│   │       ANALYTICS = "ANALYTICS"           # Analytics and reporting
│   │       WEBHOOKS = "WEBHOOKS"            # Webhook delivery
│   │       SCHEDULER = "SCHEDULER"           # Scheduled jobs
│   │       RATE_LIMIT = "RATE_LIMIT"        # Rate limiting events
│   │       
│   │       # AI Services
│   │       AI_PROCESSING = "AI_PROCESSING"   # AI/ML processing tasks
│   │   
│   │   
│   │   class EventWrapper(BaseModel, Generic[TData]):
│   │       """Base wrapper for all events with context support"""
│   │       subject: str
│   │       idempotency_key: Optional[str] = None
│   │       
│   │       # Context fields
│   │       event_id: Optional[str] = None
│   │       correlation_id: Optional[str] = None
│   │       timestamp: Optional[datetime] = None
│   │       metadata: Optional[Dict[str, Any]] = None
│   │       
│   │       # Data field is now generic
│   │       data: TData
│   │       
│   │       class Config:
│   │           json_encoders = {
│   │               UUID: str,
│   │               datetime: lambda v: v.isoformat()
│   │           }
│   │   
│   │       @classmethod
│   │       def from_context(
│   │           cls,
│   │           context: EventContext,
│   │           data: TData,
│   │           subject: Optional[str] = None
│   │       ) -> "EventWrapper[TData]":
│   │           """Create EventWrapper from EventContext and data"""
│   │           if not subject:
│   │               subject = context.event_type
│   │               
│   │           return cls(
│   │               subject=subject,
│   │               idempotency_key=context.idempotency_key,
│   │               event_id=context.event_id,
│   │               correlation_id=context.correlation_id,
│   │               timestamp=context.timestamp,
│   │               metadata=context.metadata,
│   │               data=data
│   │           )
│   │       
│   │       def to_event_dict(self) -> Dict[str, Any]:
│   │           """Convert to event dictionary for publishing"""
│   │           return {
│   │               'event_id': self.event_id,
│   │               'event_type': self.subject,
│   │               'correlation_id': self.correlation_id,
│   │               'idempotency_key': self.idempotency_key,
│   │               'timestamp': self.timestamp.isoformat() if self.timestamp else None,
│   │               'metadata': self.metadata or {},
│   │               'payload': self.data.model_dump() if isinstance(self.data, BaseModel) else {}
│   │           }
│   │   ```
│   │   
│   ├── base_publisher.py
│   │   
│   │   ```py
│   │   
│   │   from typing import Dict, Any, Optional
│   │   
│   │   from .base import Streams
│   │   from .mappers import get_stream_from_event_type, get_stream_subjects
│   │   from shared.messaging.publisher import JetStreamEventPublisher
│   │   
│   │   
│   │   class DomainEventPublisher(JetStreamEventPublisher):
│   │       """
│   │       Smart publisher that:
│   │       1. Auto-configures streams based on domain
│   │       2. Validates events belong to the correct stream
│   │       3. Provides domain-specific helpers
│   │       """
│   │       
│   │       # Concrete classes just set these two properties
│   │       domain_stream: Optional[Streams] = None
│   │       service_name_override: Optional[str] = None
│   │   
│   │       @property
│   │       def stream_name(self) -> str:
│   │           """Auto-determined from domain_stream"""
│   │           if not self.domain_stream:
│   │               raise NotImplementedError("domain_stream must be set")
│   │           return self.domain_stream.value
│   │       
│   │       @property
│   │       def subjects(self) -> list[str]:
│   │           """Auto-determined from domain_stream"""
│   │           if not self.domain_stream:
│   │               raise NotImplementedError("domain_stream must be set")
│   │           return get_stream_subjects(self.domain_stream)
│   │       
│   │       @property
│   │       def service_name(self) -> str:
│   │           """Uses override or defaults"""
│   │           return self.service_name_override or "unknown-service"
│   │       
│   │       def _validate_event_type(self, event_type: str):
│   │           """
│   │           Ensures you can't accidentally publish a billing event 
│   │           from the catalog service
│   │           """
│   │           try:
│   │               # Try to infer stream from event type
│   │               inferred_stream = get_stream_from_event_type(event_type)
│   │               if inferred_stream != self.domain_stream:
│   │                   raise ValueError(
│   │                       f"Event {event_type} belongs to {inferred_stream}, "
│   │                       f"not {self.domain_stream}"
│   │                   )
│   │           except ValueError:
│   │               # For events not following standard pattern, check prefix matches subjects
│   │               if not any(event_type.startswith(subj.replace('*', '')) 
│   │                       for subj in self.subjects):
│   │                   raise ValueError(
│   │                       f"Event {event_type} doesn't match any subject pattern "
│   │                       f"for stream {self.domain_stream}"
│   │                   )
│   │       
│   │       async def publish_event(
│   │           self,
│   │           event_type: str,
│   │           payload: Dict[str, Any],
│   │           subject: Optional[str] = None,
│   │           correlation_id: Optional[str] = None,
│   │           idempotency_key: Optional[str] = None,
│   │           metadata: Optional[Dict[str, Any]] = None
│   │       ) -> str:
│   │           """Override with same signature, adds validation"""
│   │           self._validate_event_type(event_type)
│   │           
│   │           # Call parent with all parameters
│   │           return await super().publish_event(
│   │               event_type=event_type,
│   │               payload=payload,
│   │               subject=subject,
│   │               correlation_id=correlation_id,
│   │               idempotency_key=idempotency_key,
│   │               metadata=metadata
│   │           )
│   │       
│   │       async def publish_command(
│   │           self, 
│   │           command_type: str, 
│   │           payload: Dict[str, Any], 
│   │           **kwargs
│   │       ) -> str:
│   │           """Override to add validation"""
│   │           # Ensure command format
│   │           if not command_type.startswith('cmd.'):
│   │               command_type = f'cmd.{command_type}'
│   │           
│   │           self._validate_event_type(command_type)
│   │           
│   │           return await super().publish_command(command_type, payload, **kwargs)
│   │       
│   │       async def publish_event_response(
│   │           self, 
│   │           event_type: str, 
│   │           payload: Dict[str, Any], 
│   │           **kwargs
│   │       ) -> str:
│   │           """Override to add validation"""
│   │           # Ensure event format
│   │           if not event_type.startswith('evt.'):
│   │               event_type = f'evt.{event_type}'
│   │           
│   │           self._validate_event_type(event_type)
│   │           
│   │           return await super().publish_event_response(event_type, payload, **kwargs)
│   │   ```
│   │   
│   ├── base_subscriber.py
│   │   
│   │   ```py
│   │   # File: shared/shared/events/base_subscriber.py
│   │   from .mappers import get_stream_from_event_type
│   │   from shared.messaging.subscriber import JetStreamEventSubscriber
│   │   
│   │   
│   │   class DomainEventSubscriber(JetStreamEventSubscriber):
│   │       """
│   │       Smart subscriber that:
│   │       1. Auto-determines stream from event type
│   │       2. Provides helpers for cross-domain subscriptions
│   │       3. Validates event structure
│   │       """
│   │       
│   │       @property
│   │       def stream_name(self) -> str:
│   │           """Auto-determine stream from event type"""
│   │           try:
│   │               stream = get_stream_from_event_type(self.event_type)
│   │               return stream.value
│   │           except ValueError:
│   │               # For events not following standard pattern, must override
│   │               return self._stream_name_override()
│   │       
│   │       def _stream_name_override(self) -> str:
│   │           """Override when subscribing to events not following standard pattern"""
│   │           raise NotImplementedError(
│   │               f"Event {self.event_type} doesn't follow standard pattern, "
│   │               f"must override _stream_name_override"
│   │           )
│   │   ```
│   │   
│   ├── context.py
│   │   
│   │   ```py
│   │   # shared/events/context.py
│   │   """
│   │   Standardized event context management for all services.
│   │   
│   │   Provides consistent context handling for event-driven architecture.
│   │   """
│   │   
│   │   from typing import Dict, Any, Optional, TypeVar, Generic
│   │   from dataclasses import dataclass
│   │   from datetime import datetime, timezone
│   │   from uuid import uuid4
│   │   
│   │   from ..api.correlation import set_correlation_context, get_correlation_context
│   │   
│   │   T = TypeVar('T')
│   │   
│   │   
│   │   @dataclass
│   │   class EventContext:
│   │       """Standard context for all events across the platform"""
│   │       event_id: str
│   │       event_type: str
│   │       correlation_id: Optional[str]
│   │       timestamp: datetime
│   │       source_service: str
│   │       idempotency_key: Optional[str] = None
│   │       version: str = "1.0"
│   │       metadata: Optional[Dict[str, Any]] = None
│   │       
│   │       def __post_init__(self):
│   │           if self.metadata is None:
│   │               self.metadata = {}
│   │       
│   │       @classmethod
│   │       def from_event(cls, event: Dict[str, Any]) -> "EventContext":
│   │           """Extract context from incoming event"""
│   │           return cls(
│   │               event_id=event.get('event_id', ''),
│   │               event_type=event.get('event_type', ''),
│   │               correlation_id=event.get('correlation_id'),
│   │               timestamp=datetime.fromisoformat(
│   │                   event.get('timestamp', datetime.now(timezone.utc).isoformat())
│   │               ),
│   │               source_service=event.get('metadata', {}).get('source_service', 'unknown'),
│   │               idempotency_key=event.get('idempotency_key'),
│   │               version=event.get('metadata', {}).get('version', '1.0'),
│   │               metadata=event.get('metadata', {})
│   │           )
│   │       
│   │       @classmethod
│   │       def create(
│   │           cls,
│   │           event_type: str,
│   │           source_service: str,
│   │           correlation_id: Optional[str] = None,
│   │           idempotency_key: Optional[str] = None,
│   │           metadata: Optional[Dict[str, Any]] = None
│   │       ) -> "EventContext":
│   │           """Create new event context"""
│   │           # Use existing correlation if available
│   │           if not correlation_id:
│   │               correlation_id = get_correlation_context()
│   │               
│   │           return cls(
│   │               event_id=f"evt_{uuid4().hex[:12]}",
│   │               event_type=event_type,
│   │               correlation_id=correlation_id,
│   │               timestamp=datetime.now(timezone.utc),
│   │               source_service=source_service,
│   │               idempotency_key=idempotency_key,
│   │               version="1.0",
│   │               metadata=metadata or {}
│   │           )
│   │       
│   │       def to_dict(self) -> Dict[str, Any]:
│   │           """Convert context to dictionary for logging or serialization"""
│   │           return {
│   │               'event_id': self.event_id,
│   │               'event_type': self.event_type,
│   │               'correlation_id': self.correlation_id,
│   │               'timestamp': self.timestamp.isoformat(),
│   │               'source_service': self.source_service,
│   │               'idempotency_key': self.idempotency_key,
│   │               'version': self.version,
│   │               **(self.metadata or {})
│   │           }
│   │       
│   │       def apply_correlation(self):
│   │           """Apply correlation context to async context"""
│   │           if self.correlation_id:
│   │               set_correlation_context(self.correlation_id)
│   │       
│   │       def create_response_context(
│   │           self,
│   │           response_event_type: str,
│   │           response_service: str,
│   │           idempotency_key: Optional[str] = None,
│   │           additional_metadata: Optional[Dict[str, Any]] = None
│   │       ) -> "EventContext":
│   │           """Create context for response events, preserving correlation chain"""
│   │           metadata = {
│   │               'triggered_by': self.event_id,
│   │               'original_source': self.source_service,
│   │               **(additional_metadata or {})
│   │           }
│   │           
│   │           return EventContext.create(
│   │               event_type=response_event_type,
│   │               source_service=response_service,
│   │               correlation_id=self.correlation_id,  # Preserve correlation
│   │               idempotency_key=idempotency_key,
│   │               metadata=metadata
│   │           )
│   │   
│   │   
│   │   @dataclass
│   │   class EventPayload(Generic[T]):
│   │       """Wrapper for typed event payloads with context"""
│   │       context: EventContext
│   │       data: T
│   │       
│   │       @property
│   │       def correlation_id(self) -> Optional[str]:
│   │           return self.context.correlation_id
│   │       
│   │       def to_event_dict(self) -> Dict[str, Any]:
│   │           """Convert to event dictionary for publishing"""
│   │           return {
│   │               'event_id': self.context.event_id,
│   │               'event_type': self.context.event_type,
│   │               'correlation_id': self.context.correlation_id,
│   │               'idempotency_key': self.context.idempotency_key,
│   │               'timestamp': self.context.timestamp.isoformat(),
│   │               'metadata': {
│   │                   'source_service': self.context.source_service,
│   │                   'version': self.context.version,
│   │                   **(self.context.metadata or {})
│   │               },
│   │               'payload': self.data if isinstance(self.data, dict) else {}
│   │           }
│   │   
│   │   
│   │   class EventContextManager:
│   │       """
│   │       Manages event context throughout processing lifecycle.
│   │       
│   │       This can be used by any service that processes events.
│   │       """
│   │       
│   │       def __init__(self, logger=None):
│   │           self.logger = logger
│   │       
│   │       def extract_context(self, event: Dict[str, Any]) -> EventContext:
│   │           """Extract and validate event context"""
│   │           context = EventContext.from_event(event)
│   │           
│   │           # Validate required fields
│   │           if not context.event_id and self.logger:
│   │               self.logger.warning("Event missing event_id", extra={'event': event})
│   │           
│   │           if not context.event_type:
│   │               raise ValueError("Event missing required event_type")
│   │           
│   │           # Apply correlation context
│   │           context.apply_correlation()
│   │           
│   │           # Log event reception
│   │           if self.logger:
│   │               self.logger.info(
│   │                   f"Processing {context.event_type} event",
│   │                   extra=context.to_dict()
│   │               )
│   │           
│   │           return context
│   │       
│   │       def log_event_completion(
│   │           self,
│   │           context: EventContext,
│   │           success: bool,
│   │           duration_ms: float,
│   │           error: Optional[Exception] = None,
│   │           additional_data: Optional[Dict[str, Any]] = None
│   │       ):
│   │           """Log event processing completion"""
│   │           if not self.logger:
│   │               return
│   │               
│   │           log_data = {
│   │               **context.to_dict(),
│   │               'success': success,
│   │               'duration_ms': duration_ms,
│   │               **(additional_data or {})
│   │           }
│   │           
│   │           if success:
│   │               self.logger.info(
│   │                   f"Completed processing {context.event_type}",
│   │                   extra=log_data
│   │               )
│   │           else:
│   │               self.logger.error(
│   │                   f"Failed to process {context.event_type}: {error}",
│   │                   extra={
│   │                       **log_data,
│   │                       'error_type': type(error).__name__ if error else 'Unknown'
│   │                   },
│   │                   exc_info=error
│   │               )
│   │   
│   │   
│   │   # Backwards compatibility imports
│   │   __all__ = [
│   │       'EventContext',
│   │       'EventPayload',
│   │       'EventContextManager'
│   │   ]
│   │   ```
│   │   
│   ├── mappers.py
│   │   
│   │   ```py
│   │   # shared/events/mappers.py
│   │   from typing import List
│   │   from .base import Streams
│   │   
│   │   # Simple service to stream mapping
│   │   SERVICE_STREAM_MAP = {
│   │       "analytics-service": Streams.ANALYTICS,
│   │       "auth-service": Streams.AUTH,
│   │       "billing-service": Streams.BILLING,
│   │       "catalog-ai-service": Streams.AI_PROCESSING,
│   │       "catalog-connector": Streams.CATALOG,
│   │       "catalog-image-cache": Streams.CATALOG,
│   │       "catalog-job-processor": Streams.CATALOG,
│   │       "catalog-service": Streams.CATALOG,
│   │       "credit-service": Streams.CREDIT,
│   │       "merchant-service": Streams.MERCHANT,
│   │       "notification-service": Streams.NOTIFICATION,
│   │       "profile-ai-selfie": Streams.AI_PROCESSING,
│   │       "profile-service": Streams.PROFILE,
│   │       "rate-limit-service": Streams.RATE_LIMIT,
│   │       "scheduler-service": Streams.SCHEDULER,
│   │       "webhook-service": Streams.WEBHOOKS,
│   │   }
│   │   
│   │   
│   │   def get_stream_subjects(stream: Streams) -> List[str]:
│   │       """Get all subjects for a stream"""
│   │       stream_prefix = stream.value.lower()
│   │       return [
│   │           f"cmd.{stream_prefix}.*",
│   │           f"evt.{stream_prefix}.*"
│   │       ]
│   │   
│   │   
│   │   def get_stream_for_service(service_name: str) -> Streams:
│   │       """Get the stream for a service"""
│   │       if service_name not in SERVICE_STREAM_MAP:
│   │           raise ValueError(f"Unknown service: {service_name}")
│   │       return SERVICE_STREAM_MAP[service_name]
│   │   
│   │   
│   │   def get_stream_from_event_type(event_type: str) -> Streams:
│   │       """
│   │       Infer stream from event type.
│   │       Event types follow pattern: cmd.domain.* or evt.domain.*
│   │       """
│   │       parts = event_type.split(".")
│   │       if len(parts) >= 2 and parts[0] in ["cmd", "evt"]:
│   │           domain = parts[1].upper()
│   │           if hasattr(Streams, domain):
│   │               return Streams[domain]
│   │       
│   │       raise ValueError(f"Cannot infer stream from event type: {event_type}")
│   │   
│   │   # EVENT_REGISTRY and related functions removed - no longer needed
│   │   ```
│   │   
│   └── types.py
│       
│       ```py
│       # shared/events/notification/types.py
│       from pydantic import BaseModel, Field
│       from typing import Dict, List, Any
│       from datetime import datetime
│       from uuid import UUID
│       
│       from shared.events.base import EventWrapper
│       from shared.events.context import EventContext
│       
│       
│       class NotificationCommands:
│           """Notification command types"""
│           NOTIFICATION_SEND_EMAIL = "cmd.notification.send_email"
│           NOTIFICATION_SEND_BULK = "cmd.notification.bulk_send"
│       
│       
│       class NotificationEvents:
│           """Notification event types"""
│           NOTIFICATION_EMAIL_SENT = "evt.notification.email.sent"
│           NOTIFICATION_EMAIL_FAILED = "evt.notification.email.failed"
│           NOTIFICATION_BULK_SEND_COMPLETED = "evt.notification.bulk_send.completed"
│       
│       
│       class Recipient(BaseModel):
│           shop_id: UUID
│           shop_domain: str
│           email: str
│           unsubscribe_token: str
│           dynamic_content: Dict[str, Any] = Field(default_factory=dict)
│       
│       
│       class SendEmailCommandPayload(BaseModel):
│           """Payload for sending a single email"""
│           notification_type: str
│           recipient: Recipient
│       
│       
│       class SendEmailBulkCommandPayload(BaseModel):
│           """Payload for sending bulk emails by notification type"""
│           notification_type: str
│           recipients: List[Recipient]
│       
│       
│       # Event payloads
│       class EmailSentEventPayload(BaseModel):
│           """Payload for NOTIFICATION_EMAIL_SENT event"""
│           notification_id: UUID
│           shop_id: UUID
│           notification_type: str
│           provider: str
│           provider_message_id: str
│           sent_at: datetime
│           metadata: Dict[str, Any] = Field(default_factory=dict)
│           
│           class Config:
│               json_encoders = {
│                   UUID: str,
│                   datetime: lambda v: v.isoformat()
│               }
│       
│       
│       class EmailFailedEventPayload(BaseModel):
│           """Payload for NOTIFICATION_EMAIL_FAILED event"""
│           notification_id: UUID
│           shop_id: UUID
│           notification_type: str
│           error: str
│           error_code: str
│           retry_count: int
│           will_retry: bool
│           failed_at: datetime
│       
│       
│       class BulkCompletedEventPayload(BaseModel):
│           """Payload for bulk send completion"""
│           bulk_job_id: UUID
│           notification_type: str
│           total_recipients: int
│           total_sent: int
│           total_failed: int
│           total_skipped: int
│           duration_seconds: float
│           completed_at: datetime
│       
│       
│       # Now use the generic EventWrapper with specific payload types
│       class SendEmailCommand(EventWrapper[SendEmailCommandPayload]):
│           """Command to send a single email"""
│           subject: str = NotificationCommands.NOTIFICATION_SEND_EMAIL
│           
│           @classmethod
│           def create_from_context(
│               cls,
│               context: EventContext,
│               notification_type: str,
│               recipient: Recipient
│           ) -> "SendEmailCommand":
│               """Create command with context"""
│               return cls(
│                   subject=cls.subject,
│                   idempotency_key=context.idempotency_key,
│                   event_id=context.event_id,
│                   correlation_id=context.correlation_id,
│                   timestamp=context.timestamp,
│                   metadata=context.metadata,
│                   data=SendEmailCommandPayload(
│                       notification_type=notification_type,
│                       recipient=recipient
│                   )
│               )
│       
│       
│       class SendEmailBulkCommand(EventWrapper[SendEmailBulkCommandPayload]):
│           """Command to send bulk emails with same notification type"""
│           subject: str = NotificationCommands.NOTIFICATION_SEND_BULK
│           
│           @classmethod
│           def create_from_context(
│               cls,
│               context: EventContext,
│               notification_type: str,
│               recipients: List[Recipient]
│           ) -> "SendEmailBulkCommand":
│               """Create bulk command with context"""
│               return cls(
│                   subject=cls.subject,
│                   idempotency_key=context.idempotency_key,
│                   event_id=context.event_id,
│                   correlation_id=context.correlation_id,
│                   timestamp=context.timestamp,
│                   metadata=context.metadata,
│                   data=SendEmailBulkCommandPayload(
│                       notification_type=notification_type,
│                       recipients=recipients
│                   )
│               )
│       
│       
│       class EmailSentEvent(EventWrapper[EmailSentEventPayload]):
│           """Event emitted when an email is successfully sent"""
│           subject: str = NotificationEvents.NOTIFICATION_EMAIL_SENT
│           
│           @classmethod
│           def create_from_context(
│               cls,
│               context: EventContext,
│               payload: EmailSentEventPayload
│           ) -> "EmailSentEvent":
│               """Create event with context"""
│               return cls(
│                   subject=cls.subject,
│                   idempotency_key=context.idempotency_key,
│                   event_id=context.event_id,
│                   correlation_id=context.correlation_id,
│                   timestamp=context.timestamp,
│                   metadata=context.metadata,
│                   data=payload
│               )
│       
│       
│       class EmailDeliveryFailedEvent(EventWrapper[EmailFailedEventPayload]):
│           """Event emitted when email delivery fails"""
│           subject: str = NotificationEvents.NOTIFICATION_EMAIL_FAILED
│           
│           @classmethod
│           def create_from_context(
│               cls,
│               context: EventContext,
│               payload: EmailFailedEventPayload
│           ) -> "EmailDeliveryFailedEvent":
│               """Create event with context"""
│               return cls(
│                   subject=cls.subject,
│                   idempotency_key=context.idempotency_key,
│                   event_id=context.event_id,
│                   correlation_id=context.correlation_id,
│                   timestamp=context.timestamp,
│                   metadata=context.metadata,
│                   data=payload
│               )
│       
│       
│       class BulkSendCompletedEvent(EventWrapper[BulkCompletedEventPayload]):
│           """Event emitted when a bulk email send operation completes"""
│           subject: str = NotificationEvents.NOTIFICATION_BULK_SEND_COMPLETED
│           
│           @classmethod
│           def create_from_context(
│               cls,
│               context: EventContext,
│               payload: BulkCompletedEventPayload
│           ) -> "BulkSendCompletedEvent":
│               """Create event with context"""
│               return cls(
│                   subject=cls.subject,
│                   idempotency_key=context.idempotency_key,
│                   event_id=context.event_id,
│                   correlation_id=context.correlation_id,
│                   timestamp=context.timestamp,
│                   metadata=context.metadata,
│                   data=payload
│               )
│       ```
│       
├── messaging/
│   ├── __init__.py
│   ├── jetstream_wrapper.py
│   │   
│   │   ```py
│   │   from typing import List, Optional, Dict, Type, Any, TypeVar, cast
│   │   import os
│   │   
│   │   import nats
│   │   from nats.aio.client import Client
│   │   from nats.js import JetStreamContext
│   │   
│   │   from shared.messaging.publisher import JetStreamEventPublisher
│   │   from shared.messaging.subscriber import JetStreamEventSubscriber
│   │   
│   │   T = TypeVar('T', bound=JetStreamEventPublisher)
│   │   
│   │   class JetStreamWrapper:
│   │       """
│   │       JetStream wrapper that manages connection and provides easy access to publishers/subscribers.
│   │       """
│   │       
│   │       def __init__(self, logger: Optional[Any] = None):
│   │           self._client: Optional[Client] = None
│   │           self._js: Optional[JetStreamContext] = None
│   │           self._publishers: Dict[str, JetStreamEventPublisher] = {}
│   │           self._subscribers: List[JetStreamEventSubscriber] = []
│   │           self.logger = logger
│   │       
│   │       @property
│   │       def client(self) -> Client:
│   │           """Get the NATS client (for backward compatibility)"""
│   │           if not self._client:
│   │               raise Exception("NATS client not connected")
│   │           return self._client
│   │       
│   │       @property
│   │       def js(self) -> JetStreamContext:
│   │           """Get the JetStream context"""
│   │           if not self._js:
│   │               raise Exception("JetStream not initialized")
│   │           return self._js
│   │       
│   │       @property
│   │       def publishers(self) -> Dict[str, JetStreamEventPublisher]:
│   │           """Get all registered publishers"""
│   │           return self._publishers
│   │       
│   │       async def connect(self, servers: List[str]):
│   │           """
│   │           Connect to NATS and initialize JetStream.
│   │           
│   │           Args:
│   │               servers: List of NATS server URLs
│   │           """
│   │           try:
│   │               # Connection options
│   │               options = {
│   │                   "servers": servers,
│   │                   "max_reconnect_attempts": -1,
│   │                   "reconnect_time_wait": 2,
│   │               }
│   │               
│   │               # Add authentication if provided
│   │               if user := os.getenv("NATS_USER"):
│   │                   options["user"] = user
│   │                   options["password"] = os.getenv("NATS_PASSWORD", "")
│   │               
│   │               self._client = await nats.connect(**options)
│   │               self._js = self._client.jetstream()
│   │               
│   │               if self.logger:
│   │                   self.logger.info(f"Connected to NATS with JetStream at {servers}")
│   │               
│   │           except Exception as e:
│   │               if self.logger:
│   │                   self.logger.error(f"Failed to connect to NATS: {e}")
│   │               raise
│   │       
│   │       async def close(self):
│   │           """Close the NATS connection and stop all subscribers"""
│   │           # Stop all subscribers first
│   │           for subscriber in self._subscribers:
│   │               try:
│   │                   await subscriber.stop()
│   │               except Exception as e:
│   │                   if self.logger:
│   │                       self.logger.error(f"Error stopping subscriber: {e}")
│   │           
│   │           # Close NATS connection
│   │           if self._client and not self._client.is_closed:
│   │               await self._client.close()
│   │               if self.logger:
│   │                   self.logger.info("NATS connection closed")
│   │       
│   │       def create_publisher(self, publisher_class: Type[T]) -> T:
│   │           """
│   │           Create and cache a publisher instance.
│   │           
│   │           Args:
│   │               publisher_class: The publisher class to instantiate
│   │               
│   │           Returns:
│   │               Publisher instance
│   │           """
│   │           class_name = publisher_class.__name__
│   │           
│   │           if class_name not in self._publishers:
│   │               if not self._client or not self._js:
│   │                   raise Exception("Must connect to NATS before creating publishers")
│   │               
│   │               self._publishers[class_name] = publisher_class(self._client, self._js, self.logger)
│   │               if self.logger:
│   │                   self.logger.info(f"Created publisher: {class_name}")
│   │           
│   │           return cast(T, self._publishers[class_name])
│   │       
│   │       def get_publisher(self, publisher_class: Type[T]) -> Optional[T]:
│   │           """
│   │           Get a publisher by class type.
│   │           
│   │           Args:
│   │               publisher_class: The publisher class to retrieve
│   │               
│   │           Returns:
│   │               Publisher instance if exists, None otherwise
│   │           """
│   │           publisher = self._publishers.get(publisher_class.__name__)
│   │           return cast(T, publisher) if publisher else None
│   │       
│   │       def create_subscriber(self, subscriber_class: Type[JetStreamEventSubscriber]) -> JetStreamEventSubscriber:
│   │           """
│   │           Create a subscriber instance.
│   │           
│   │           Args:
│   │               subscriber_class: The subscriber class to instantiate
│   │               
│   │           Returns:
│   │               Subscriber instance
│   │           """
│   │           if not self._client or not self._js:
│   │               raise Exception("Must connect to NATS before creating subscribers")
│   │           
│   │           subscriber = subscriber_class(self._client, self._js, self.logger)
│   │           self._subscribers.append(subscriber)
│   │           if self.logger:
│   │               self.logger.info(f"Created subscriber: {subscriber_class.__name__}")
│   │           
│   │           return subscriber
│   │       
│   │       async def start_subscriber(self, subscriber_class: Type[JetStreamEventSubscriber]):
│   │           """
│   │           Create and start a subscriber in the background.
│   │           
│   │           Args:
│   │               subscriber_class: The subscriber class to instantiate and start
│   │               
│   │           Returns:
│   │               The asyncio Task running the subscriber
│   │           """
│   │           import asyncio
│   │           
│   │           subscriber = self.create_subscriber(subscriber_class)
│   │           task = asyncio.create_task(subscriber.listen())
│   │           if self.logger:
│   │               self.logger.info(f"Started subscriber: {subscriber_class.__name__}")
│   │           
│   │           return task
│   │   ```
│   │   
│   ├── publisher.py
│   │   
│   │   ```py
│   │   # File: shared/shared/messaging/publisher.py
│   │   import json
│   │   import uuid
│   │   from abc import ABC, abstractmethod
│   │   from typing import Dict, Any, Optional
│   │   from datetime import datetime, timezone
│   │   
│   │   from nats.aio.client import Client
│   │   from nats.js import JetStreamContext
│   │   from nats.js.api import StreamConfig, RetentionPolicy, StorageType
│   │   
│   │   
│   │   class JetStreamEventPublisher(ABC):
│   │       """
│   │       JetStream publisher specifically for structured events.
│   │       Combines base functionality with event structure in one class.
│   │       """
│   │   
│   │       @property
│   │       @abstractmethod
│   │       def stream_name(self) -> str:
│   │           """The JetStream stream name to publish to."""
│   │           pass
│   │   
│   │       @property
│   │       @abstractmethod
│   │       def subjects(self) -> list[str]:
│   │           """List of subjects this stream should handle."""
│   │           pass
│   │   
│   │       @property
│   │       @abstractmethod
│   │       def service_name(self) -> str:
│   │           """The name of the service publishing events."""
│   │           pass
│   │   
│   │       @property
│   │       def service_version(self) -> str:
│   │           """The version of the service."""
│   │           return "1.0.0"
│   │   
│   │       def __init__(self, client: Client, js: JetStreamContext, logger: Optional[Any] = None):
│   │           self.client = client
│   │           self.js = js
│   │           self._stream_created = False
│   │           self.logger = logger or self._get_default_logger()
│   │   
│   │       def _get_default_logger(self):
│   │           """Get a default logger if none provided"""
│   │           import logging
│   │           return logging.getLogger(self.__class__.__name__)
│   │       
│   │       async def ensure_stream(self) -> None:
│   │           """Ensure the stream exists with default configuration."""
│   │           if self._stream_created:
│   │               return
│   │   
│   │           stream_config = StreamConfig(
│   │               name=self.stream_name,
│   │               subjects=self.subjects,
│   │               retention=RetentionPolicy.LIMITS,
│   │               max_age=7 * 24 * 60 * 60,  # 7 days
│   │               max_msgs_per_subject=100000,
│   │               storage=StorageType.FILE,
│   │               duplicate_window=60,
│   │               allow_rollup_hdrs=True,
│   │           )
│   │   
│   │           try:
│   │               await self.js.stream_info(self.stream_name)
│   │               if self.logger:
│   │                   self.logger.info(f"Using existing stream: {self.stream_name}")
│   │           except:
│   │               await self.js.add_stream(stream_config)
│   │               if self.logger:
│   │                   self.logger.info(f"Created new stream: {self.stream_name}")
│   │   
│   │           self._stream_created = True
│   │   
│   │       async def publish_event(
│   │           self,
│   │           event_type: str,
│   │           payload: Dict[str, Any],
│   │           subject: Optional[str] = None,
│   │           correlation_id: Optional[str] = None,
│   │           idempotency_key: Optional[str] = None,
│   │           metadata: Optional[Dict[str, Any]] = None
│   │       ) -> str:
│   │           """Publish a structured event."""
│   │           await self.ensure_stream()
│   │   
│   │           # Generate IDs
│   │           event_id = str(uuid.uuid4())
│   │           if not correlation_id:
│   │               correlation_id = str(uuid.uuid4())
│   │           if not idempotency_key:
│   │               idempotency_key = event_id
│   │   
│   │           # Build event
│   │           event = {
│   │               "event_id": event_id,
│   │               "event_type": event_type,
│   │               "correlation_id": correlation_id,
│   │               "idempotency_key": idempotency_key,
│   │               "timestamp": datetime.now(timezone.utc).isoformat(),
│   │               "metadata": {
│   │                   "source_service": self.service_name,
│   │                   "version": self.service_version,
│   │                   **(metadata or {})
│   │               },
│   │               "payload": payload
│   │           }
│   │   
│   │           # Publish
│   │           subject = subject or event_type
│   │           headers = {"Nats-Msg-Id": idempotency_key}
│   │           
│   │           try:
│   │               ack = await self.js.publish(
│   │                   subject,
│   │                   json.dumps(event).encode("utf-8"),
│   │                   headers=headers
│   │               )
│   │               if self.logger:
│   │                   self.logger.debug(f"Published {event_type} to {subject} (seq: {ack.seq})")
│   │                   
│   │               if ack.duplicate:
│   │                   self.logger.info(
│   │                       f"Duplicate message detected and ignored",
│   │                       extra={"idempotency_key": idempotency_key}
│   │                   )
│   │               return event_id
│   │           
│   │           except Exception as e:
│   │               if self.logger:
│   │                   self.logger.critical(f"Failed to publish to {subject}: {e}", exc_info=True)
│   │               raise
│   │   
│   │       async def publish_command(self, command_type: str, payload: Dict[str, Any], **kwargs) -> str:
│   │           """Publish a command event."""
│   │           if not command_type.startswith('cmd.'):
│   │               command_type = f'cmd.{command_type}'
│   │           
│   │           idempotency_key = kwargs.pop('idempotency_key', None)
│   │   
│   │           return await self.publish_event(event_type=command_type, payload=payload, idempotency_key=idempotency_key, **kwargs)
│   │   
│   │       
│   │       async def publish_event_response(self, event_type: str, payload: Dict[str, Any], **kwargs) -> str:
│   │           """Publish an event response."""
│   │           if not event_type.startswith('evt.'):
│   │               event_type = f'evt.{event_type}'
│   │               
│   │           # Ensure idempotency key is set
│   │           idempotency_key = kwargs.pop('idempotency_key', None)
│   │           
│   │           return await self.publish_event(event_type=event_type, payload=payload, idempotency_key=idempotency_key, **kwargs)
│   │   
│   │   
│   │   ```
│   │   
│   └── subscriber.py
│       
│       ```py
│       # shared/events/subscriber.py
│       import json
│       from abc import ABC, abstractmethod
│       from typing import Dict, Any, Optional
│       import asyncio
│       
│       from nats.aio.client import Client
│       from nats.js import JetStreamContext
│       from nats.js.api import ConsumerConfig, DeliverPolicy, AckPolicy
│       
│       
│       class JetStreamEventSubscriber(ABC):
│           """
│           JetStream subscriber specifically for structured events.
│           Combines base functionality with event handling in one class.
│           """
│       
│           @property
│           @abstractmethod
│           def stream_name(self) -> str:
│               """The JetStream stream name to subscribe to."""
│               pass
│       
│           @property
│           @abstractmethod
│           def subject(self) -> str:
│               """The subject pattern to subscribe to."""
│               pass
│       
│           @property
│           @abstractmethod
│           def durable_name(self) -> str:
│               """The durable consumer name."""
│               pass
│       
│           @property
│           @abstractmethod
│           def event_type(self) -> str:
│               """The expected event_type for validation."""
│               pass
│       
│           def __init__(
│               self, client: Client, js: JetStreamContext, logger: Optional[Any] = None
│           ):
│               self.client = client
│               self.js = js
│               self._subscription = None
│               self.logger = logger or self._get_default_logger()
│               
│               # Debug initialization
│               self.logger.debug(f"Initialized {self.__class__.__name__}")
│               self.logger.debug(f"JetStream context: {self.js is not None}")
│               self.logger.debug(f"NATS client connected: {self.client.is_connected if self.client else False}")
│       
│           def _get_default_logger(self):
│               """Get a default logger if none provided"""
│               import logging
│       
│               return logging.getLogger(self.__class__.__name__)
│       
│           @abstractmethod
│           async def on_event(
│               self, event: Dict[str, Any], headers: Optional[Dict[str, str]] = None
│           )   -> None:
│               """Process the validated event."""
│               pass
│       
│           async def on_error(self, error: Exception, event: Dict[str, Any]) -> bool:
│               """Handle processing errors. Return True to ack, False to retry."""
│               self.logger.error(f"Error processing {self.event_type}: {error}")
│               return False  # Default: retry
│       
│           async def listen(self) -> None:
│               """Subscribe and process messages."""
│       
│               # Consumer config
│               consumer_config = ConsumerConfig(
│                   durable_name=self.durable_name,
│                   deliver_policy=DeliverPolicy.ALL,
│                   ack_policy=AckPolicy.EXPLICIT,
│                   max_deliver=3,
│                   ack_wait=30,
│                   filter_subject=self.subject,
│               )
│       
│               # Create or bind consumer
│               try:
│                   await self.js.consumer_info(self.stream_name, self.durable_name)
│                   self.logger.info(f"Using existing consumer: {self.durable_name}")
│               except:
│                   await self.js.add_consumer(self.stream_name, config=consumer_config)
│                   self.logger.info(f"Created new consumer: {self.durable_name}")
│               
│               # Subscribe
│               try:
│                   self._subscription = await self.js.pull_subscribe(
│                       self.subject, 
│                       durable=self.durable_name, 
│                       stream=self.stream_name
│                   )
│                   
│                   if self._subscription is None:
│                       raise Exception("Failed to create subscription")
│                       
│                   self.logger.info(f"Listening on {self.stream_name}/{self.subject}")
│                   
│                   error_count = 0
│                   max_errors = 2
│                   
│                   # Process messages
│                   while True:
│                       try:
│                           # Check subscription is still valid
│                           if self._subscription is None:
│                               self.logger.error("Subscription is None, reconnecting...")
│                               await asyncio.sleep(5)
│                               # Try to resubscribe
│                               self._subscription = await self.js.pull_subscribe(
│                                   self.subject, 
│                                   durable=self.durable_name, 
│                                   stream=self.stream_name
│                               )
│                               continue
│                           
│                           messages = await self._subscription.fetch(batch=10, timeout=1)
│                           error_count = 0  # Reset error count on success
│                           for msg in messages:
│                               await self._process_message(msg)
│                           
│                           
│                               
│                       except asyncio.TimeoutError:
│                           # This is normal - no messages available
│                           continue
│                       except Exception as e:
│                           error_count += 1
│                           if error_count > max_errors:
│                               self.logger.error("Too many errors, stopping subscriber")
│                               break
│                           
│               except Exception as e:
│                   self.logger.error(f"Failed to create subscription: {e}")
│                   raise
│       
│           async def _process_message(self, msg) -> None:
│               """Process a single message with error handling."""
│               try:
│                   # Parse message
│                   try:
│                       data = json.loads(msg.data.decode("utf-8"))
│                   except json.JSONDecodeError as e:
│                       self.logger.error(f"Invalid JSON: {e}")
│                       await msg.ack()
│                       return
│       
│                   # Validate structure
│                   required = ["event_id", "event_type", "timestamp", "payload"]
│                   if missing := [f for f in required if f not in data]:
│                       self.logger.error(f"Missing fields: {missing}")
│                       await msg.ack()
│                       return
│       
│                   # Validate event type
│                   if self.event_type and data.get("event_type") != self.event_type:
│                       self.logger.warning(
│                           f"Wrong event type: expected {self.event_type}, got {data.get('event_type')}"
│                       )
│                       await msg.ack()
│                       return
│       
│                   # Extract headers
│                   headers = {}
│                   if msg.headers:
│                       headers = {
│                           k: v[0] if isinstance(v, list) else v
│                           for k, v in msg.headers.items()
│                       }
│       
│                   # Process event
│                   try:
│                       await self.on_event(data, headers)
│                       await msg.ack()
│                   except Exception as e:
│                       should_ack = await self.on_error(e, data)
│                       if should_ack:
│                           await msg.ack()
│       
│               except Exception as e:
│                   self.logger.critical(f"Fatal error processing message: {e}", exc_info=True)
│                   try:
│                       await msg.ack()  # Prevent poison messages
│                   except:
│                       pass
│       
│           async def stop(self) -> None:
│               """Stop listening."""
│               if self._subscription:
│                   await self._subscription.unsubscribe()
│                   self._subscription = None
│       ```
│       
├── metrics/
│   ├── __init__.py
│   │   
│   │   ```py
│   │   
│   │   # -------------------------------
│   │   # shared/metrics/__init__.py
│   │   # -------------------------------
│   │   
│   │   """Prometheus metrics utilities for microservices."""
│   │   
│   │   from .middleware import (
│   │       PrometheusMiddleware,
│   │       metrics_endpoint,
│   │       http_requests_total,
│   │       http_request_duration_seconds,
│   │       http_requests_in_progress,
│   │   )
│   │   
│   │   __all__ = [
│   │       "PrometheusMiddleware",
│   │       "metrics_endpoint",
│   │       "http_requests_total",
│   │       "http_request_duration_seconds",
│   │       "http_requests_in_progress",
│   │   ]
│   │   ```
│   │   
│   └── middleware.py
│       
│       ```py
│       # -------------------------------
│       # shared/metrics/middleware.py
│       # -------------------------------
│       
│       """
│       Prometheus metrics middleware for all services.
│       
│       Provides standard HTTP metrics and allows services to register
│       their own domain-specific metrics.
│       """
│       
│       import time
│       import re
│       from typing import Dict, Any, Optional, Callable
│       from fastapi import Request
│       from starlette.middleware.base import BaseHTTPMiddleware
│       from starlette.responses import Response
│       from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
│       
│       # Standard HTTP metrics for all services
│       http_requests_total = Counter(
│           'http_requests_total',
│           'Total HTTP requests',
│           ['service', 'method', 'endpoint', 'status']
│       )
│       
│       http_request_duration_seconds = Histogram(
│           'http_request_duration_seconds',
│           'HTTP request duration in seconds',
│           ['service', 'method', 'endpoint']
│       )
│       
│       http_requests_in_progress = Gauge(
│           'http_requests_in_progress',
│           'HTTP requests in progress',
│           ['service']
│       )
│       
│       
│       class PrometheusMiddleware(BaseHTTPMiddleware):
│           """Prometheus metrics collection middleware."""
│           
│           def __init__(self, app, service_name: str):
│               super().__init__(app)
│               self.service_name = service_name
│           
│           async def dispatch(self, request: Request, call_next):
│               # Skip metrics endpoint to avoid recursion
│               if request.url.path == "/metrics":
│                   return await call_next(request)
│               
│               # Get method and normalize path
│               method = request.method
│               path = self._normalize_path(request.url.path)
│               
│               # Track in-progress requests
│               http_requests_in_progress.labels(service=self.service_name).inc()
│               
│               # Time the request
│               start_time = time.time()
│               
│               try:
│                   response = await call_next(request)
│                   status_code = response.status_code
│                   
│                   # Record success metrics
│                   self._record_metrics(method, path, status_code, start_time)
│                   
│                   return response
│                   
│               except Exception as e:
│                   # Record failure metrics
│                   self._record_metrics(method, path, 500, start_time)
│                   raise
│               finally:
│                   http_requests_in_progress.labels(service=self.service_name).dec()
│           
│           def _record_metrics(self, method: str, path: str, status: int, start_time: float):
│               """Record HTTP metrics."""
│               http_requests_total.labels(
│                   service=self.service_name,
│                   method=method,
│                   endpoint=path,
│                   status=status
│               ).inc()
│               
│               http_request_duration_seconds.labels(
│                   service=self.service_name,
│                   method=method,
│                   endpoint=path
│               ).observe(time.time() - start_time)
│           
│           def _normalize_path(self, path: str) -> str:
│               """Normalize paths to prevent high cardinality."""
│               # Replace UUIDs
│               path = re.sub(
│                   r'[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}',
│                   '{id}',
│                   path
│               )
│               # Replace numeric IDs
│               path = re.sub(r'/\d+', '/{id}', path)
│               return path
│       
│       
│       async def metrics_endpoint(request: Request) -> Response:
│           """Endpoint to expose Prometheus metrics."""
│           return Response(
│               content=generate_latest(),
│               media_type=CONTENT_TYPE_LATEST
│           )
│       
│       ```
│       
├── utils/
│   ├── __init__.py
│   └── logger.py
│       
│       ```py
│       # shared/utils/logger.py
│       import logging
│       import logging.handlers
│       import os
│       import json
│       from datetime import datetime
│       from typing import Dict, Any
│       from pathlib import Path
│       from contextvars import ContextVar
│       
│       
│       # Context variable for request-scoped data
│       request_context: ContextVar[Dict[str, Any]] = ContextVar('request_context', default={})
│       
│       
│       class ServiceLogger:
│           """
│           Service-specific logger that automatically includes service name and request context.
│           """
│           
│           def __init__(self, service_name: str):
│               self.service_name = service_name
│               self._setup_logging()
│               self._logger = logging.getLogger(service_name)
│           
│           def _setup_logging(self):
│               """Configure logging for this service"""
│               env = os.getenv("APP_ENV", "dev").lower()
│               log_level = os.getenv("LOG_LEVEL", "INFO").upper()
│               print(f"Setting up logger for {self.service_name} in {env} environment with level {log_level}")
│               
│               # Create logs directory
│               Path("logs").mkdir(exist_ok=True)
│               
│               # Configure formatters based on environment
│               if env == "prod":
│                   formatter = JsonFormatter(self.service_name)
│               else:
│                   formatter = ConsoleFormatter(self.service_name)
│               
│               # Set up handlers
│               console_handler = logging.StreamHandler()
│               console_handler.setFormatter(formatter)
│               console_handler.setLevel(log_level)
│               
│               # Configure the service logger
│               logger = logging.getLogger(self.service_name)
│               logger.setLevel(log_level)
│               logger.addHandler(console_handler)
│               
│               # Add file handler for production
│               if env == "prod":
│                   file_handler = logging.handlers.RotatingFileHandler(
│                       f"logs/{self.service_name}.log",
│                       maxBytes=10485760,  # 10MB
│                       backupCount=5,
│                       encoding='utf8'
│                   )
│                   file_handler.setFormatter(formatter)
│                   file_handler.setLevel(logging.INFO)
│                   logger.addHandler(file_handler)
│               
│               # Prevent propagation to avoid duplicate logs
│               logger.propagate = False
│           
│           def set_request_context(self, **kwargs):
│               """Set request-scoped context (e.g., request_id, user_id)"""
│               ctx = request_context.get()
│               ctx.update(kwargs)
│               request_context.set(ctx)
│           
│           def clear_request_context(self):
│               """Clear request context"""
│               request_context.set({})
│           
│           def _log(self, level: int, msg: str, *args, **kwargs):
│               """Internal log method that adds context"""
│               # Get request context
│               ctx = request_context.get()
│               
│               # Add context to extra
│               extra = kwargs.get('extra', {})
│               extra.update(ctx)
│               kwargs['extra'] = extra
│               
│               self._logger.log(level, msg, *args, **kwargs)
│           
│           def debug(self, msg: str, *args, **kwargs):
│               self._log(logging.DEBUG, msg, *args, **kwargs)
│           
│           def info(self, msg: str, *args, **kwargs):
│               self._log(logging.INFO, msg, *args, **kwargs)
│           
│           def warning(self, msg: str, *args, **kwargs):
│               self._log(logging.WARNING, msg, *args, **kwargs)
│           
│           def error(self, msg: str, *args, **kwargs):
│               self._log(logging.ERROR, msg, *args, **kwargs)
│           
│           def critical(self, msg: str, *args, **kwargs):
│               self._log(logging.CRITICAL, msg, *args, **kwargs)
│       
│       
│       class ConsoleFormatter(logging.Formatter):
│           """Console formatter that includes service name and request context"""
│           
│           def __init__(self, service_name: str):
│               self.service_name = service_name
│               super().__init__()
│           
│           def format(self, record):
│               # Build context string from extra fields
│               context_parts = []
│               request_id = getattr(record, 'request_id', None)
│               if request_id is not None:
│                   context_parts.append(f"request_id={request_id}")
│               user_id = getattr(record, 'user_id', None)
│               if user_id is not None:
│                   context_parts.append(f"user_id={user_id}")
│               
│               # Add any other extra fields
│               for key in record.__dict__:
│                   if key not in ['name', 'msg', 'args', 'created', 'filename', 'funcName',
│                                 'levelname', 'levelno', 'lineno', 'module', 'msecs',
│                                 'pathname', 'process', 'processName', 'relativeCreated',
│                                 'thread', 'threadName', 'exc_info', 'exc_text', 'stack_info',
│                                 'message', 'getMessage', 'request_id', 'user_id']:
│                       context_parts.append(f"{key}={getattr(record, key)}")
│               
│               # Format: 2024-01-15 10:30:45 - funding-service - INFO - [request_id=123] Processing order
│               timestamp = datetime.fromtimestamp(record.created).strftime('%Y-%m-%d %H:%M:%S')
│               
│               message = f"{timestamp} - {self.service_name} - {record.levelname}"
│               if context_parts:
│                   message += f" - [{' '.join(context_parts)}]"
│               message += f" - {record.getMessage()}"
│               
│               if record.exc_info:
│                   message += '\n' + self.formatException(record.exc_info)
│               
│               return message
│       
│       
│       class JsonFormatter(logging.Formatter):
│           """JSON formatter for production"""
│           
│           def __init__(self, service_name: str):
│               self.service_name = service_name
│               super().__init__()
│           
│           def format(self, record):
│               log_data = {
│                   "timestamp": datetime.utcnow().isoformat(),
│                   "service": self.service_name,
│                   "level": record.levelname,
│                   "message": record.getMessage(),
│                   "environment": os.getenv("APP_ENV", "dev"),
│               }
│               
│               # Add request context from extra
│               request_id = getattr(record, 'request_id', None)
│               if request_id is not None:
│                   log_data['request_id'] = request_id
│               user_id = getattr(record, 'user_id', None)
│               if user_id is not None:
│                   log_data['user_id'] = user_id
│               
│               # Add any other extra fields
│               for key in record.__dict__:
│                   if key not in ['name', 'msg', 'args', 'created', 'filename', 'funcName',
│                                 'levelname', 'levelno', 'lineno', 'module', 'msecs',
│                                 'pathname', 'process', 'processName', 'relativeCreated',
│                                 'thread', 'threadName', 'exc_info', 'exc_text', 'stack_info',
│                                 'message', 'getMessage', 'request_id', 'user_id']:
│                       log_data[key] = getattr(record, key)
│               
│               # Add exception if present
│               if record.exc_info:
│                   log_data['exception'] = self.formatException(record.exc_info)
│               
│               return json.dumps(log_data)
│       
│       
│       # Factory function to create service logger
│       def create_logger(service_name: str) -> ServiceLogger:
│           """
│           Create a logger for a specific service.
│           
│           Args:
│               service_name: Name of the service
│               
│           Returns:
│               ServiceLogger instance
│           """
│           return ServiceLogger(service_name)
│       
│       
│       # ============ USAGE ============
│       
│       """
│       USAGE:
│       
│       1. In your service initialization (main.py or app.py):
│       ```python
│       from shared.utils.logger import create_logger
│       
│       # Create service-specific logger
│       logger = create_logger("funding-service")
│       ```
│       
│       2. Basic logging:
│       ```python
│       logger.info("Service started")
│       logger.error("Connection failed", extra={"host": "localhost", "port": 5432})
│       ```
│       
│       3. In FastAPI middleware or request handler:
│       ```python
│       @app.middleware("http")
│       async def add_request_context(request: Request, call_next):
│           # Set request context for all logs in this request
│           logger.set_request_context(
│               request_id=request.headers.get("X-Request-ID", str(uuid.uuid4())),
│               method=request.method,
│               path=request.url.path
│           )
│           
│           logger.info("Request started")
│           response = await call_next(request)
│           logger.info("Request completed", extra={"status_code": response.status_code})
│           
│           # Clear context after request
│           logger.clear_request_context()
│           return response
│       ```
│       
│       4. In any route or service method:
│       ```python
│       @app.post("/api/orders")
│       async def create_order(order: Order, user_id: str = Depends(get_current_user)):
│           # Add user context
│           logger.set_request_context(user_id=user_id)
│           
│           logger.info("Creating order", extra={"order_id": order.id})
│           # ... business logic ...
│           logger.info("Order created successfully")
│       ```
│       
│       5. Output examples:
│       
│       Development:
│       2024-01-15 10:30:45 - funding-service - INFO - [request_id=abc123 user_id=456] - Creating order
│       
│       Production (JSON):
│       {"timestamp": "2024-01-15T10:30:45.123Z", "service": "funding-service", "level": "INFO", "message": "Creating order", "request_id": "abc123", "user_id": "456", "order_id": "789"}
│       """
│       ```
│       
└── __init__.py
tests/
└── __init__.py
.python-version
poetry.lock
pyproject.toml

```toml
# shared/pyproject.toml
[tool.poetry]
name = "shared"
version = "0.1.0"
description = "Shared utilities for GLAM system services"
authors = ["GLAM Team <team@glam.com>"]

[tool.poetry.dependencies]
python = "^3.11"
nats-py = "^2.6.0"
pydantic = "^2.5.0"
python-json-logger = "^2.0.7"
redis = "^5.0.1"
tenacity = "^8.2.3"
alembic = "^1.16.2"
pydantic-settings = "^2.10.1"
asyncio = "^3.4.3"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"
```

README.md

================================================================================
Output includes file contents
================================================================================