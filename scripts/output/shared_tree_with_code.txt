================================================================================
Directory Structure: /home/bellabe/glam-app/shared/shared
================================================================================

shared/
api/
â”œâ”€â”€ __init__.py
â”‚   
â”‚   ```py
â”‚   # -------------------------------
â”‚   # shared/api/__init__.py
â”‚   # -------------------------------
â”‚   
â”‚   """
â”‚   Unified API response models and utilities for glam-app microservices.
â”‚   
â”‚   This module provides a single, consistent approach to API responses
â”‚   across all services.
â”‚   """
â”‚   
â”‚   from .debug import (
â”‚       setup_debug_handlers,
â”‚       # Debugging utilities
â”‚       setup_debug_middleware,
â”‚   )
â”‚   from .dependencies import (
â”‚       ClientAuthDep,
â”‚       InternalAuthDep,
â”‚       LoggerDep,
â”‚       PaginationDep,
â”‚       RequestContextDep,
â”‚       WebhookHeadersDep,
â”‚   )
â”‚   from .health import (
â”‚       # Health check utilities
â”‚       create_health_router,
â”‚   )
â”‚   from .middleware import (
â”‚       # Middleware
â”‚       APIMiddleware,
â”‚       setup_middleware,
â”‚   )
â”‚   from .models import (
â”‚       # Core models
â”‚       ApiResponse,
â”‚       ErrorDetail,
â”‚       Links,
â”‚       Meta,
â”‚       Pagination,
â”‚   )
â”‚   from .responses import (
â”‚       # Response helpers
â”‚       create_response,
â”‚       error_response,
â”‚       paginated_response,
â”‚       success_response,
â”‚   )
â”‚   from .validation import validate_shop_context
â”‚   
â”‚   __all__ = [
â”‚       "ApiResponse",
â”‚       "Meta",
â”‚       "Pagination",
â”‚       "Links",
â”‚       "ErrorDetail",
â”‚       "create_response",
â”‚       "success_response",
â”‚       "error_response",
â”‚       "paginated_response",
â”‚       "ClientAuthDep",
â”‚       "InternalAuthDep",
â”‚       "LoggerDep",
â”‚       "PaginationDep",
â”‚       "RequestContextDep",
â”‚       "WebhookHeadersDep",
â”‚       "setup_debug_middleware",
â”‚       "setup_debug_handlers",
â”‚       "APIMiddleware",
â”‚       "setup_middleware",
â”‚       "create_health_router",
â”‚       "validate_shop_context",
â”‚   ]
â”‚   ```
â”‚   
â”œâ”€â”€ debug.py
â”‚   
â”‚   ```py
â”‚   # shared/api/debug.py
â”‚   # ruff: noqa: T201
â”‚   """Debug utilities for FastAPI applications."""
â”‚   
â”‚   import json
â”‚   import logging
â”‚   from collections.abc import Callable
â”‚   
â”‚   from fastapi import FastAPI, HTTPException, Request
â”‚   from fastapi.exceptions import RequestValidationError
â”‚   from fastapi.responses import JSONResponse
â”‚   from starlette.middleware.base import BaseHTTPMiddleware
â”‚   
â”‚   logger = logging.getLogger(__name__)
â”‚   
â”‚   
â”‚   class EarlyDebugMiddleware(BaseHTTPMiddleware):
â”‚       """Debug middleware that runs before any dependencies or validation."""
â”‚   
â”‚       async def dispatch(self, request: Request, call_next: Callable):
â”‚           print("\n" + "=" * 60)
â”‚           print("ðŸ” EARLY DEBUG - REQUEST RECEIVED")
â”‚           print("=" * 60)
â”‚   
â”‚           # Log all request details
â”‚           print(f"ðŸŒ URL: {request.url}")
â”‚           print(f"ðŸ“ Path: {request.url.path}")
â”‚           print(f"ðŸ”§ Method: {request.method}")
â”‚           print(f"â“ Query Params: {dict(request.query_params)}")
â”‚   
â”‚           # Log all headers
â”‚           print("ðŸ“‹ Headers:")
â”‚           for name, value in request.headers.items():
â”‚               # Mask authorization for security
â”‚               if name.lower() == "authorization":
â”‚                   value = f"Bearer {value[7:17]}..." if value.startswith("Bearer ") else "***"
â”‚               print(f"   {name}: {value}")
â”‚   
â”‚           # Log body for POST/PUT/PATCH WITHOUT consuming it
â”‚           body_logged = False
â”‚           if request.method in ["POST", "PUT", "PATCH"]:
â”‚               try:
â”‚                   # Read body once and store it
â”‚                   body = await request.body()
â”‚                   if body:
â”‚                       try:
â”‚                           body_json = json.loads(body)
â”‚                           print("ðŸ“¦ Body (JSON):")
â”‚                           print(json.dumps(body_json, indent=2))
â”‚                           body_logged = True
â”‚                       except json.JSONDecodeError:
â”‚                           body_str = body.decode("utf-8", errors="ignore")
â”‚                           print(f"ðŸ“¦ Body (Raw): {body_str[:200]}{'...' if len(body_str) > 200 else ''}")
â”‚                           body_logged = True
â”‚                   else:
â”‚                       print("ðŸ“¦ Body: (empty)")
â”‚                       body_logged = True
â”‚   
â”‚               except Exception as e:
â”‚                   print(f"ðŸ“¦ Body: (error reading: {e})")
â”‚   
â”‚           if not body_logged:
â”‚               print("ðŸ“¦ Body: (no body for GET request)")
â”‚   
â”‚           print("â³ Calling next middleware/handler...")
â”‚           print("=" * 60)
â”‚   
â”‚           try:
â”‚               response = await call_next(request)
â”‚   
â”‚               print("\n" + "=" * 60)
â”‚               print("âœ… EARLY DEBUG - RESPONSE READY")
â”‚               print("=" * 60)
â”‚               print(f"ðŸ“¤ Status: {response.status_code}")
â”‚               print(f"ðŸ“¤ Headers: {dict(response.headers)}")
â”‚               print("=" * 60 + "\n")
â”‚   
â”‚               return response
â”‚   
â”‚           except Exception as e:
â”‚               print("\n" + "=" * 60)
â”‚               print("âŒ EARLY DEBUG - EXCEPTION CAUGHT")
â”‚               print("=" * 60)
â”‚               print(f"ðŸ’¥ Exception Type: {type(e).__name__}")
â”‚               print(f"ðŸ’¥ Exception Message: {e!s}")
â”‚               print(f"ðŸ’¥ Exception Details: {getattr(e, 'detail', 'No details')}")
â”‚               if hasattr(e, "status_code"):
â”‚                   print(f"ðŸ’¥ Status Code: {e.status_code}")
â”‚               print("=" * 60 + "\n")
â”‚               raise  # Re-raise to let other handlers deal with it
â”‚   
â”‚   
â”‚   def setup_debug_middleware(app: FastAPI):
â”‚       """Add debug middleware as the first middleware."""
â”‚       app.add_middleware(EarlyDebugMiddleware)
â”‚   
â”‚   
â”‚   def setup_debug_handlers(app: FastAPI):
â”‚       """Add debug exception handlers to catch errors before middleware."""
â”‚   
â”‚       @app.exception_handler(RequestValidationError)
â”‚       async def validation_exception_handler(request: Request, exc: RequestValidationError):
â”‚           """Debug validation errors in detail."""
â”‚   
â”‚           print("=" * 50)
â”‚           print("ðŸš¨ VALIDATION ERROR CAUGHT!")
â”‚           print("=" * 50)
â”‚   
â”‚           # Log request details
â”‚           print(f"ðŸ“¥ Request URL: {request.url}")
â”‚           print(f"ðŸ“¥ Request Method: {request.method}")
â”‚           print("ðŸ“¥ Request Headers:")
â”‚           for name, value in request.headers.items():
â”‚               print(f"   {name}: {value}")
â”‚   
â”‚           # Log request body if available
â”‚           try:
â”‚               if request.method in ["POST", "PUT", "PATCH"]:
â”‚                   # Try to get body (might be consumed already)
â”‚                   body = await request.body()
â”‚                   if body:
â”‚                       try:
â”‚                           body_json = json.loads(body)
â”‚                           print(f"ðŸ“¥ Request Body (JSON): {json.dumps(body_json, indent=2)}")
â”‚                       except Exception:
â”‚                           print(f"ðŸ“¥ Request Body (Raw): {body.decode('utf-8', errors='ignore')[:500]}...")
â”‚                   else:
â”‚                       print("ðŸ“¥ Request Body: (empty)")
â”‚           except Exception as e:
â”‚               print(f"ðŸ“¥ Request Body: (error reading: {e})")
â”‚   
â”‚           # Log validation errors in detail
â”‚           print(f"âŒ Validation Errors ({len(exc.errors())} total):")
â”‚           for i, error in enumerate(exc.errors()):
â”‚               print(f"   {i + 1}. Field: {error.get('loc', 'unknown')}")
â”‚               print(f"      Type: {error.get('type', 'unknown')}")
â”‚               print(f"      Message: {error.get('msg', 'unknown')}")
â”‚               print(f"      Input: {error.get('input', 'not provided')}")
â”‚               print()
â”‚   
â”‚           print("=" * 50)
â”‚   
â”‚           # Return structured error response
â”‚           validation_errors = []
â”‚           for error in exc.errors():
â”‚               field_path = ".".join(str(loc) for loc in error["loc"])
â”‚               validation_errors.append(
â”‚                   {"field": field_path, "message": error["msg"], "type": error["type"], "input": error.get("input")}
â”‚               )
â”‚   
â”‚           return JSONResponse(
â”‚               status_code=422,
â”‚               content={
â”‚                   "error": {
â”‚                       "code": "VALIDATION_ERROR",
â”‚                       "message": "Request validation failed",
â”‚                       "details": {"validation_errors": validation_errors, "total_errors": len(validation_errors)},
â”‚                   }
â”‚               },
â”‚           )
â”‚   
â”‚       @app.exception_handler(HTTPException)
â”‚       async def http_exception_handler(request: Request, exc: HTTPException):
â”‚           """Debug HTTP exceptions."""
â”‚   
â”‚           print("=" * 50)
â”‚           print(f"ðŸš¨ HTTP EXCEPTION: {exc.status_code}")
â”‚           print("=" * 50)
â”‚           print(f"ðŸ“¥ Request URL: {request.url}")
â”‚           print(f"ðŸ“¥ Request Method: {request.method}")
â”‚           print(f"âŒ Exception Detail: {exc.detail}")
â”‚           print(f"âŒ Exception Type: {type(exc.detail)}")
â”‚           print("=" * 50)
â”‚   
â”‚           # Let your middleware handle this
â”‚           raise exc
â”‚   
â”‚       @app.exception_handler(Exception)
â”‚       async def general_exception_handler(request: Request, exc: Exception):
â”‚           """Catch any other exceptions."""
â”‚   
â”‚           print("=" * 50)
â”‚           print(f"ðŸš¨ GENERAL EXCEPTION: {type(exc).__name__}")
â”‚           print("=" * 50)
â”‚           print(f"ðŸ“¥ Request URL: {request.url}")
â”‚           print(f"ðŸ“¥ Request Method: {request.method}")
â”‚           print(f"âŒ Exception: {exc}")
â”‚           print("=" * 50)
â”‚   
â”‚           # Let your middleware handle this
â”‚           raise exc
â”‚   ```
â”‚   
â”œâ”€â”€ dependencies.py
â”‚   
â”‚   ```py
â”‚   """
â”‚   FastAPI dependencies for standardized API behavior.
â”‚   Clean, generic, production-ready dependencies.
â”‚   """
â”‚   
â”‚   import os
â”‚   import uuid
â”‚   from typing import TYPE_CHECKING, Annotated
â”‚   
â”‚   import jwt
â”‚   from fastapi import Depends, HTTPException, Query, Request, status
â”‚   from pydantic import BaseModel, Field
â”‚   
â”‚   if TYPE_CHECKING:
â”‚       from shared.utils.logger import ServiceLogger
â”‚   
â”‚   
â”‚   # Pagination
â”‚   class PaginationParams(BaseModel):
â”‚       """Standard pagination parameters."""
â”‚   
â”‚       page: int = Field(default=1, ge=1)
â”‚       limit: int = Field(default=50, ge=1, le=1000)
â”‚   
â”‚       @property
â”‚       def offset(self) -> int:
â”‚           return (self.page - 1) * self.limit
â”‚   
â”‚   
â”‚   def get_pagination_params(
â”‚       page: int = Query(1, ge=1, description="Page number"),
â”‚       limit: int = Query(50, ge=1, le=1000, description="Items per page"),
â”‚   ) -> PaginationParams:
â”‚       return PaginationParams(page=page, limit=limit)
â”‚   
â”‚   
â”‚   PaginationDep = Annotated[PaginationParams, Depends(get_pagination_params)]
â”‚   
â”‚   
â”‚   # Logger
â”‚   def get_logger(request: Request) -> "ServiceLogger":
â”‚       return request.app.state.logger
â”‚   
â”‚   
â”‚   LoggerDep = Annotated["ServiceLogger", Depends(get_logger)]
â”‚   
â”‚   
â”‚   # Request Context Utilities
â”‚   def get_correlation_id(request: Request) -> str:
â”‚       return request.headers.get("X-Correlation-ID", f"corr_{uuid.uuid4().hex[:12]}")
â”‚   
â”‚   
â”‚   def get_client_ip(request: Request) -> str:
â”‚       forwarded_for = request.headers.get("X-Forwarded-For")
â”‚       if forwarded_for:
â”‚           return forwarded_for.split(",")[0].strip()
â”‚       return request.client.host if request.client else "unknown"
â”‚   
â”‚   
â”‚   def get_content_type(request: Request) -> str | None:
â”‚       return request.headers.get("Content-Type")
â”‚   
â”‚   
â”‚   class RequestContext(BaseModel):
â”‚       """Essential request context for logging/auditing."""
â”‚   
â”‚       correlation_id: str
â”‚       method: str
â”‚       path: str
â”‚       content_type: str | None = None
â”‚       ip_client: str | None = None
â”‚   
â”‚       @classmethod
â”‚       def from_request(cls, request: Request) -> "RequestContext":
â”‚           return cls(
â”‚               correlation_id=get_correlation_id(request),
â”‚               method=request.method,
â”‚               path=str(request.url.path),
â”‚               ip_client=get_client_ip(request),
â”‚               content_type=get_content_type(request),
â”‚           )
â”‚   
â”‚   
â”‚   def get_request_context(request: Request) -> RequestContext:
â”‚       return RequestContext.from_request(request)
â”‚   
â”‚   
â”‚   RequestContextDep = Annotated[RequestContext, Depends(get_request_context)]
â”‚   
â”‚   
â”‚   # Platform headers
â”‚   SUPPORTED_PLATFORMS = {"shopify", "bigcommerce", "woocommerce", "magento", "squarespace", "custom"}
â”‚   
â”‚   
â”‚   # Authentication
â”‚   class ClientAuthContext(BaseModel):
â”‚       shop: str
â”‚       scope: str
â”‚       token: str
â”‚   
â”‚       @property
â”‚       def audience(self) -> str:
â”‚           return "client"
â”‚   
â”‚   
â”‚   class InternalAuthContext(BaseModel):
â”‚       service: str
â”‚       token: str
â”‚   
â”‚       @property
â”‚       def audience(self) -> str:
â”‚           return "internal"
â”‚   
â”‚   
â”‚   def _get_bearer_token(request: Request) -> str:
â”‚       auth = request.headers.get("Authorization")
â”‚       if not auth or not auth.lower().startswith("bearer "):
â”‚           raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Missing bearer token")
â”‚       return auth.split(" ", 1)[1].strip()
â”‚   
â”‚   
â”‚   def require_client_auth(request: Request) -> ClientAuthContext:
â”‚       token = _get_bearer_token(request)
â”‚       secret = os.getenv("CLIENT_JWT_SECRET", "")
â”‚       if not secret:
â”‚           raise RuntimeError("CLIENT_JWT_SECRET not configured")
â”‚   
â”‚       try:
â”‚           payload = jwt.decode(token, secret, algorithms=["HS256"])
â”‚       except jwt.PyJWTError as e:
â”‚           raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=f"Invalid JWT: {e!s}") from e
â”‚   
â”‚       return ClientAuthContext(
â”‚           shop=payload.get("sub", ""),
â”‚           scope=payload.get("scope", ""),
â”‚           token=token,
â”‚       )
â”‚   
â”‚   
â”‚   def require_internal_auth(request: Request) -> InternalAuthContext:
â”‚       token = _get_bearer_token(request)
â”‚       raw = os.getenv("INTERNAL_JWT_SECRET", "")
â”‚       if not raw:
â”‚           raise RuntimeError("INTERNAL_JWT_SECRET not configured")
â”‚   
â”‚       allowed = {}
â”‚       for entry in raw.split(","):
â”‚           entry = entry.strip()
â”‚           if not entry:
â”‚               continue
â”‚           if ":" in entry:
â”‚               service, key = entry.split(":", 1)
â”‚               allowed[key.strip()] = service.strip()
â”‚           else:
â”‚               allowed[entry] = "unknown"
â”‚   
â”‚       if token not in allowed:
â”‚           raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail="Invalid bearer token")
â”‚   
â”‚       return InternalAuthContext(service=allowed[token], token=token)
â”‚   
â”‚   
â”‚   ClientAuthDep = Annotated[ClientAuthContext, Depends(require_client_auth)]
â”‚   InternalAuthDep = Annotated[InternalAuthContext, Depends(require_internal_auth)]
â”‚   
â”‚   
â”‚   # Webhooks
â”‚   class WebhookHeaders(BaseModel):
â”‚       topic: str
â”‚       webhook_id: str | None = None
â”‚   
â”‚       @property
â”‚       def event_type(self) -> str:
â”‚           return self.topic.replace("/", ".").replace("_", ".")
â”‚   
â”‚   
â”‚   def get_webhook_headers(request: Request) -> WebhookHeaders:
â”‚       topic = request.headers.get("X-Webhook-Topic")
â”‚       if not topic:
â”‚           raise HTTPException(
â”‚               status_code=status.HTTP_400_BAD_REQUEST,
â”‚               detail={
â”‚                   "code": "MISSING_WEBHOOK_TOPIC",
â”‚                   "message": "Missing required webhook topic header",
â”‚                   "details": {"expected_header": "X-Webhook-Topic"},
â”‚               },
â”‚           )
â”‚   
â”‚       if len(topic) > 256:
â”‚           raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="X-Webhook-Topic too long")
â”‚   
â”‚       webhook_id = request.headers.get("X-Webhook-Id")
â”‚       if webhook_id and len(webhook_id) > 256:
â”‚           raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="X-Webhook-Id too long")
â”‚   
â”‚       return WebhookHeaders(topic=topic, webhook_id=webhook_id)
â”‚   
â”‚   
â”‚   WebhookHeadersDep = Annotated[WebhookHeaders, Depends(get_webhook_headers)]
â”‚   ```
â”‚   
â”œâ”€â”€ health.py
â”‚   
â”‚   ```py
â”‚   # glam-app/shared/api/health.py
â”‚   
â”‚   from datetime import UTC, datetime
â”‚   
â”‚   from fastapi import APIRouter, Request
â”‚   
â”‚   from shared.api.responses import success_response
â”‚   
â”‚   
â”‚   def create_health_router(service_name: str) -> APIRouter:
â”‚       router = APIRouter()
â”‚   
â”‚       @router.get("/health", tags=["Health"])
â”‚       async def health_check(request: Request):
â”‚           """Basic health check endpoint with service name and timestamp"""
â”‚           return success_response(
â”‚               data={
â”‚                   "status": "healthy",
â”‚                   "service": service_name,
â”‚                   "timestamp": datetime.now(UTC).isoformat(),
â”‚               },
â”‚               request_id=getattr(request.state, "request_id", None),
â”‚               correlation_id=getattr(request.state, "correlation_id", None),
â”‚           )
â”‚   
â”‚       return router
â”‚   ```
â”‚   
â”œâ”€â”€ middleware.py
â”‚   
â”‚   ```py
â”‚   # shared/api/middleware.py
â”‚   
â”‚   """API middleware."""
â”‚   
â”‚   import time
â”‚   from collections.abc import Callable
â”‚   
â”‚   from fastapi import FastAPI, Request, Response
â”‚   from fastapi.exceptions import HTTPException, RequestValidationError
â”‚   from fastapi.responses import JSONResponse
â”‚   from starlette.middleware.base import BaseHTTPMiddleware
â”‚   
â”‚   from shared.utils.exceptions import GlamBaseError
â”‚   from shared.utils.logger import ServiceLogger
â”‚   
â”‚   from .responses import error_response
â”‚   
â”‚   
â”‚   class APIMiddleware(BaseHTTPMiddleware):
â”‚       """Unified middleware for request/response handling."""
â”‚   
â”‚       def __init__(self, app: FastAPI, *, service_name: str = "glam-service"):
â”‚           super().__init__(app)
â”‚           self.service_name = service_name
â”‚   
â”‚       async def dispatch(self, request: Request, call_next: Callable) -> Response:
â”‚           correlation_id = request.headers.get("X-Correlation-ID")
â”‚           logger: ServiceLogger = request.app.state.logger
â”‚   
â”‚           start_time = time.perf_counter()
â”‚   
â”‚           try:
â”‚               response = await call_next(request)
â”‚           except Exception as exc:
â”‚               status_code, error_resp = self._handle_exception(exc, correlation_id)
â”‚   
â”‚               logger.error(
â”‚                   "Request failed",
â”‚                   extra={
â”‚                       "correlation_id": correlation_id,
â”‚                       "method": request.method,
â”‚                       "path": request.url.path,
â”‚                       "status": status_code,
â”‚                       "duration_ms": round((time.perf_counter() - start_time) * 1000, 2),
â”‚                       "error_code": error_resp.error.code if error_resp.error else "UNKNOWN",
â”‚                       "service": self.service_name,
â”‚                   },
â”‚               )
â”‚   
â”‚               response = JSONResponse(
â”‚                   content=error_resp.model_dump(mode="json", exclude_none=True),
â”‚                   status_code=status_code,
â”‚               )
â”‚   
â”‚           response.headers["X-Correlation-ID"] = correlation_id
â”‚           response.headers["X-Service-Name"] = self.service_name
â”‚           return response
â”‚   
â”‚       def _handle_exception(self, exc: Exception, correlation_id: str):
â”‚           """Convert exception to standardized error response."""
â”‚   
â”‚           if isinstance(exc, GlamBaseError):
â”‚               return exc.status, error_response(
â”‚                   code=exc.code,
â”‚                   message=exc.message,
â”‚                   details=exc.details,
â”‚                   correlation_id=correlation_id,
â”‚               )
â”‚   
â”‚           elif isinstance(exc, RequestValidationError):
â”‚               validation_errors = [
â”‚                   {
â”‚                       "field": ".".join(str(loc) for loc in error["loc"]),
â”‚                       "message": error["msg"],
â”‚                       "type": error["type"],
â”‚                   }
â”‚                   for error in exc.errors()
â”‚               ]
â”‚               return 422, error_response(
â”‚                   code="VALIDATION_ERROR",
â”‚                   message="Request validation failed",
â”‚                   details={"validation_errors": validation_errors},
â”‚                   correlation_id=correlation_id,
â”‚               )
â”‚   
â”‚           elif isinstance(exc, HTTPException):
â”‚               if isinstance(exc.detail, dict):
â”‚                   return exc.status_code, error_response(
â”‚                       code=exc.detail.get("code", f"HTTP_{exc.status_code}"),
â”‚                       message=exc.detail.get("message", str(exc.detail)),
â”‚                       details=exc.detail.get("details", exc.detail),
â”‚                       correlation_id=correlation_id,
â”‚                   )
â”‚               return exc.status_code, error_response(
â”‚                   code=f"HTTP_{exc.status_code}",
â”‚                   message=str(exc.detail),
â”‚                   details=None,
â”‚                   correlation_id=correlation_id,
â”‚               )
â”‚   
â”‚           # Unknown/unhandled exception
â”‚           return 500, error_response(
â”‚               code="INTERNAL_ERROR",
â”‚               message=f"An unexpected error occurred: {exc!s}",
â”‚               details={"type": type(exc).__name__},
â”‚               correlation_id=correlation_id,
â”‚           )
â”‚   
â”‚   
â”‚   def setup_middleware(app: FastAPI, *, service_name: str):
â”‚       """Add core middleware to FastAPI app."""
â”‚       app.add_middleware(APIMiddleware, service_name=service_name)
â”‚   ```
â”‚   
â”œâ”€â”€ models.py
â”‚   
â”‚   ```py
â”‚   # -------------------------------
â”‚   # shared/api/models.py
â”‚   # -------------------------------
â”‚   
â”‚   """
â”‚   Unified API response models for glam-app services.
â”‚   Consolidates all response structures into a single, consistent pattern.
â”‚   """
â”‚   
â”‚   from datetime import UTC, datetime
â”‚   from typing import Any, Generic, TypeVar
â”‚   
â”‚   from pydantic import BaseModel, ConfigDict, Field
â”‚   
â”‚   # Generic type for response data
â”‚   T = TypeVar("T")
â”‚   
â”‚   
â”‚   class Meta(BaseModel):
â”‚       """Metadata included in all responses."""
â”‚   
â”‚       request_id: str = Field(description="Unique request identifier")
â”‚       correlation_id: str | None = Field(None, description="Distributed tracing ID")
â”‚       timestamp: datetime = Field(default_factory=lambda: datetime.now(UTC), description="Response timestamp in UTC")
â”‚   
â”‚       model_config = ConfigDict(json_encoders={datetime: lambda v: v.isoformat()})
â”‚   
â”‚   
â”‚   class Pagination(BaseModel):
â”‚       """Pagination metadata for list responses."""
â”‚   
â”‚       page: int = Field(ge=1)
â”‚       limit: int = Field(ge=1, le=1000)
â”‚       total: int = Field(ge=0)
â”‚       pages: int = Field(ge=0)
â”‚       has_next: bool
â”‚       has_previous: bool
â”‚   
â”‚       @classmethod
â”‚       def create(cls, page: int, limit: int, total: int) -> "Pagination":
â”‚           """Create pagination from parameters."""
â”‚           pages = (total + limit - 1) // limit if total > 0 else 0
â”‚           return cls(page=page, limit=limit, total=total, pages=pages, has_next=page < pages, has_previous=page > 1)
â”‚   
â”‚   
â”‚   class Links(BaseModel):
â”‚       """HATEOAS links for resource navigation."""
â”‚   
â”‚       self: str
â”‚       next: str | None = None
â”‚       previous: str | None = None
â”‚       first: str | None = None
â”‚       last: str | None = None
â”‚   
â”‚       @classmethod
â”‚       def create_paginated(cls, base_url: str, page: int, limit: int, pages: int, **query_params) -> "Links":
â”‚           """Create pagination links."""
â”‚   
â”‚           def build_url(page_num: int) -> str:
â”‚               params = {**query_params, "page": page_num, "limit": limit}
â”‚               query = "&".join(f"{k}={v}" for k, v in params.items())
â”‚               return f"{base_url}?{query}"
â”‚   
â”‚           return cls(
â”‚               self=build_url(page),
â”‚               next=build_url(page + 1) if page < pages else None,
â”‚               previous=build_url(page - 1) if page > 1 else None,
â”‚               first=build_url(1) if pages > 0 else None,
â”‚               last=build_url(pages) if pages > 0 else None,
â”‚           )
â”‚   
â”‚   
â”‚   class ErrorDetail(BaseModel):
â”‚       """Error information."""
â”‚   
â”‚       code: str
â”‚       message: str
â”‚       details: dict[str, Any] | None = None
â”‚   
â”‚   
â”‚   class ApiResponse(BaseModel, Generic[T]):
â”‚       """
â”‚       Unified API response structure.
â”‚       Used for both success and error responses.
â”‚       """
â”‚   
â”‚       # For success responses
â”‚       data: T | None = None
â”‚   
â”‚       # For error responses
â”‚       error: ErrorDetail | None = None
â”‚   
â”‚       # Always present
â”‚       meta: Meta
â”‚   
â”‚       # Optional for paginated responses
â”‚       pagination: Pagination | None = None
â”‚       links: Links | None = None
â”‚   
â”‚       model_config = ConfigDict(json_encoders={datetime: lambda v: v.isoformat()})
â”‚   ```
â”‚   
â”œâ”€â”€ responses.py
â”‚   
â”‚   ```py
â”‚   # -------------------------------
â”‚   # shared/api/responses.py
â”‚   # -------------------------------
â”‚   
â”‚   """Response helper functions."""
â”‚   
â”‚   import uuid
â”‚   from typing import Any
â”‚   
â”‚   from .models import ApiResponse, ErrorDetail, Links, Meta, Pagination, T
â”‚   
â”‚   
â”‚   def create_response(
â”‚       data: T | None = None,
â”‚       error: ErrorDetail | None = None,
â”‚       request_id: str | None = None,
â”‚       correlation_id: str | None = None,
â”‚       pagination: Pagination | None = None,
â”‚       links: Links | None = None,
â”‚   ) -> ApiResponse[T]:
â”‚       """Create a unified API response."""
â”‚       if request_id is None:
â”‚           request_id = f"req_{uuid.uuid4().hex[:12]}"
â”‚   
â”‚       meta = Meta(request_id=request_id, correlation_id=correlation_id)
â”‚   
â”‚       return ApiResponse(data=data, error=error, meta=meta, pagination=pagination, links=links)
â”‚   
â”‚   
â”‚   def success_response(
â”‚       data: T, request_id: str | None = None, correlation_id: str | None = None, links: Links | None = None
â”‚   ) -> ApiResponse[T]:
â”‚       """Create a success response."""
â”‚       return create_response(data=data, request_id=request_id, correlation_id=correlation_id, links=links)
â”‚   
â”‚   
â”‚   def error_response(
â”‚       code: str,
â”‚       message: str,
â”‚       details: dict[str, Any] | None = None,
â”‚       request_id: str | None = None,
â”‚       correlation_id: str | None = None,
â”‚   ) -> ApiResponse[None]:
â”‚       """Create an error response."""
â”‚       error = ErrorDetail(code=code, message=message, details=details)
â”‚       return create_response(error=error, request_id=request_id, correlation_id=correlation_id)
â”‚   
â”‚   
â”‚   def paginated_response(
â”‚       data: list[T],
â”‚       page: int,
â”‚       limit: int,
â”‚       total: int,
â”‚       base_url: str,
â”‚       request_id: str | None = None,
â”‚       correlation_id: str | None = None,
â”‚       **query_params,
â”‚   ) -> ApiResponse[list[T]]:
â”‚       """Create a paginated response."""
â”‚       pagination = Pagination.create(page, limit, total)
â”‚       links = Links.create_paginated(base_url, page, limit, pagination.pages, **query_params)
â”‚   
â”‚       return create_response(
â”‚           data=data, request_id=request_id, correlation_id=correlation_id, pagination=pagination, links=links
â”‚       )
â”‚   ```
â”‚   
â””â”€â”€ validation.py
    
    ```py
    # shared/api/validation.py
    from typing import Any
    
    from fastapi import HTTPException, status
    
    from shared.api.dependencies import ClientAuthContext, InternalAuthContext, PlatformContext
    from shared.utils.logger import ServiceLogger
    
    
    def validate_shop_context(
        client_auth: ClientAuthContext,
        platform_ctx: PlatformContext,
        logger: ServiceLogger,
        body_platform: str | None = None,
        body_domain: str | None = None,
        expected_platform: str | None = None,
        expected_scope: str | None = None,
        webhook_payload: dict[str, Any] | None = None,
    ) -> None:
        """
        Unified validation for shop context across auth, headers, body, and webhooks.
    
        Args:
            client_auth: JWT authentication context
            platform_ctx: Platform context from headers
            logger: Service logger
            body_platform: Platform from request body (if applicable)
            body_domain: Domain from request body (if applicable)
            expected_platform: Expected platform for this endpoint (e.g., "shopify")
            expected_scope: Expected JWT scope (e.g., "bff:call")
            webhook_payload: Webhook payload for platform-specific validation
    
        Raises:
            HTTPException: On any validation failure
        """
    
        # 1. Validate expected platform (for platform-specific endpoints)
        if expected_platform and platform_ctx.platform != expected_platform:
            logger.warning(
                f"Invalid platform for {expected_platform}-only endpoint",
                extra={"received_platform": platform_ctx.platform, "expected_platform": expected_platform},
            )
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "code": "INVALID_PLATFORM",
                    "message": f"This endpoint only accepts {expected_platform} requests",
                    "details": {"received": platform_ctx.platform, "expected": expected_platform},
                },
            )
    
        # 2. Validate JWT shop matches header domain
        if client_auth.shop != platform_ctx.domain:
            logger.warning(
                "Shop domain mismatch between JWT and headers",
                extra={"jwt_shop": client_auth.shop, "header_domain": platform_ctx.domain},
            )
            raise HTTPException(
                status_code=status.HTTP_401_UNAUTHORIZED,
                detail={
                    "code": "domain_MISMATCH",
                    "message": "Shop domain mismatch between JWT and headers",
                    "details": {"jwt_shop": client_auth.shop, "header_domain": platform_ctx.domain},
                },
            )
    
        # 3. Validate JWT scope if specified
        if expected_scope and client_auth.scope != expected_scope:
            logger.warning(
                "Invalid JWT scope", extra={"received_scope": client_auth.scope, "expected_scope": expected_scope}
            )
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail={
                    "code": "INVALID_SCOPE",
                    "message": "Invalid JWT scope",
                    "details": {"received": client_auth.scope, "expected": expected_scope},
                },
            )
    
        # 4. Validate body domain if provided
        if body_domain and body_domain.lower() != platform_ctx.domain.lower():
            logger.warning(
                "Domain mismatch between request body and header",
                extra={"body_domain": body_domain, "header_domain": platform_ctx.domain},
            )
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "code": "BODY_DOMAIN_MISMATCH",
                    "message": "Domain mismatch between request body and header",
                    "details": {"body_domain": body_domain, "header_domain": platform_ctx.domain},
                },
            )
    
        # 5. Validate body platform if provided
        if body_platform and body_platform.lower() != platform_ctx.platform.lower():
            logger.warning(
                "Platform mismatch between request body and header",
                extra={"body_platform": body_platform, "header_platform": platform_ctx.platform},
            )
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail={
                    "code": "PLATFORM_MISMATCH",
                    "message": "Platform mismatch between request body and header",
                    "details": {"body_platform": body_platform, "header_platform": platform_ctx.platform},
                },
            )
    
        # 6. Platform-specific webhook payload validation
        if webhook_payload and platform_ctx.is_shopify:
            # Shopify-specific validation
            payload_domain = (webhook_payload.get("myshopify_domain") or webhook_payload.get("domain") or "").lower()
    
            if payload_domain and payload_domain != platform_ctx.domain:
                logger.warning(
                    "Shopify webhook payload domain mismatch",
                    extra={"payload_domain": payload_domain, "header_domain": platform_ctx.domain},
                )
                raise HTTPException(
                    status_code=status.HTTP_400_BAD_REQUEST,
                    detail={
                        "code": "WEBHOOK_DOMAIN_MISMATCH",
                        "message": "Webhook payload domain doesn't match header domain",
                        "details": {"payload_domain": payload_domain, "header_domain": platform_ctx.domain},
                    },
                )
    
        # Add other platform-specific validations as needed
        # elif platform_ctx.platform == "bigcommerce":
        #     ...
    
    
    # Usage patterns:
    
    # Minimal validation (just auth consistency)
    # validate_shop_context(client_auth, platform_ctx, logger)
    
    # # With body validation
    # validate_shop_context(
    #     client_auth, platform_ctx, logger,
    #     body_platform=body.platform,
    #     body_domain=body.domain
    # )
    
    # # Platform-specific endpoint
    # validate_shop_context(
    #     client_auth, platform_ctx, logger,
    #     expected_platform="shopify"
    # )
    
    # # Webhook with all validations
    # validate_shop_context(
    #     client_auth, platform_ctx, logger,
    #     expected_platform="shopify",
    #     expected_scope="bff:call",
    #     webhook_payload=payload
    # )
    
    # shared/api/validation.py - ADD this function to existing file
    
    
    def validate_service_context(
        internal_auth: InternalAuthContext,
        logger: ServiceLogger,
        allowed_services: list[str] | None = None,
        operation: str | None = None,
    ) -> None:
        """
        Validate internal service-to-service calls.
    
        Args:
            internal_auth: Internal service authentication context
            logger: Service logger
            allowed_services: List of services allowed to make this call
            operation: Operation being performed (for logging)
    
        Raises:
            HTTPException: On validation failure
        """
    
        # Check if service is in allowed list
        if allowed_services and internal_auth.service not in allowed_services:
            logger.warning(
                "Unauthorized service access attempt",
                extra={
                    "requesting_service": internal_auth.service,
                    "allowed_services": allowed_services,
                    "operation": operation,
                },
            )
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail={
                    "code": "SERVICE_NOT_ALLOWED",
                    "message": f"Service '{internal_auth.service}' not authorized for this operation",
                    "details": {
                        "service": internal_auth.service,
                        "operation": operation,
                        "allowed_services": allowed_services,
                    },
                },
            )
    
        logger.info("Service access validated", extra={"requesting_service": internal_auth.service, "operation": operation})
    ```
    
messaging/
â”œâ”€â”€ events/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ analytics.py
â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/messaging/models.py
â”‚   â”‚   """Standardized event models for GLAM messaging system."""
â”‚   â”‚   
â”‚   â”‚   from datetime import UTC, datetime
â”‚   â”‚   from typing import Any, Generic, TypeVar
â”‚   â”‚   from uuid import UUID, uuid4
â”‚   â”‚   
â”‚   â”‚   from pydantic import BaseModel, ConfigDict, Field, field_validator
â”‚   â”‚   
â”‚   â”‚   # Type variable for payload data
â”‚   â”‚   T = TypeVar("T", bound=BaseModel)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class PlatformContext(BaseModel):
â”‚   â”‚       """Platform identification context - REQUIRED for all events."""
â”‚   â”‚   
â”‚   â”‚       merchant_id: UUID = Field(..., description="Internal merchant identifier")
â”‚   â”‚       platform_name: str = Field(..., description="Platform type: shopify, woocommerce, etc")
â”‚   â”‚       platform_shop_id: str = Field(..., description="Platform-specific ID (shop_gid for Shopify)")
â”‚   â”‚       domain: str = Field(..., description="Full platform domain")
â”‚   â”‚   
â”‚   â”‚       @field_validator("merchant_id", mode="before")
â”‚   â”‚       @classmethod
â”‚   â”‚       def coerce_merchant_id(cls, v):
â”‚   â”‚           """Convert string UUID to UUID object"""
â”‚   â”‚           if isinstance(v, str):
â”‚   â”‚               return UUID(v)
â”‚   â”‚           return v
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class BaseEventPayload(BaseModel):
â”‚   â”‚       """
â”‚   â”‚       Base class for all event payloads.
â”‚   â”‚       Services should extend this for their specific events.
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       model_config = ConfigDict(json_encoders={UUID: str, datetime: lambda v: v.isoformat()})
â”‚   â”‚       platform: PlatformContext = Field(..., description="Complete platform identification")
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class EventEnvelope(BaseModel, Generic[T]):
â”‚   â”‚       """
â”‚   â”‚       Standard envelope for all events in GLAM_EVENTS stream.
â”‚   â”‚       Source service is encoded in the event_type subject.
â”‚   â”‚       """
â”‚   â”‚   
â”‚   â”‚       model_config = ConfigDict(json_encoders={UUID: str, datetime: lambda v: v.isoformat()})
â”‚   â”‚   
â”‚   â”‚       # Required envelope fields
â”‚   â”‚       event_id: str = Field(default_factory=lambda: str(uuid4()))
â”‚   â”‚       event_type: str = Field(..., description="Subject: evt.{service}.{action}.v1")
â”‚   â”‚       correlation_id: str = Field(..., description="Request correlation ID")
â”‚   â”‚       source_service: str = Field(..., description="Service name (redundant with subject)")
â”‚   â”‚       timestamp: datetime = Field(default_factory=lambda: datetime.now(UTC), description="When published to stream")
â”‚   â”‚   
â”‚   â”‚       # Typed payload with platform context
â”‚   â”‚       data: T = Field(..., description="Event payload extending BaseEventPayload")
â”‚   â”‚   
â”‚   â”‚       def to_bytes(self) -> bytes:
â”‚   â”‚           """Serialize to JSON bytes for NATS."""
â”‚   â”‚           return self.model_dump_json().encode("utf-8")
â”‚   â”‚   
â”‚   â”‚       @classmethod
â”‚   â”‚       def from_bytes(cls, data: bytes) -> "EventEnvelope":
â”‚   â”‚           """Deserialize from NATS message."""
â”‚   â”‚           return cls.model_validate_json(data)
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class ErrorPayload(BaseEventPayload):
â”‚   â”‚       """Payload for error/failure events."""
â”‚   â”‚   
â”‚   â”‚       error_code: str
â”‚   â”‚       error_message: str
â”‚   â”‚       failed_operation: str
â”‚   â”‚       retry_count: int = 0
â”‚   â”‚       max_retries: int = 3
â”‚   â”‚       original_data: dict[str, Any] | None = None
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ billing.py
â”‚   â”œâ”€â”€ catalog.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/shared/messaging/events/catalog.py
â”‚   â”‚   
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   
â”‚   â”‚   from pydantic import Field
â”‚   â”‚   
â”‚   â”‚   from shared.messaging.events.base import BaseEventPayload
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class CatalogSyncStartedPayload(BaseEventPayload):
â”‚   â”‚       """Payload for catalog sync started event"""
â”‚   â”‚   
â”‚   â”‚       sync_id: UUID = Field(..., description="Unique sync operation ID")
â”‚   â”‚       total_items: int = Field(..., description="Total items to sync")
â”‚   â”‚       status: str = Field(..., description="Initial sync status")
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class CatalogSyncCompletedPayload(BaseEventPayload):
â”‚   â”‚       """Payload for catalog sync completed event"""
â”‚   â”‚   
â”‚   â”‚       sync_id: UUID = Field(..., description="Unique sync operation ID")
â”‚   â”‚       total_items: int = Field(..., description="Total items synced")
â”‚   â”‚       status: str = Field(..., description="Final sync status")
â”‚   â”‚       first_sync: bool = Field(default=False, description="Is this the first sync?")
â”‚   â”‚       has_changes: bool = Field(default=False, description="Were there any changes?")
â”‚   â”‚       email: str | None = Field(None, description="Merchant email if available")
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ credit.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/shared/messaging/events/credit.py
â”‚   â”‚   
â”‚   â”‚   from datetime import datetime
â”‚   â”‚   
â”‚   â”‚   from pydantic import Field
â”‚   â”‚   
â”‚   â”‚   from shared.messaging.events.base import BaseEventPayload
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class CreditBalanceLowPayload(BaseEventPayload):
â”‚   â”‚       """Payload for credit balance low event"""
â”‚   â”‚   
â”‚   â”‚       balance: float = Field(..., description="Current credit balance")
â”‚   â”‚       threshold: float = Field(..., description="Low balance threshold")
â”‚   â”‚       email: str | None = Field(None, description="Merchant email if available")
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class CreditBalanceDepletedPayload(BaseEventPayload):
â”‚   â”‚       """Payload for credit balance depleted event"""
â”‚   â”‚   
â”‚   â”‚       depleted_at: datetime = Field(..., description="When balance hit zero")
â”‚   â”‚       email: str | None = Field(None, description="Merchant email if available")
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ merchant.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   from shared.messaging.events.base import BaseEventPayload
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class MerchantCreatedPayload(BaseEventPayload):
â”‚   â”‚       """Payload for merchant.created.v1 event."""
â”‚   â”‚   
â”‚   â”‚       shop_name: str
â”‚   â”‚       email: str
â”‚   â”‚       country: str
â”‚   â”‚       currency: str
â”‚   â”‚       timezone: str
â”‚   â”‚       platform_version: str
â”‚   â”‚       scopes: str
â”‚   â”‚       status: str
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ notification.py
â”‚   â”‚   
â”‚   â”‚   ```py
â”‚   â”‚   # shared/shared/messaging/events/notification.py
â”‚   â”‚   from uuid import UUID
â”‚   â”‚   
â”‚   â”‚   from shared.messaging.events.base import BaseEventPayload
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class EmailSentPayload(BaseEventPayload):
â”‚   â”‚       """Payload for email sent event"""
â”‚   â”‚   
â”‚   â”‚       notification_id: UUID
â”‚   â”‚       template_type: str
â”‚   â”‚       recipient_email: str
â”‚   â”‚       provider: str
â”‚   â”‚       provider_message_id: str
â”‚   â”‚   
â”‚   â”‚   
â”‚   â”‚   class EmailFailedPayload(BaseEventPayload):
â”‚   â”‚       """Payload for email failed event"""
â”‚   â”‚   
â”‚   â”‚       notification_id: UUID
â”‚   â”‚       template_type: str
â”‚   â”‚       recipient_email: str
â”‚   â”‚       error_code: str
â”‚   â”‚       error_message: str
â”‚   â”‚       retry_count: int = 0
â”‚   â”‚   ```
â”‚   â”‚   
â”‚   â”œâ”€â”€ recommendation.py
â”‚   â””â”€â”€ webhook.py
â”œâ”€â”€ __init__.py
â”‚   
â”‚   ```py
â”‚   # shared/messaging/__init__.py
â”‚   """Shared messaging module for publisher, subscriber, event context, stream client, subject, and payloads."""
â”‚   
â”‚   from .jetstream_client import JetStreamClient
â”‚   from .listener import Listener
â”‚   from .publisher import Publisher
â”‚   from .subjects import Subjects
â”‚   
â”‚   __all__ = [
â”‚       "JetStreamClient",
â”‚       "Listener",
â”‚       "Publisher",
â”‚       "Subjects",
â”‚   ]
â”‚   ```
â”‚   
â”œâ”€â”€ jetstream_client.py
â”‚   
â”‚   ```py
â”‚   # shared/shared/messaging/jetstream_client.py
â”‚   """Pure JetStream client - only connection + stream management."""
â”‚   
â”‚   import os
â”‚   
â”‚   import nats
â”‚   from nats.aio.client import Client
â”‚   from nats.js import JetStreamContext
â”‚   from nats.js.api import RetentionPolicy, StorageType, StreamConfig
â”‚   from nats.js.errors import NotFoundError
â”‚   
â”‚   from shared.utils.logger import ServiceLogger
â”‚   
â”‚   
â”‚   class JetStreamClient:
â”‚       """Pure JetStream client - only connection + stream management."""
â”‚   
â”‚       def __init__(self, logger: ServiceLogger) -> None:  # âœ” typed
â”‚           self._client: Client | None = None
â”‚           self._js: JetStreamContext | None = None
â”‚           self.logger = logger
â”‚   
â”‚       # context-manager helpers --------------------------------------------------
â”‚       async def __aenter__(self):
â”‚           return self
â”‚   
â”‚       async def __aexit__(self, exc_t, exc, tb):
â”‚           await self.close()
â”‚   
â”‚       # public accessors ---------------------------------------------------------
â”‚       @property
â”‚       def client(self) -> Client:
â”‚           if not self._client:
â”‚               raise RuntimeError("NATS client not connected")
â”‚           return self._client
â”‚   
â”‚       @property
â”‚       def js(self) -> JetStreamContext:
â”‚           if not self._js:
â”‚               raise RuntimeError("JetStream not initialized")
â”‚           return self._js
â”‚   
â”‚       # connection ---------------------------------------------------------------
â”‚       async def connect(self, servers: list[str]) -> None:
â”‚           opts = {
â”‚               "servers": servers,
â”‚               "max_reconnect_attempts": -1,
â”‚               "reconnect_time_wait": 2,
â”‚           }
â”‚           if user := os.getenv("NATS_USER"):
â”‚               opts.update(user=user, password=os.getenv("NATS_PASSWORD", ""))
â”‚   
â”‚           self._client = await nats.connect(**opts)
â”‚           self._js = self._client.jetstream()
â”‚           if self.logger:
â”‚               self.logger.info("Connected to NATS %s", servers)
â”‚   
â”‚       async def close(self) -> None:
â”‚           if self._client and not self._client.is_closed:
â”‚               await self._client.close()
â”‚               if self.logger:
â”‚                   self.logger.info("NATS connection closed")
â”‚   
â”‚       def is_connected(self) -> bool:
â”‚           return bool(self._client and self._client.is_connected)
â”‚   
â”‚       # stream helpers -----------------------------------------------------------
â”‚       async def ensure_stream(
â”‚           self,
â”‚           name: str,
â”‚           subjects: list[str],
â”‚           **kw,
â”‚       ) -> None:
â”‚           if not self._js:
â”‚               raise RuntimeError("JetStream not initialized")
â”‚   
â”‚           cfg = StreamConfig(
â”‚               name=name,
â”‚               subjects=subjects,
â”‚               retention=RetentionPolicy.LIMITS,
â”‚               max_age=24 * 60 * 60,
â”‚               max_msgs=1_000_000,
â”‚               storage=StorageType.FILE,
â”‚           )
â”‚   
â”‚           try:
â”‚               await self._js.stream_info(name)
â”‚               if self.logger:
â”‚                   self.logger.debug("Using existing stream: %s", name)
â”‚           except NotFoundError:
â”‚               await self._js.add_stream(cfg)
â”‚               if self.logger:
â”‚                   self.logger.info("Created new stream: %s", name)
â”‚   
â”‚       async def delete_stream(self, name: str) -> None:
â”‚           if not self._js:
â”‚               raise RuntimeError("JetStream not initialized")
â”‚           await self._js.delete_stream(name)
â”‚           if self.logger:
â”‚               self.logger.info("Deleted stream: %s", name)
â”‚   
â”‚       async def get_stream_info(self, name: str) -> dict:
â”‚           if not self._js:
â”‚               raise RuntimeError("JetStream not initialized")
â”‚           info = await self._js.stream_info(name)
â”‚           return {
â”‚               "name": info.config.name,
â”‚               "subjects": info.config.subjects,
â”‚               "messages": info.state.messages,
â”‚               "bytes": info.state.bytes,
â”‚           }
â”‚   ```
â”‚   
â”œâ”€â”€ listener.py
â”‚   
â”‚   ```py
â”‚   # shared/messaging/listener.py
â”‚   """Enhanced listener with automatic envelope unpacking and type safety."""
â”‚   
â”‚   import asyncio
â”‚   import contextlib
â”‚   import json
â”‚   from abc import ABC, abstractmethod
â”‚   from datetime import datetime
â”‚   from typing import Generic, TypeVar
â”‚   
â”‚   from nats.errors import TimeoutError as NATSTimeoutError
â”‚   from nats.js.api import AckPolicy, ConsumerConfig, DeliverPolicy
â”‚   from nats.js.errors import NotFoundError
â”‚   
â”‚   from shared.api.correlation import set_correlation_context
â”‚   from shared.utils.logger import ServiceLogger
â”‚   
â”‚   from .events.base import BaseEventPayload
â”‚   from .jetstream_client import JetStreamClient
â”‚   
â”‚   T = TypeVar("T", bound=BaseEventPayload)
â”‚   
â”‚   
â”‚   class Listener(ABC, Generic[T]):
â”‚       """
â”‚       Enhanced listener with type-safe payload handling.
â”‚       """
â”‚   
â”‚       stream_name: str = "GLAM_EVENTS"
â”‚       batch_size: int = 10
â”‚       ack_wait_sec: int = 30
â”‚       max_deliver: int = 3
â”‚       idle_sleep_sec: float = 0.05
â”‚       poll_window_sec: float = 2.0
â”‚   
â”‚       _task: asyncio.Task | None = None
â”‚       _running: bool = False
â”‚       _sub = None
â”‚   
â”‚       @property
â”‚       @abstractmethod
â”‚       def service_name(self) -> str:
â”‚           """Service name for consumer identification."""
â”‚           ...
â”‚   
â”‚       @property
â”‚       @abstractmethod
â”‚       def subject(self) -> str:
â”‚           """NATS subject to listen to (evt.* or cmd.*)."""
â”‚           ...
â”‚   
â”‚       @property
â”‚       @abstractmethod
â”‚       def queue_group(self) -> str:
â”‚           """Queue group for load balancing."""
â”‚           ...
â”‚   
â”‚       @property
â”‚       @abstractmethod
â”‚       def payload_class(self) -> type[T]:
â”‚           """Payload class for type validation."""
â”‚           ...
â”‚   
â”‚       def __init__(self, js_client: JetStreamClient, logger: ServiceLogger) -> None:
â”‚           self._js = js_client.js
â”‚           self.logger = logger
â”‚           # Track delivery attempts for DLQ logic
â”‚           self._delivery_attempts: dict[str, int] = {}
â”‚   
â”‚       async def start(self) -> None:
â”‚           """Start listening for events."""
â”‚           await self._ensure_consumer()
â”‚           await self._create_subscription()
â”‚           self.logger.info("Listener started", extra={"subject": self.subject, "service": self.service_name})
â”‚           self._running = True
â”‚           self._task = asyncio.create_task(self._poll_loop(), name=f"{self.service_name}:{self.subject}")
â”‚   
â”‚       async def stop(self) -> None:
â”‚           """Stop listening gracefully."""
â”‚           self._running = False
â”‚           if self._task:
â”‚               self._task.cancel()
â”‚               with contextlib.suppress(asyncio.CancelledError):
â”‚                   await self._task
â”‚               self._task = None
â”‚           if self._sub:
â”‚               await self._sub.unsubscribe()
â”‚           self.logger.info("Listener stopped", extra={"subject": self.subject, "service": self.service_name})
â”‚   
â”‚       @abstractmethod
â”‚       async def on_message(
â”‚           self, payload: T, event_id: str, correlation_id: str, source_service: str, timestamp: datetime
â”‚       ) -> None:
â”‚           """
â”‚           Process message with typed payload and metadata.
â”‚   
â”‚           Args:
â”‚               payload: Typed and validated payload
â”‚               event_id: Unique event ID
â”‚               correlation_id: Correlation ID for tracing
â”‚               source_service: Service that published the event
â”‚               timestamp: When the event was published
â”‚           """
â”‚           ...
â”‚   
â”‚       async def on_error(self, error: Exception, event_id: str, correlation_id: str, delivery_count: int) -> bool:
â”‚           """
â”‚           Handle processing errors.
â”‚   
â”‚           Returns:
â”‚               True to ACK (don't retry), False to NACK (retry)
â”‚           """
â”‚           self.logger.error(
â”‚               "Error processing message",
â”‚               extra={
â”‚                   "subject": self.subject,
â”‚                   "event_id": event_id,
â”‚                   "correlation_id": correlation_id,
â”‚                   "delivery_count": delivery_count,
â”‚                   "error": str(error),
â”‚               },
â”‚           )
â”‚   
â”‚           # Default: retry until max_deliver
â”‚           return delivery_count >= self.max_deliver
â”‚   
â”‚       async def _ensure_consumer(self) -> None:
â”‚           """Ensure consumer exists for this listener."""
â”‚           durable = f"{self.service_name}-{self.queue_group}"
â”‚   
â”‚           try:
â”‚               await self._js.consumer_info(self.stream_name, durable)
â”‚               self.logger.debug("Consumer exists: %s", durable)
â”‚           except NotFoundError:
â”‚               cfg = ConsumerConfig(
â”‚                   durable_name=durable,
â”‚                   deliver_policy=DeliverPolicy.ALL,
â”‚                   ack_policy=AckPolicy.EXPLICIT,
â”‚                   max_deliver=self.max_deliver,
â”‚                   max_ack_pending=self.batch_size * 5,
â”‚                   filter_subject=self.subject,
â”‚                   ack_wait=self.ack_wait_sec,
â”‚               )
â”‚               await self._js.add_consumer(self.stream_name, cfg)
â”‚               self.logger.info("Created consumer: %s", durable)
â”‚   
â”‚       async def _create_subscription(self) -> None:
â”‚           """Create pull subscription."""
â”‚           durable = f"{self.service_name}-{self.queue_group}"
â”‚           self._sub = await self._js.pull_subscribe(
â”‚               self.subject,
â”‚               durable=durable,
â”‚               stream=self.stream_name,
â”‚           )
â”‚   
â”‚       async def _poll_loop(self) -> None:
â”‚           """Main polling loop."""
â”‚           try:
â”‚               while self._running:
â”‚                   if not self._sub:
â”‚                       self.logger.error("Subscription not initialized")
â”‚                       await asyncio.sleep(1)
â”‚                       continue
â”‚   
â”‚                   try:
â”‚                       msgs = await self._sub.fetch(
â”‚                           batch=self.batch_size,
â”‚                           timeout=self.poll_window_sec,
â”‚                       )
â”‚                   except (TimeoutError, NATSTimeoutError):
â”‚                       # Normal: no messages available
â”‚                       await asyncio.sleep(self.idle_sleep_sec)
â”‚                       continue
â”‚   
â”‚                   if not msgs:
â”‚                       await asyncio.sleep(self.idle_sleep_sec)
â”‚                       continue
â”‚   
â”‚                   # Process batch
â”‚                   for msg in msgs:
â”‚                       await self._process_message(msg)
â”‚   
â”‚           except asyncio.CancelledError:
â”‚               self.logger.info("Poll loop cancelled")
â”‚           except Exception:
â”‚               self.logger.critical("Poll loop crashed", exc_info=True)
â”‚   
â”‚       async def _process_message(self, msg) -> None:
â”‚           """Process a single message with envelope unpacking."""
â”‚           delivery_count = 1
â”‚   
â”‚           try:
â”‚               # Get delivery count from metadata
â”‚               md = getattr(msg, "metadata", None)
â”‚               if md:
â”‚                   delivery_count = getattr(md, "num_delivered", 1)
â”‚   
â”‚               # Parse the JSON envelope
â”‚               try:
â”‚                   envelope_data = json.loads(msg.data.decode("utf-8"))
â”‚               except json.JSONDecodeError as e:
â”‚                   self.logger.error("Failed to parse message JSON", extra={"error": str(e)})
â”‚                   await msg.ack()  # ACK corrupt messages
â”‚                   return
â”‚   
â”‚               # Extract envelope fields
â”‚               event_id = envelope_data.get("event_id")
â”‚               event_type = envelope_data.get("event_type")
â”‚               correlation_id = envelope_data.get("correlation_id")
â”‚               source_service = envelope_data.get("source_service")
â”‚               timestamp_str = envelope_data.get("timestamp")
â”‚               data = envelope_data.get("data")
â”‚   
â”‚               # Validate required fields
â”‚               if not all([event_id, event_type, correlation_id, source_service, timestamp_str, data]):
â”‚                   self.logger.error("Missing required envelope fields", extra={"envelope": envelope_data})
â”‚                   await msg.ack()
â”‚                   return
â”‚   
â”‚               # Validate event type matches subject
â”‚               if event_type != self.subject:
â”‚                   self.logger.warning(
â”‚                       "Subject mismatch", extra={"expected": self.subject, "received": event_type, "event_id": event_id}
â”‚                   )
â”‚                   await msg.ack()
â”‚                   return
â”‚   
â”‚               # Parse timestamp
â”‚               try:
â”‚                   timestamp = datetime.fromisoformat(timestamp_str.replace("Z", "+00:00"))
â”‚               except (ValueError, AttributeError):
â”‚                   timestamp = datetime.utcnow()
â”‚   
â”‚               # Validate and parse payload
â”‚               try:
â”‚                   typed_payload = self.payload_class.model_validate(data)
â”‚               except Exception as e:
â”‚                   self.logger.error(
â”‚                       "Payload validation failed", extra={"event_id": event_id, "error": str(e), "data": data}
â”‚                   )
â”‚                   await msg.ack()
â”‚                   return
â”‚   
â”‚               # Set correlation context
â”‚               set_correlation_context(correlation_id)
â”‚   
â”‚               # Process message
â”‚               try:
â”‚                   await self.on_message(typed_payload, event_id, correlation_id, source_service, timestamp)
â”‚                   await msg.ack()
â”‚   
â”‚                   # Clear delivery tracking on success
â”‚                   if event_id in self._delivery_attempts:
â”‚                       del self._delivery_attempts[event_id]
â”‚   
â”‚               except Exception as e:
â”‚                   # Track delivery attempts
â”‚                   self._delivery_attempts[event_id] = delivery_count
â”‚   
â”‚                   # Let subclass decide on retry strategy
â”‚                   should_ack = await self.on_error(e, event_id, correlation_id, delivery_count)
â”‚   
â”‚                   if should_ack:
â”‚                       await msg.ack()
â”‚                       if event_id in self._delivery_attempts:
â”‚                           del self._delivery_attempts[event_id]
â”‚                   else:
â”‚                       await msg.nak()
â”‚   
â”‚           except Exception as e:
â”‚               self.logger.critical("Message processing failed catastrophically", extra={"error": str(e)}, exc_info=True)
â”‚               await msg.ack()
â”‚   ```
â”‚   
â”œâ”€â”€ publisher.py
â”‚   
â”‚   ```py
â”‚   # shared/messaging/publisher.py
â”‚   """Enhanced publisher with standardized envelope and auto-correlation."""
â”‚   
â”‚   from abc import ABC, abstractmethod
â”‚   from typing import TypeVar
â”‚   
â”‚   from shared.api.correlation import get_correlation_context
â”‚   from shared.utils.logger import ServiceLogger
â”‚   
â”‚   from .events.base import BaseEventPayload, EventEnvelope
â”‚   from .jetstream_client import JetStreamClient
â”‚   
â”‚   T = TypeVar("T", bound=BaseEventPayload)
â”‚   
â”‚   
â”‚   class Publisher(ABC):
â”‚       """Base publisher with standardized event publishing."""
â”‚   
â”‚       stream_name: str = "GLAM_EVENTS"  # Single stream for all events
â”‚   
â”‚       @property
â”‚       @abstractmethod
â”‚       def service_name(self) -> str:
â”‚           """Service identifier for source tracking."""
â”‚           ...
â”‚   
â”‚       def __init__(self, jetstream_client: JetStreamClient, logger: ServiceLogger) -> None:
â”‚           self.js_client = jetstream_client
â”‚           self.logger = logger
â”‚           self._ensure_stream_created = False
â”‚   
â”‚       async def _ensure_stream(self) -> None:
â”‚           """Ensure GLAM_EVENTS stream exists (called once)."""
â”‚           if self._ensure_stream_created:
â”‚               return
â”‚   
â”‚           await self.js_client.ensure_stream(
â”‚               self.stream_name,
â”‚               subjects=["evt.>", "cmd.>", "dlq.>"],  # Prepared for DLQ
â”‚           )
â”‚           self._ensure_stream_created = True
â”‚   
â”‚       async def publish_event(
â”‚           self,
â”‚           subject: str,
â”‚           payload: T,
â”‚           correlation_id: str | None = None,
â”‚           metadata: dict | None = None,
â”‚       ) -> str:
â”‚           """
â”‚           Publish an event with automatic envelope wrapping.
â”‚   
â”‚           Args:
â”‚               subject: NATS subject (evt.* or cmd.*)
â”‚               payload: Typed event payload extending BaseEventPayload
â”‚               correlation_id: Optional - will use context if not provided
â”‚               metadata: Additional metadata
â”‚   
â”‚           Returns:
â”‚               event_id of the published event
â”‚           """
â”‚           # Validate subject pattern
â”‚           if not (subject.startswith("evt.") or subject.startswith("cmd.") or subject.startswith("dlq.")):
â”‚               raise ValueError(f"Invalid subject pattern: {subject}. Must start with evt., cmd., or dlq.")
â”‚   
â”‚           # Auto-detect correlation ID from context if not provided
â”‚           if not correlation_id:
â”‚               correlation_id = get_correlation_context()
â”‚               if not correlation_id:
â”‚                   # Generate new one if no context
â”‚                   from uuid import uuid4
â”‚   
â”‚                   correlation_id = f"corr_{uuid4().hex[:12]}"
â”‚   
â”‚           # Create envelope with typed payload
â”‚           envelope = EventEnvelope[type(payload)](
â”‚               event_type=subject,
â”‚               correlation_id=correlation_id,
â”‚               source_service=self.service_name,
â”‚               data=payload,
â”‚               metadata=metadata or {},
â”‚           )
â”‚   
â”‚           self.logger.info(
â”‚               "Publishing event",
â”‚               extra={
â”‚                   "event_id": envelope.event_id,
â”‚                   "event_type": subject,
â”‚                   "correlation_id": correlation_id,
â”‚                   "service": self.service_name,
â”‚               },
â”‚           )
â”‚   
â”‚           try:
â”‚               # Ensure stream exists
â”‚               await self._ensure_stream()
â”‚   
â”‚               # Publish with envelope
â”‚               ack = await self.js_client.js.publish(subject, envelope.to_bytes())
â”‚   
â”‚               self.logger.info(
â”‚                   "Event published successfully",
â”‚                   extra={"event_id": envelope.event_id, "event_type": subject, "sequence": ack.seq if ack else None},
â”‚               )
â”‚   
â”‚               return envelope.event_id
â”‚   
â”‚           except Exception as e:
â”‚               self.logger.error(
â”‚                   "Failed to publish event", extra={"event_id": envelope.event_id, "event_type": subject, "error": str(e)}
â”‚               )
â”‚               raise
â”‚   
â”‚       async def publish_to_dlq(
â”‚           self,
â”‚           original_subject: str,
â”‚           error_payload: dict,
â”‚           correlation_id: str,
â”‚           error: Exception,
â”‚       ) -> str:
â”‚           """
â”‚           Publish failed event to dead letter queue.
â”‚   
â”‚           Args:
â”‚               original_subject: Original event subject that failed
â”‚               error_payload: Original payload that failed processing
â”‚               correlation_id: Original correlation ID
â”‚               error: The exception that occurred
â”‚           """
â”‚           # Convert subject to DLQ pattern: evt.order.created -> dlq.order.created
â”‚           dlq_subject = original_subject.replace("evt.", "dlq.").replace("cmd.", "dlq.")
â”‚   
â”‚           from .events.models import ErrorPayload
â”‚   
â”‚           error_data = ErrorPayload(
â”‚               error_code=type(error).__name__,
â”‚               error_message=str(error),
â”‚               failed_operation=original_subject,
â”‚               original_data=error_payload,
â”‚           )
â”‚   
â”‚           return await self.publish_event(
â”‚               subject=dlq_subject,
â”‚               payload=error_data,
â”‚               correlation_id=correlation_id,
â”‚               metadata={"original_subject": original_subject},
â”‚           )
â”‚   ```
â”‚   
â””â”€â”€ subjects.py
    
    ```py
    # shared/shared/messaging/subjects.py
    """NATS subjects for microservices."""
    
    from enum import Enum
    
    
    class Subjects(str, Enum):
        """NATS subjects for the notification service"""
    
        # Notification events
        NOTIFICATION_EMAIL_REQUESTED = "cmd.notification.email.send.v1"
        NOTIFICATION_EMAIL_SENT = "evt.notification.email.sent.v1"
        NOTIFICATION_EMAIL_FAILED = "evt.notification.email.failed.v1"
    
        # Billing subjects
        BILLING_TRIAL_STARTED = "evt.billing.trial.started.v1"
        BILLING_TRIAL_EXPIRED = "evt.billing.trial.expired.v1"
        BILLING_CREDITS_PURCHASED = "evt.billing.credits.purchased.v1"
    
        # Merchant subjects
        MERCHANT_CREATED = "evt.merchant.created.v1"
    
        # Catalog subjects
        CATAlOG_SYNC_STARTED = "evt.catalog.sync.started.v1"
        CATALOG_SYNC_COMPLETED = "evt.catalog.sync.completed.v1"
        CATALOG_SYNC_FAILED = "evt.catalog.sync.failed.v1"
    
        # Credit events
        CREDIT_BALANCE_LOW = "evt.credit.balance.low.v1"
        CREDIT_BALANCE_DEPLETED = "evt.credit.balance.depleted.v1"
        CREDITS_CONSUMED = "evt.credits.consumed.v1"
        CREDITS_RESET = "evt.credits.reset.v1"
    
        # Analytics events
        ANALYTICS_EVENT_TRACKED = "evt.analytics.tracked.v1"
        ANALYTICS_AGGREGATED = "evt.analytics.aggregated.v1"
    
        # Webhook events
        WEBHOOK_RECEIVED = "evt.webhook.received.v1"
        WEBHOOK_PROCESSED = "evt.webhook.processed.v1"
        WEBHOOK_FAILED = "evt.webhook.failed.v1"
    ```
    
utils/
â”œâ”€â”€ __init__.py
â”‚   
â”‚   ```py
â”‚   from .config_loader import load_root_env
â”‚   from .exceptions import (
â”‚       ConfigurationError,
â”‚       DomainError,
â”‚       ForbiddenError,
â”‚       GlamBaseError,
â”‚       InfrastructureError,
â”‚       InternalError,
â”‚       NotFoundError,
â”‚       RateLimitExceededError,
â”‚       RequestTimeoutError,
â”‚       ServiceUnavailableError,
â”‚       UnauthorizedError,
â”‚       ValidationError,
â”‚   )
â”‚   from .idempotency_key import generate_idempotency_key
â”‚   from .logger import ServiceLogger, create_logger
â”‚   
â”‚   __all__ = [
â”‚       # Config loader
â”‚       "load_root_env",
â”‚       # Exceptions
â”‚       "GlamBaseError",
â”‚       "ConfigurationError",
â”‚       "InternalError",
â”‚       "RequestTimeoutError",
â”‚       "ServiceUnavailableError",
â”‚       "RateLimitExceededError",
â”‚       "ForbiddenError",
â”‚       "UnauthorizedError",
â”‚       "NotFoundError",
â”‚       "ValidationError",
â”‚       "DomainError",
â”‚       "InfrastructureError",
â”‚       # Logger
â”‚       "create_logger",
â”‚       "ServiceLogger",
â”‚       # Idempotency key
â”‚       "generate_idempotency_key",
â”‚   ]
â”‚   ```
â”‚   
â”œâ”€â”€ config_loader.py
â”‚   
â”‚   ```py
â”‚   # shared/shared/utils/config_loader.py
â”‚   
â”‚   import os
â”‚   from pathlib import Path
â”‚   
â”‚   from dotenv import load_dotenv
â”‚   
â”‚   
â”‚   def load_root_env():
â”‚       """Load .env from repository root"""
â”‚       # Don't load in Docker containers
â”‚       if os.path.exists("/.dockerenv"):
â”‚           return
â”‚       # Find repo root
â”‚       current = Path(__file__).resolve()
â”‚       while current.name != "glam-app":
â”‚           if current.parent == current:
â”‚               break
â”‚           current = current.parent
â”‚       else:
â”‚           env_file = current / ".env"
â”‚           if env_file.exists():
â”‚               load_dotenv(env_file, override=False)
â”‚   ```
â”‚   
â”œâ”€â”€ exceptions.py
â”‚   
â”‚   ```py
â”‚   # shared/utils/exceptions.py
â”‚   
â”‚   """
â”‚   Base error classes for the glam-app error hierarchy.
â”‚   
â”‚   This module defines the fundamental error types that all other
â”‚   errors inherit from, following a three-tier model:
â”‚   1. GlamBaseError - Root of all application errors
â”‚   2. InfrastructureError - External system failures
â”‚   3. DomainError - Business logic violations
â”‚   """
â”‚   
â”‚   from typing import Any
â”‚   
â”‚   
â”‚   class GlamBaseError(Exception):
â”‚       """
â”‚       Base class for all glam-app errors.
â”‚   
â”‚       Attributes:
â”‚           code: Stable error code for clients (e.g., "VALIDATION_ERROR")
â”‚           status: HTTP status code (default 500)
â”‚           message: Human-readable error message
â”‚           details: Additional error context
â”‚           __cause__: Original exception if wrapped
â”‚       """
â”‚   
â”‚       code: str = "INTERNAL_ERROR"
â”‚       status: int = 500
â”‚   
â”‚       def __init__(
â”‚           self,
â”‚           message: str,
â”‚           *,
â”‚           code: str | None = None,
â”‚           status: int | None = None,
â”‚           details: dict[str, Any] | None = None,
â”‚           cause: Exception | None = None,
â”‚       ):
â”‚           super().__init__(message)
â”‚   
â”‚           if code is not None:
â”‚               self.code = code
â”‚           if status is not None:
â”‚               self.status = status
â”‚   
â”‚           self.message = message
â”‚           self.details = details or {}
â”‚   
â”‚           # Preserve the original exception chain
â”‚           if cause is not None:
â”‚               self.__cause__ = cause
â”‚   
â”‚       def to_dict(self) -> dict[str, Any]:
â”‚           """Convert error to dictionary for JSON serialization."""
â”‚           result: dict[str, Any] = {
â”‚               "code": self.code,
â”‚               "message": self.message,
â”‚           }
â”‚   
â”‚           if self.details:
â”‚               result["details"] = self.details
â”‚   
â”‚           return result
â”‚   
â”‚   
â”‚   class InfrastructureError(GlamBaseError):
â”‚       """
â”‚       Infrastructure/external system errors.
â”‚   
â”‚       These are failures in external dependencies like databases,
â”‚       APIs, message queues, etc. They may be retryable.
â”‚       """
â”‚   
â”‚       code = "INFRASTRUCTURE_ERROR"
â”‚       status = 503  # Service Unavailable
â”‚   
â”‚       def __init__(self, message: str, *, service: str | None = None, retryable: bool = True, **kwargs):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if service:
â”‚               self.details["service"] = service
â”‚   
â”‚           self.details["retryable"] = retryable
â”‚           self.retryable = retryable
â”‚   
â”‚   
â”‚   class DomainError(GlamBaseError):
â”‚       """
â”‚       Domain/business logic errors.
â”‚   
â”‚       These represent violations of business rules or invalid
â”‚       operations within the application domain.
â”‚       """
â”‚   
â”‚       code = "DOMAIN_ERROR"
â”‚       status = 400  # Bad Request
â”‚   
â”‚   
â”‚   # Common domain errors used across services
â”‚   
â”‚   
â”‚   class ValidationError(DomainError):
â”‚       """Invalid request data or parameters."""
â”‚   
â”‚       code = "VALIDATION_ERROR"
â”‚       status = 422  # Unprocessable Entity
â”‚   
â”‚       def __init__(self, message: str, *, field: str | None = None, value: Any | None = None, **kwargs):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if field:
â”‚               self.details["field"] = field
â”‚           if value is not None:
â”‚               self.details["value"] = str(value)
â”‚   
â”‚   
â”‚   class NotFoundError(DomainError):
â”‚       """Requested resource not found."""
â”‚   
â”‚       code = "NOT_FOUND"
â”‚       status = 404
â”‚   
â”‚       def __init__(self, message: str, *, resource: str | None = None, resource_id: Any | None = None, **kwargs):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if resource:
â”‚               self.details["resource"] = resource
â”‚           if resource_id is not None:
â”‚               self.details["resource_id"] = str(resource_id)
â”‚   
â”‚   
â”‚   class ConflictError(DomainError):
â”‚       """Operation conflicts with current state."""
â”‚   
â”‚       code = "CONFLICT"
â”‚       status = 409
â”‚   
â”‚       def __init__(
â”‚           self, message: str, *, conflicting_resource: str | None = None, current_state: str | None = None, **kwargs
â”‚       ):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if conflicting_resource:
â”‚               self.details["conflicting_resource"] = conflicting_resource
â”‚           if current_state:
â”‚               self.details["current_state"] = current_state
â”‚   
â”‚   
â”‚   class UnauthorizedError(DomainError):
â”‚       """Authentication required or failed."""
â”‚   
â”‚       code = "UNAUTHORIZED"
â”‚       status = 401
â”‚   
â”‚       def __init__(self, message: str = "Authentication required", *, auth_type: str | None = None, **kwargs):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if auth_type:
â”‚               self.details["auth_type"] = auth_type
â”‚   
â”‚   
â”‚   class ForbiddenError(DomainError):
â”‚       """Authenticated but insufficient permissions."""
â”‚   
â”‚       code = "FORBIDDEN"
â”‚       status = 403
â”‚   
â”‚       def __init__(
â”‚           self,
â”‚           message: str = "Insufficient permissions",
â”‚           *,
â”‚           required_permission: str | None = None,
â”‚           resource: str | None = None,
â”‚           **kwargs,
â”‚       ):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if required_permission:
â”‚               self.details["required_permission"] = required_permission
â”‚           if resource:
â”‚               self.details["resource"] = resource
â”‚   
â”‚   
â”‚   class RateLimitExceededError(DomainError):
â”‚       """Too many requests."""
â”‚   
â”‚       code = "RATE_LIMITED"
â”‚       status = 429
â”‚   
â”‚       def __init__(
â”‚           self,
â”‚           message: str = "Rate limit exceeded",
â”‚           *,
â”‚           limit: int | None = None,
â”‚           window: str | None = None,
â”‚           retry_after: int | None = None,
â”‚           **kwargs,
â”‚       ):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if limit:
â”‚               self.details["limit"] = limit
â”‚           if window:
â”‚               self.details["window"] = window
â”‚           if retry_after:
â”‚               self.details["retry_after"] = retry_after
â”‚   
â”‚   
â”‚   class ServiceUnavailableError(InfrastructureError):
â”‚       """Service temporarily unavailable."""
â”‚   
â”‚       code = "SERVICE_UNAVAILABLE"
â”‚       status = 503
â”‚   
â”‚   
â”‚   class RequestTimeoutError(InfrastructureError):
â”‚       """Operation timed out."""
â”‚   
â”‚       code = "TIMEOUT"
â”‚       status = 504
â”‚   
â”‚       def __init__(self, message: str, *, timeout_seconds: float | None = None, operation: str | None = None, **kwargs):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if timeout_seconds:
â”‚               self.details["timeout_seconds"] = timeout_seconds
â”‚           if operation:
â”‚               self.details["operation"] = operation
â”‚   
â”‚   
â”‚   class InternalError(GlamBaseError):
â”‚       """Unexpected internal server error."""
â”‚   
â”‚       code = "INTERNAL_ERROR"
â”‚       status = 500
â”‚   
â”‚       def __init__(self, message: str = "An unexpected error occurred", *, error_id: str | None = None, **kwargs):
â”‚           # Never expose internal details in production
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if error_id:
â”‚               self.details["error_id"] = error_id
â”‚   
â”‚   
â”‚   class ConfigurationError(GlamBaseError):
â”‚       """Configuration errors in the application."""
â”‚   
â”‚       code = "CONFIGURATION_ERROR"
â”‚       status = 500
â”‚   
â”‚       def __init__(self, message: str, *, config_key: str | None = None, expected_value: Any | None = None, **kwargs):
â”‚           super().__init__(message, **kwargs)
â”‚   
â”‚           if config_key:
â”‚               self.details["config_key"] = config_key
â”‚           if expected_value is not None:
â”‚               self.details["expected_value"] = expected_value
â”‚   ```
â”‚   
â”œâ”€â”€ idempotency_key.py
â”‚   
â”‚   ```py
â”‚   # shared/utils/idempotency.py
â”‚   """Simple idempotency key generator."""
â”‚   
â”‚   from uuid import UUID
â”‚   
â”‚   
â”‚   def generate_idempotency_key(
â”‚       system: str, operation_type: str, identifier: str | int | UUID, extra: str | None = None
â”‚   ) -> str:
â”‚       """
â”‚       Generate idempotency key: SYSTEM_OPERATION_ID[_EXTRA]
â”‚   
â”‚       Examples:
â”‚           generate_idempotency_key("SHOPIFY", "ORDER", "123456")
â”‚           â†’ "SHOPIFY_ORDER_123456"
â”‚   
â”‚           generate_idempotency_key("STRIPE", "PAYMENT", "pi_abc123")
â”‚           â†’ "STRIPE_PAYMENT_pi_abc123"
â”‚   
â”‚           generate_idempotency_key("SHOPIFY", "ORDER", "123", "TESTSTORE")
â”‚           â†’ "SHOPIFY_ORDER_123_TESTSTORE"
â”‚       """
â”‚       # Normalize inputs
â”‚       system = str(system).upper().replace("-", "_").replace(".", "_")
â”‚       operation_type = str(operation_type).upper().replace("-", "_").replace(".", "_")
â”‚       identifier = str(identifier)
â”‚   
â”‚       # Build key
â”‚       parts = [system, operation_type, identifier]
â”‚   
â”‚       if extra:
â”‚           parts.append(str(extra).upper().replace("-", "_").replace(".", "_"))
â”‚   
â”‚       return "_".join(parts)
â”‚   ```
â”‚   
â””â”€â”€ logger.py
    
    ```py
    # shared/utils/logger.py
    import json
    import logging
    import sys
    from typing import Any
    
    
    class JsonFormatter(logging.Formatter):
        def format(self, record):
            log_record = {
                "timestamp": self.formatTime(record, self.datefmt),
                "level": record.levelname,
                "logger": record.name,
                "message": record.getMessage(),
            }
            # Add all custom fields set in `extra`
            log_record.update({k: v for k, v in record.__dict__.items() if k not in logging.LogRecord.__dict__})
            return json.dumps(log_record)
    
    
    class ServiceLogger:
        """Service logger that wraps Python's standard logger"""
    
        def __init__(self, service_name: str):
            self.service_name = service_name
            self.logger = logging.getLogger(service_name)
            self._request_context: dict[str, Any] = {}
    
            # Only add handler if root logger has no handlers
            # This prevents duplicate handlers in reload
            if not logging.root.handlers:
                handler = logging.StreamHandler(sys.stdout)
                formatter = JsonFormatter(datefmt="%Y-%m-%dT%H:%M:%S")
                handler.setFormatter(formatter)
                logging.root.addHandler(handler)
                logging.root.setLevel(logging.INFO)
    
        def set_request_context(self, **kwargs):
            """Set request-scoped context"""
            self._request_context = kwargs
    
        def clear_request_context(self):
            """Clear request context"""
            self._request_context = {}
    
        def _add_context(self, extra: dict | None) -> dict:
            """Add request context to extra fields"""
            combined = self._request_context.copy()
            if extra:
                combined.update(extra)
            return combined if combined else None
    
        def info(self, msg, *args, **kwargs):
            extra = kwargs.pop("extra", None)
            self.logger.info(msg, *args, extra=self._add_context(extra), **kwargs)
    
        def error(self, msg, *args, **kwargs):
            extra = kwargs.pop("extra", None)
            self.logger.error(msg, *args, extra=self._add_context(extra), **kwargs)
    
        def warning(self, msg, *args, **kwargs):
            extra = kwargs.pop("extra", None)
            self.logger.warning(msg, *args, extra=self._add_context(extra), **kwargs)
    
        def debug(self, msg, *args, **kwargs):
            extra = kwargs.pop("extra", None)
            self.logger.debug(msg, *args, extra=self._add_context(extra), **kwargs)
    
        def critical(self, msg, *args, **kwargs):
            extra = kwargs.pop("extra", None)
            self.logger.critical(msg, *args, extra=self._add_context(extra), **kwargs)
    
    
    def create_logger(service_name: str) -> ServiceLogger:
        return ServiceLogger(service_name)
    ```
    
__init__.py

================================================================================
Output includes file contents
================================================================================