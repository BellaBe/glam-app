================================================================================
Directory Structure: /home/bellabe/glam-app/infrastructure
================================================================================

infrastructure/
caddy/
├── Caddyfile.dev
└── Caddyfile.prod
docker/
├── ai-service.Dockerfile
│
│   ```Dockerfile
│   # infrastructure/docker/ai-service.Dockerfile
│   ARG SERVICE
│
│   FROM python:3.11-slim AS builder
│   ARG SERVICE
│   ENV DEBIAN_FRONTEND=noninteractive \
│       PIP_DISABLE_PIP_VERSION_CHECK=1 \
│       POETRY_VERSION=1.8.3 \
│       POETRY_VIRTUALENVS_CREATE=false \
│       POETRY_NO_INTERACTION=1
│
│   RUN apt-get update && apt-get install -y --no-install-recommends curl gcc g++ cmake \
│       && rm -rf /var/lib/apt/lists/*
│
│   RUN curl -sSL https://install.python-poetry.org | python3 -
│   ENV PATH="/root/.local/bin:${PATH}"
│
│   WORKDIR /build
│   # Copy only metadata first
│   COPY services/${SERVICE}/pyproject.toml /build/pyproject.toml
│   COPY services/${SERVICE}/poetry.lock /build/poetry.lock
│
│   # Export and build wheels
│   RUN poetry export --with main -f requirements.txt > /requirements.txt
│   RUN pip wheel --no-cache-dir --wheel-dir /wheels -r /requirements.txt
│
│   # Copy code/models after deps
│   COPY services/${SERVICE}/ /build/service
│
│
│   FROM python:3.11-slim AS production
│   ARG SERVICE
│   ENV PYTHONUNBUFFERED=1 OMP_NUM_THREADS=2 OPENCV_VIDEOIO_PRIORITY_BACKEND=0
│
│   RUN apt-get update && apt-get install -y --no-install-recommends \
│       libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 libgl1-mesa-glx libglu1-mesa curl \
│       && apt-get clean && rm -rf /var/lib/apt/lists/* \
│       && useradd -m -u 1000 appuser
│
│   WORKDIR /app
│   COPY --from=builder /wheels /wheels
│   COPY --from=builder /requirements.txt /requirements.txt
│   RUN pip install --no-cache-dir --find-links=/wheels -r /requirements.txt \
│       && rm -rf /wheels /requirements.txt
│
│   COPY --chown=appuser:appuser --from=builder /build/service /app
│
│   USER appuser
│   EXPOSE 8000
│   HEALTHCHECK --interval=30s --timeout=15s --start-period=60s --retries=3 \
│     CMD curl -f http://localhost:8000/health || exit 1
│   CMD ["uvicorn","src.main:app","--host","0.0.0.0","--port","8000","--workers","1"]
│
│   FROM builder AS development
│   WORKDIR /app
│   RUN poetry install --with dev --no-root && pip install watchdog
│   COPY --chown=appuser:appuser --from=builder /build /app
│   USER appuser
│   EXPOSE 8000
│   CMD ["uvicorn","src.main:app","--host","0.0.0.0","--port","8000","--reload"]
│   ```
│
└── service.Dockerfile

    ```Dockerfile
    # infrastructure/docker/service.Dockerfile
    ARG SERVICE

    FROM python:3.11-slim AS builder
    ARG SERVICE
    ENV DEBIAN_FRONTEND=noninteractive \
        PIP_DISABLE_PIP_VERSION_CHECK=1 \
        POETRY_VERSION=1.8.3 \
        POETRY_VIRTUALENVS_CREATE=false \
        POETRY_NO_INTERACTION=1

    # Build deps only here
    RUN apt-get update && apt-get install -y --no-install-recommends curl gcc g++ build-essential \
        && rm -rf /var/lib/apt/lists/*

    # Install Poetry in builder
    RUN curl -sSL https://install.python-poetry.org | python3 -
    ENV PATH="/root/.local/bin:${PATH}"

    WORKDIR /build

    # Copy only lock metadata first for cache
    # Shared layer
    COPY shared/pyproject.toml /build/shared/pyproject.toml
    COPY shared/poetry.lock /build/shared/poetry.lock
    # Service layer
    COPY services/${SERVICE}/pyproject.toml /build/service/pyproject.toml
    COPY services/${SERVICE}/poetry.lock /build/service/poetry.lock

    # Export fully pinned requirements from locks
    # Remove editable lines if any
    RUN cd /build/shared  && poetry export --with main -f requirements.txt | sed '/^-e /d' > /req-shared.txt
    RUN cd /build/service && poetry export --with main -f requirements.txt | sed '/^-e /d' > /req-svc.txt
    RUN cat /req-shared.txt /req-svc.txt > /requirements.txt

    # Build wheels for offline deterministic installs
    RUN pip wheel --no-cache-dir --wheel-dir /wheels -r /requirements.txt

    # Now copy source (after deps for better caching)
    COPY shared /build/shared
    COPY services/${SERVICE} /build/service

    # Optional: build local wheels for your own packages if they are proper PEP 517 packages
    # RUN pip install build && python -m build /build/shared -o /dist && python -m build /build/service -o /dist && \
    #     pip wheel --no-cache-dir --wheel-dir /wheels /dist/*.whl

    FROM python:3.11-slim AS production
    ARG SERVICE
    ENV PYTHONUNBUFFERED=1 PYTHONDONTWRITEBYTECODE=1

    RUN apt-get update && apt-get install -y --no-install-recommends libpq5 curl \
        && apt-get clean && rm -rf /var/lib/apt/lists/* \
        && useradd -m -u 1000 appuser

    WORKDIR /app

    # Install from wheels exactly
    COPY --from=builder /wheels /wheels
    COPY --from=builder /requirements.txt /requirements.txt
    RUN pip install --no-cache-dir --find-links=/wheels -r /requirements.txt \
        && rm -rf /wheels /requirements.txt

    # Bring application code
    COPY --chown=appuser:appuser --from=builder /build/shared /shared
    COPY --chown=appuser:appuser --from=builder /build/service /app

    USER appuser
    EXPOSE 8000

    # Migrations via module invocation to avoid missing console scripts
    HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
      CMD curl -f http://localhost:8000/health || exit 1

    CMD sh -c "if [ -d alembic ]; then python -m alembic upgrade head; fi && \
               uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 1"

    # Dev target keeps Poetry if you need it
    FROM builder AS development
    ARG SERVICE
    RUN cd /build/shared  && poetry install --with dev --no-root && \
        cd /build/service && poetry install --with dev --no-root && \
        pip install watchdog
    WORKDIR /app
    COPY --chown=appuser:appuser --from=builder /build/shared /shared
    COPY --chown=appuser:appuser --from=builder /build/service /app
    USER appuser
    EXPOSE 8000
    CMD ["uvicorn","src.main:app","--host","0.0.0.0","--port","8000","--reload"]
    ```

scripts/
├── backup.sh
│
│   ```sh
│   #!/bin/bash
│   set -euo pipefail
│
│   # Configuration
│   BACKUP_DIR="${BACKUP_DIR:-/var/backups/glam}"
│   DATE=$(date +%Y%m%d_%H%M%S)
│   BACKUP_PATH="${BACKUP_DIR}/${DATE}"
│   RETENTION_DAYS=7
│   COMPOSE_FILE="${COMPOSE_FILE:-docker-compose.yml}"
│
│   mkdir -p "${BACKUP_PATH}"
│
│   echo "Starting backup at $(date)"
│
│   DATABASES=(
│       "analytics_db"
│       "billing_db"
│       "catalog_db"
│       "credit_db"
│       "merchant_db"
│       "notification_db"
│       "recommendation_db"
│       "season_compatibility_db"
│       "selfie_db"
│       "token_db"
│       "webhook_db"
│   )
│
│   for db in "${DATABASES[@]}"; do
│       echo "  Backing up ${db}..."
│       docker compose exec -T postgres pg_dump -U postgres -Fc "${db}" > "${BACKUP_PATH}/${db}.dump"
│   done
│
│   # Backup config (without secrets)
│   echo "Backing up configuration..."
│   grep -v "PASS\|KEY\|SECRET\|TOKEN" .env.prod > "${BACKUP_PATH}/env.backup" 2>/dev/null || true
│
│   # Compress
│   echo "Compressing backup..."
│   tar -czf "${BACKUP_PATH}.tar.gz" -C "${BACKUP_DIR}" "${DATE}"
│   rm -rf "${BACKUP_PATH}"
│
│   # Cleanup old backups
│   echo "Cleaning old backups..."
│   find "${BACKUP_DIR}" -name "*.tar.gz" -mtime +${RETENTION_DAYS} -delete
│
│   echo "✅ Backup completed: ${BACKUP_PATH}.tar.gz"
│   echo "   Size: $(du -h ${BACKUP_PATH}.tar.gz | cut -f1)"
│   ```
│
├── cleanup-system.sh
├── debug-container.sh
│
│   ```sh
│   #!/bin/bash
│   # Container Debugging Script
│   # Source: Docker Troubleshooting Ch.7, pg 98-105
│
│   set -e
│
│   CONTAINER=$1
│
│   if [ -z "$CONTAINER" ]; then
│       echo "Usage: $0 <container-name-or-id>"
│       exit 1
│   fi
│
│   echo "=== Container Status ==="
│   docker inspect $CONTAINER --format '{{.State.Status}}'
│   docker inspect $CONTAINER --format 'Exit Code: {{.State.ExitCode}}'
│   # Exit codes: 0=clean, 1=app error, 137=OOM killed, 139=segfault
│
│   echo -e "\n=== Last 50 Log Lines ==="
│   docker logs --tail 50 $CONTAINER
│
│   echo -e "\n=== Resource Usage ==="
│   docker stats --no-stream $CONTAINER
│
│   echo -e "\n=== Running Processes ==="
│   docker top $CONTAINER
│
│   echo -e "\n=== Port Bindings ==="
│   docker port $CONTAINER
│
│   echo -e "\n=== Network Config ==="
│   docker inspect $CONTAINER --format '{{range .NetworkSettings.Networks}}{{.IPAddress}}{{end}}'
│
│   echo -e "\n=== Volume Mounts ==="
│   docker inspect $CONTAINER --format '{{range .Mounts}}{{.Source}} -> {{.Destination}}{{"\n"}}{{end}}'
│
│   echo -e "\n=== Environment Variables ==="
│   docker exec $CONTAINER env | sort
│   ```
│
├── postgres-init.sh
│
│   ```sh
│   #!/bin/bash
│   set -e
│
│   echo "=== GlamYouUp Database Initialization ==="
│   echo "Starting at $(date)"
│
│   DATABASES=(
│       "analytics_db"
│       "billing_db"
│       "catalog_db"
│       "credit_db"
│       "merchant_db"
│       "notification_db"
│       "recommendation_db"
│       "season_compatibility_db"
│       "selfie_db"
│       "token_db"
│       "webhook_db"
│   )
│
│   for DB in "${DATABASES[@]}"; do
│       echo "Creating database: $DB"
│       psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" <<-EOSQL
│           CREATE DATABASE $DB
│               WITH
│               ENCODING = 'UTF8'
│               LC_COLLATE = 'C'
│               LC_CTYPE = 'C'
│               TEMPLATE = template0;
│
│           GRANT ALL PRIVILEGES ON DATABASE $DB TO $POSTGRES_USER;
│
│           \c $DB
│
│           CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
│           CREATE EXTENSION IF NOT EXISTS "pg_stat_statements";
│           CREATE EXTENSION IF NOT EXISTS "pg_trgm";
│           CREATE EXTENSION IF NOT EXISTS "btree_gin";
│           CREATE EXTENSION IF NOT EXISTS "btree_gist";
│
│           GRANT ALL ON SCHEMA public TO $POSTGRES_USER;
│           GRANT ALL ON ALL TABLES IN SCHEMA public TO $POSTGRES_USER;
│           GRANT ALL ON ALL SEQUENCES IN SCHEMA public TO $POSTGRES_USER;
│           GRANT ALL ON ALL FUNCTIONS IN SCHEMA public TO $POSTGRES_USER;
│
│           ALTER DEFAULT PRIVILEGES IN SCHEMA public
│               GRANT ALL ON TABLES TO $POSTGRES_USER;
│           ALTER DEFAULT PRIVILEGES IN SCHEMA public
│               GRANT ALL ON SEQUENCES TO $POSTGRES_USER;
│           ALTER DEFAULT PRIVILEGES IN SCHEMA public
│               GRANT ALL ON FUNCTIONS TO $POSTGRES_USER;
│
│           ALTER DATABASE $DB SET random_page_cost = 1.1;
│           ALTER DATABASE $DB SET effective_io_concurrency = 200;
│           ALTER DATABASE $DB SET statement_timeout = '30s';
│           ALTER DATABASE $DB SET idle_in_transaction_session_timeout = '5min';
│   EOSQL
│       echo "✅ Created database: $DB"
│   done
│
│   psql -v ON_ERROR_STOP=1 --username "$POSTGRES_USER" --dbname=postgres <<-EOSQL
│       CREATE EXTENSION IF NOT EXISTS pg_stat_statements;
│
│       CREATE OR REPLACE VIEW db_sizes AS
│       SELECT
│           datname as database,
│           pg_size_pretty(pg_database_size(datname)) as size,
│           pg_database_size(datname) as bytes
│       FROM pg_database
│       WHERE datname NOT IN ('postgres', 'template0', 'template1')
│       ORDER BY pg_database_size(datname) DESC;
│
│       CREATE OR REPLACE VIEW db_connections AS
│       SELECT
│           datname as database,
│           count(*) as connections,
│           max(backend_start) as oldest_connection,
│           count(*) FILTER (WHERE state = 'active') as active,
│           count(*) FILTER (WHERE state = 'idle') as idle,
│           count(*) FILTER (WHERE state = 'idle in transaction') as idle_in_transaction
│       FROM pg_stat_activity
│       WHERE datname IS NOT NULL
│       GROUP BY datname
│       ORDER BY count(*) DESC;
│   EOSQL
│
│   echo "✅ Initialization Complete"
│   echo "Total databases: ${#DATABASES[@]}"
│   ```
│
├── restore.sh
│
│   ```sh
│   #!/bin/bash
│   set -euo pipefail
│
│   BACKUP_DATE=${1:-}
│   BACKUP_DIR="${BACKUP_DIR:-/var/backups/glam}"
│
│   if [ -z "$BACKUP_DATE" ]; then
│       echo "Usage: $0 YYYYMMDD_HHMMSS"
│       echo "Available backups:"
│       ls -lh "$BACKUP_DIR"/*.tar.gz 2>/dev/null || echo "No backups found"
│       exit 1
│   fi
│
│   BACKUP_FILE="$BACKUP_DIR/${BACKUP_DATE}.tar.gz"
│
│   if [ ! -f "$BACKUP_FILE" ]; then
│       echo "Backup file not found: $BACKUP_FILE"
│       exit 1
│   fi
│
│   echo "Restoring from $BACKUP_FILE..."
│   read -p "This will OVERWRITE current databases. Continue? (yes/NO) " -r
│   if [[ ! $REPLY == "yes" ]]; then
│       echo "Aborted"
│       exit 1
│   fi
│
│   TEMP_DIR=$(mktemp -d)
│   trap "rm -rf $TEMP_DIR" EXIT
│
│   tar -xzf "$BACKUP_FILE" -C "$TEMP_DIR"
│
│   DATABASES=(
│       "analytics_db"
│       "billing_db"
│       "catalog_db"
│       "credit_db"
│       "merchant_db"
│       "notification_db"
│       "recommendation_db"
│       "season_compatibility_db"
│       "selfie_db"
│       "token_db"
│       "webhook_db"
│   )
│
│   for db in "${DATABASES[@]}"; do
│       dump_file="$TEMP_DIR/${BACKUP_DATE}/${db}.dump"
│       if [ -f "$dump_file" ]; then
│           echo "Restoring $db..."
│           docker compose exec -T postgres pg_restore -U postgres -d "$db" --clean --if-exists < "$dump_file" || echo "⚠️  Failed to restore $db"
│       else
│           echo "⚠️  Dump not found: $dump_file"
│       fi
│   done
│
│   echo "✅ Restore complete!"
│   ```
│
└── security-scan.sh
.env.dev
.env.example
.env.local
.env.prod
docker-compose.dev.yml

```yml
# infrastructure/docker-compose.dev.yml
# Development: Exact prod config with debug settings
# Pattern: DRY configuration with anchors for reuse across environments
# Usage: docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d

x-prod-logging: &prod-logging
  logging:
    driver: json-file
    options:
      max-size: '10m'
      max-file: '3'

x-prod-logging-heavy: &prod-logging-heavy
  logging:
    driver: json-file
    options:
      max-size: '20m'
      max-file: '5'

x-api-limits: &api-limits
  deploy:
    resources:
      limits:
        cpus: '0.25'
        memory: 256M
      reservations:
        memory: 128M

x-api-service-dev: &api-service-dev
  <<: *prod-logging
  build:
    target: development

services:
  postgres:
    <<: *prod-logging-heavy
    ports:
      - "5432:5432"
    command: >
      postgres
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c maintenance_work_mem=256MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=10MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=4
      -c max_parallel_workers_per_gather=2
      -c max_parallel_workers=4
      -c max_parallel_maintenance_workers=2
      -c max_connections=200
      -c log_min_duration_statement=200
      -c log_checkpoints=on
      -c autovacuum_max_workers=2
      -c autovacuum_naptime=10s
    volumes:
      - ./scripts/backup.sh:/usr/local/bin/backup.sh:ro
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 4G
        reservations:
          memory: 2G

  nats:
    <<: *prod-logging
    ports:
      - "4222:4222"
      - "8222:8222"
    command: [
      "nats-server",
      "-js",
      "--store_dir", "/data",
      "--max_payload", "8MB",
      "--max_connections", "1000",
      "--max_subscriptions", "1000",
      "--js_max_memory", "512MB",
      "--js_max_storage", "10GB"
    ]
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          memory: 512M

  analytics-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8001:8000"

  billing-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8002:8000"

  catalog-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8003:8000"

  catalog-connector:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8004:8000"

  credit-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8005:8000"

  merchant-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8006:8000"

  notification-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8007:8000"

  recommendation-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8008:8000"

  season-compatibility-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8009:8000"

  selfie-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8010:8000"

  token-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8011:8000"

  webhook-service:
    <<: [*api-service-dev, *api-limits]
    ports:
      - "8012:8000"

  selfie-ai-analyzer:
    <<: *api-service-dev
    ports:
      - "8013:8000"
    deploy:
      resources:
        limits:
          cpus: '1.5'
          memory: 3G
        reservations:
          memory: 2G

  catalog-ai-analyzer:
    <<: *api-service-dev
    ports:
      - "8014:8000"
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          memory: 1G

  caddy:
    <<: *prod-logging-heavy
    image: caddy:2-alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./caddy/Caddyfile.dev:/etc/caddy/Caddyfile:ro
      - caddy-data-local:/data
      - caddy-config-local:/config
    networks:
      - glam
    depends_on:
      - postgres
      - nats
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          memory: 256M

  mailhog:
    image: mailhog/mailhog:latest
    ports:
      - "1025:1025"
      - "8025:8025"
    networks:
      - glam
    logging:
      driver: none
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M

volumes:
  caddy-data-local:
  caddy-config-local:
```

docker-compose.local.yml

```yml
# infrastructure/docker-compose.local.yml
# Purpose: Local development - services run OUTSIDE Docker, only infra in containers
# Usage: docker compose -f docker-compose.yml -f docker-compose.local.yml up -d
# Setup: echo "127.0.0.1 api.glamyouup.local" | sudo tee -a /etc/hosts
services:
  postgres:
    ports:
      - "5432:5432"

  nats:
    ports:
      - "4222:4222"
      - "8222:8222"

  # Disable all services
  analytics-service:
    deploy:
      replicas: 0
  billing-service:
    deploy:
      replicas: 0
  catalog-service:
    deploy:
      replicas: 0
  catalog-connector:
    deploy:
      replicas: 0
  credit-service:
    deploy:
      replicas: 0
  merchant-service:
    deploy:
      replicas: 0
  notification-service:
    deploy:
      replicas: 0
  recommendation-service:
    deploy:
      replicas: 0
  season-compatibility-service:
    deploy:
      replicas: 0
  selfie-service:
    deploy:
      replicas: 0
  token-service:
    deploy:
      replicas: 0
  webhook-service:
    deploy:
      replicas: 0
  selfie-ai-analyzer:
    deploy:
      replicas: 0
  catalog-ai-analyzer:
    deploy:
      replicas: 0

  mailhog:
    image: mailhog/mailhog:latest
    ports:
      - "1025:1025"
      - "8025:8025"
    networks:
      - glam
    logging:
      driver: none

```

docker-compose.prod.yml

```yml
# infrastructure/docker-compose.prod.yml
# Purpose: Production on Oracle Cloud E5.Flex (2 OCPU, 24GB RAM)
# Usage: docker compose -f docker-compose.yml -f docker-compose.prod.yml up -d
# Optimizations: Resource limits, logging rotation, SSL, tuned Postgres

x-prod-logging: &prod-logging
  logging:
    driver: json-file
    options:
      max-size: '10m'
      max-file: '3'

x-prod-logging-heavy: &prod-logging-heavy
  logging:
    driver: json-file
    options:
      max-size: '20m'
      max-file: '5'

x-api-limits: &api-limits
  deploy:
    resources:
      limits:
        memory: 256M
      reservations:
        memory: 128M

x-api-service-prod: &api-service-prod
  <<: *prod-logging
  build:
    target: production

services:
  postgres:
    <<: *prod-logging-heavy
    command: >
      postgres
      -c shared_buffers=1GB
      -c effective_cache_size=3GB
      -c maintenance_work_mem=256MB
      -c checkpoint_completion_target=0.9
      -c wal_buffers=16MB
      -c default_statistics_target=100
      -c random_page_cost=1.1
      -c effective_io_concurrency=200
      -c work_mem=10MB
      -c min_wal_size=1GB
      -c max_wal_size=4GB
      -c max_worker_processes=4
      -c max_parallel_workers_per_gather=2
      -c max_parallel_workers=4
      -c max_parallel_maintenance_workers=2
      -c max_connections=200
      -c log_min_duration_statement=200
      -c log_checkpoints=on
      -c autovacuum_max_workers=2
      -c autovacuum_naptime=10s
    volumes:
      - ./scripts/backup.sh:/usr/local/bin/backup.sh:ro
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 2G

  nats:
    <<: *prod-logging
    command: [
      "nats-server",
      "-js",
      "--store_dir", "/data",
      "--http_port", "8222",
      "--max_payload", "8MB",
      "--max_connections", "1000",
      "--max_subscriptions", "1000",
      "--js_max_memory", "512MB",
      "--js_max_storage", "10GB"
    ]
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  analytics-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/analytics-service:${TAG}

  billing-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/billing-service:${TAG}

  catalog-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/catalog-service:${TAG}

  catalog-connector:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/catalog-connector:${TAG}

  credit-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/credit-service:${TAG}

  merchant-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/merchant-service:${TAG}

  notification-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/notification-service:${TAG}

  recommendation-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/recommendation-service:${TAG}

  season-compatibility-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/season-compatibility-service:${TAG}

  selfie-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/selfie-service:${TAG}

  token-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/token-service:${TAG}

  webhook-service:
    <<: [*api-service-prod, *api-limits]
    image: ${REGISTRY:-glamyouup}/webhook-service:${TAG}

  selfie-ai-analyzer:
    <<: *api-service-prod
    image: ${REGISTRY:-glamyouup}/selfie-ai-analyzer:${TAG}
    deploy:
      resources:
        limits:
          memory: 3G
        reservations:
          memory: 2G

  catalog-ai-analyzer:
    <<: *api-service-prod
    image: ${REGISTRY:-glamyouup}/catalog-ai-analyzer:${TAG}
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  caddy:
    <<: *prod-logging-heavy
    image: caddy:2-alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./caddy/Caddyfile.prod:/etc/caddy/Caddyfile:ro
      - caddy-data:/data
      - caddy-config:/config
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:2019/metrics"]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - glam
    depends_on:
      - postgres
      - nats
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

volumes:
  caddy-data:
  caddy-config:
```

docker-compose.yml

```yml
# infrastructure/docker-compose.yml
# Purpose: Base service definitions - DO NOT RUN DIRECTLY
# Pattern: DRY configuration with anchors for reuse across environments
# Usage: docker compose -f docker-compose.yml -f docker-compose.{env}.yml up

x-healthcheck-defaults: &healthcheck-defaults
  interval: 30s
  timeout: 10s
  retries: 3
  start_period: 40s

x-healthcheck-ai: &healthcheck-ai
  interval: 30s
  timeout: 15s
  retries: 3
  start_period: 60s

x-api-service: &api-service
  build:
    context: ..
    dockerfile: infrastructure/docker/service.Dockerfile
  networks:
    - glam
  environment:
    - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${DB_NAME}
    - NATS_URL=nats://nats:4222
    - JWT_SECRET=${JWT_SECRET}
    - LOG_LEVEL=${LOG_LEVEL:-INFO}
  depends_on:
    postgres:
      condition: service_healthy
    nats:
      condition: service_healthy
  healthcheck:
    <<: *healthcheck-defaults
    test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  restart: unless-stopped

x-ai-service: &ai-service
  build:
    context: ..
    dockerfile: infrastructure/docker/ai-service.Dockerfile
  networks:
    - glam
  environment:
    - NATS_URL=nats://nats:4222
    - LOG_LEVEL=${LOG_LEVEL:-INFO}
  depends_on:
    nats:
      condition: service_healthy
  healthcheck:
    <<: *healthcheck-ai
    test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
  restart: unless-stopped

services:
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF8 --locale=C"
    volumes:
      - postgres-data:/var/lib/postgresql/data
      - ./scripts/postgres-init.sh:/docker-entrypoint-initdb.d/init.sh:ro
    networks:
      - glam
    healthcheck:
      test: pg_isready -U ${POSTGRES_USER} && psql -U ${POSTGRES_USER} -tAc "SELECT 1 FROM pg_database WHERE datname='analytics_db'" | grep -q 1
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped

  nats:
    image: nats:2.10.7-alpine
    command: ["nats-server", "-js", "--store_dir", "/data", "--http_port", "8222"]
    volumes:
      - nats-data:/data
    networks:
      - glam
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:8222/healthz"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  analytics-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: analytics-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/analytics_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  billing-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: billing-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/billing_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  catalog-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: catalog-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/catalog_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  catalog-connector:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: catalog-connector
    environment:
      - NATS_URL=nats://nats:4222
      - TOKEN_SERVICE_URL=http://token-service:8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      nats:
        condition: service_healthy
      token-service:
        condition: service_healthy

  credit-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: credit-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/credit_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  merchant-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: merchant-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/merchant_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  notification-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: notification-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/notification_db
      - NATS_URL=nats://nats:4222
      - SMTP_HOST=${SMTP_HOST}
      - SMTP_PORT=${SMTP_PORT:-587}
      - SMTP_USER=${SMTP_USER}
      - SMTP_PASSWORD=${SMTP_PASSWORD}
      - EMAIL_FROM=${EMAIL_FROM}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  recommendation-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: recommendation-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/recommendation_db
      - NATS_URL=nats://nats:4222
      - SEASON_COMPATIBILITY_SERVICE_URL=http://season-compatibility-service:8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
      season-compatibility-service:
        condition: service_healthy

  season-compatibility-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: season-compatibility-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/season_compatibility_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  selfie-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: selfie-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/selfie_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - SELFIE_AI_ANALYZER_URL=http://selfie-ai-analyzer:8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    depends_on:
      postgres:
        condition: service_healthy
      nats:
        condition: service_healthy
      selfie-ai-analyzer:
        condition: service_healthy

  token-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: token-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/token_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - ENCRYPTION_KEY=${ENCRYPTION_KEY}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  webhook-service:
    <<: *api-service
    build:
      context: ..
      dockerfile: infrastructure/docker/service.Dockerfile
      args:
        SERVICE: webhook-service
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/webhook_db
      - NATS_URL=nats://nats:4222
      - JWT_SECRET=${JWT_SECRET}
      - SHOPIFY_WEBHOOK_SECRET=${SHOPIFY_WEBHOOK_SECRET}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  selfie-ai-analyzer:
    <<: *ai-service
    build:
      context: ..
      dockerfile: infrastructure/docker/ai-service.Dockerfile
      args:
        SERVICE: selfie-ai-analyzer
    environment:
      - NATS_URL=nats://nats:4222
      - INTERNAL_API_KEY=${INTERNAL_API_KEY}
      - OMP_NUM_THREADS=2
      - OPENCV_VIDEOIO_PRIORITY_BACKEND=0
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

  catalog-ai-analyzer:
    <<: *ai-service
    build:
      context: ..
      dockerfile: infrastructure/docker/ai-service.Dockerfile
      args:
        SERVICE: catalog-ai-analyzer
    environment:
      - NATS_URL=nats://nats:4222
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OMP_NUM_THREADS=1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}

networks:
  glam:
    driver: bridge

volumes:
  postgres-data:
  nats-data:
```


================================================================================
Output includes file contents
================================================================================
